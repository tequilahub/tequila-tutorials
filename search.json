[
  {
    "objectID": "tutorials.html",
    "href": "tutorials.html",
    "title": "Tutorials",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "Building a Quantum Circuit for Gaussian Convolutions\n\n\n\n\n\n\n\n\n\n\n\n\nNov 23, 2024\n\n\nOliver Hüttenhofer\n\n\n\n\n\n\n  \n\n\n\n\nExcited State Methods\n\n\n\n\n\n\n\nmra\n\n\ncode\n\n\n\n\n\n\n\n\n\n\n\nOct 15, 2024\n\n\nElisabeth Welizky\n\n\n\n\n\n\n  \n\n\n\n\nMolecular Quantum Circuits\n\n\n\n\n\n\n\ntequila\n\n\ncode\n\n\nchemistry\n\n\n\n\n\n\n\n\n\n\n\nSep 12, 2024\n\n\nJakob Kottmann\n\n\n\n\n\n\n  \n\n\n\n\nBuilding a Variational Quantum Classifier\n\n\n\n\n\n\n\ncode\n\n\n\n\n\n\n\n\n\n\n\nJul 19, 2024\n\n\nSimon Reichert, Adapted by Thuy Truong\n\n\n\n\n\n\n  \n\n\n\n\nElectronic Hamiltonians\n\n\n\n\n\n\n\nchemistry\n\n\n\n\n\n\n\n\n\n\n\nNov 10, 2022\n\n\nJakob Kottmann\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "research/electronic-hamiltonians/index.html",
    "href": "research/electronic-hamiltonians/index.html",
    "title": "Electronic Hamiltonians",
    "section": "",
    "text": "What are electronic Hamiltonians and how can we construct them?\n\n\n\n\n\nFirst Quantized Formulation:\n\nHamiltonian is directly defined from the nuclear coordinates and charges\n\nSpin and Fermionic anti-symmetry need to be imposed on the wavefunctions\n\nParticle number is fixed\n\nExplicit computation of matrix representation unfeasible without approximations\n\nSecond Quantized Formulation:\n\nNeeds a set of orbitals to be constructed\n\nSpin and Fermionic anti-symmetry included in Hamiltonian\n\nParticle number is not fixed\n\nExplicit construction in finite basis feasible\n\n\n\n\nThe word molecule often stands for \\(N_\\text{e}\\) electrons with coordinates \\(r_k\\) moving in a potential created by atomic nuclei - assumed to be fixed point-charges with coordinates \\(R_A\\) and charges \\(N_A\\). The electronic Hamiltonian is then the operator expressing the interactions of the electrons in that potential \\[H =  \\sum_{k}^{N_\\text{e}} h\\left(r_k\\right) + \\sum_{k}^{N_\\text{e}} \\sum_{l&lt;k} g\\left(r_k,r_l\\right) + V_\\text{nn}.\\] We write it three parts and a constant, which are in atomic units:\n\nOne-body interactions: \\[ h(r) = T(r) + V_\\text{ne}(r) \\] including the kinetic energy of the electrons and the Coulombic attraction between electrons and nuclear charges\n\\[T(r) = -\\frac{1}{2} {\\nabla^2_{r}}, \\quad V_{\\text{ne}}(r) = \\sum_{A \\in \\text{nuclei}} \\frac{N_A}{\\|r-R_A\\|}.\\]\n\nTwo-body interactions: the Coulombic repulsion between individual electrons\n\\[g(r_k,r_l) = \\frac{1}{\\| r_k - r_l \\|}\\]\n\nA constant term: Coulombic repulsion between the nuclear charges\n\\[V_\\text{nn} = \\sum_{A&lt;B} \\frac{N_A N_B}{\\|R_A - R_b\\|} \\]\nwhich is just a constant for a given molecular structure.\n\nWith this, we have fully defined it, and the lowest eigenvalue of this differential operator gives the corresponding ground state energy. To ensure that the ground state describes a multi-electron system, we must impose restrictions on the wavefunction - Fermions have a spin and anti-symmetric permutation symmetry.\n\n\nAs we are describing electrons, they need to obey fermionic antisymmetry. In first quantization (or real-space formulation), the Hamiltonian does not have that property included, so without restrictions on the wavefunctions, it only describes \\(N_\\text{e}\\) negatively charged point-particles without any permutation symmetries or spin.\nWe can add spin conveniently by defining a single-electron wavefunction as a so called spin-orbital: A three-dimensional function \\(\\psi(r) \\in \\mathcal{L}^2(\\mathbb{R}^3)\\), describing the electron in spatial space, augmented with a spin-state \\[\\lvert\\sigma\\rangle \\in \\text{Span}\\left\\{\\lvert \\uparrow \\rangle, \\lvert \\downarrow \\rangle\\right\\} \\equiv \\mathbb{C}^2.\\] If the set of spatial orbitals \\(\\psi_k\\) forms a complete basis in \\(\\mathcal{L}^2(\\mathbb{R}^3)\\), we have an exact description of the electron. A convenient notation is to express the spin component as a function of a spin-coordinate \\(s\\left\\{-1,1\\right\\}\\) and combine spin coordinate \\(s\\) and spatial coordinate \\(r\\) to \\(x=(r,s)\\). In a given set of \\(M\\) spatial orbital, an arbitrary one electron wavefunction can then be expressed as \\[\n\\Psi(x) = \\sum_k^{2M} c_k \\phi(x) = \\sum_{l}^{M} \\psi_{l}(r)\\otimes \\left( c_{2l}\\lvert \\uparrow \\rangle + c_{2l+1} \\lvert \\downarrow \\rangle \\right)\n\\] with the spin-orbitals defined as \\[\n\\phi_k = \\psi_{\\lfloor{i/2}\\rfloor} \\otimes \\lvert \\sigma(k) \\rangle,\\; \\sigma_k=\\begin{cases} \\lvert \\uparrow \\rangle,\\; k \\text{ is even}  \\\\  \\lvert \\uparrow \\rangle,\\; k \\text{ is odd}  \\end{cases}.  \n\\] Many electron functions can then be constructed as linear combinations of anti-symmetric products of single electron functions (so called Slater-Determinants). \\[\n\\Psi\\left(x_1, \\dots, x_{N_\\text{e}}\\right) = \\sum_{m} d_m \\det\\left(\\phi_{m_1},\\dots, \\phi_{m_{N_\\text{e}}}\\right) \\\n\\]\n\n\n\n\nUsing second quantized language, we can significantly simplify the treatment of electron spin and anti-symmetry with the help of abstract field operators \\(\\hat{\\phi}^\\dagger(x)\\) (\\(\\hat{\\phi}(x)\\)) that create (or annihilate) electrons at spin-position \\(x\\). With them, we can formaly write the electronic Hamiltonian as \\[H = \\int \\hat{\\phi}^\\dagger(x) h(x) \\hat{\\phi}(x) \\operatorname{x}x + \\int \\int \\hat{\\phi}^\\dagger(x)\\hat{\\phi}^\\dagger(y) g(x,y) \\hat{\\phi}(x)\\hat{\\phi}(y) \\operatorname{d}x\\operatorname{d}y+ V_\\text{nn}.\\] The wavefunction is now only required to carry information about electron occupancies at all points in space. When acting on the wavefunction, the one-body part of the operator is first annihilating an electron at point \\(x\\). If no electron is present, this will lead to an energy contribution of zero and otherwise invoke \\(h(x)\\), followed by the restoration of the electron by the creation operator. The two-body part acts in the same way and the integrals ensure that we probe all points in space. In practice, this is unfeasible, and it is convenient to introduce a finite basis in the form of spin orbitals to expand the field operators as \\[\\hat{\\phi}(x) = \\sum_k \\phi(x)_k a_k, \\] leading to the more prominent form of the second quantized Hamiltonian \\[\nH = \\sum_{ij} \\tilde{h}^i{j}a^\\dagger_i a_j \\sum_{ijkl} \\tilde{g}^{ij}_{kl} a^\\dagger_i a^\\dagger_j a_l a_k + V_\\text{nn}.\n\\] The new discretized operators \\(a^\\dagger_k\\) (\\(a_k\\)) are now creating (annihilating) an electron in the spin orbital \\(\\phi_k\\) and the tensors \\(\\tilde{h}^{i}_{j}\\) and \\(\\tilde{g}^{ij}_{kl}\\) are integrals over the one- and two-body operators and the spin orbitals. The one-body integrals are then given by \\[\n\\tilde{h}^{i}_{j} = h^{\\lfloor{i/2}\\rfloor}_{\\lfloor{j/2}\\rfloor} \\langle \\sigma_i \\vert \\sigma_j  \\rangle\n\\] with the spatial part \\[ h^{k}_{l} =  \\langle k \\rvert h \\lvert l \\rangle \\equiv \\int \\psi_k^*(r) h(r) \\psi_l(r) \\operatorname{d}r. \\] In the same way, the spatial part of the two-body integrals is given by \\[ g^{ij}_{kl} = \\langle i j \\rvert g_{12}  \\lvert k l \\rangle \\equiv \\int \\int \\psi_i^*(r_1) \\psi_j^*(r_2) \\frac{1}{|r_1-r_2|} \\psi_k(r_1) \\psi_l(r_2) \\operatorname{d}r_1 \\operatorname{d}r_2.  \\] Note that there exist three different short notations \\[ \\langle ij\\vert kl \\rangle \\equiv \\left(ik \\vert jl \\right) \\equiv \\left[ ij  \\vert lk \\right]  \\] usually referred to as Dirac (physicist, 1212), Mulliken (chemist, 1122) and openfermion (google, 1221) notations. Depending on the convention used, the meaning of the indices \\(g^{ij}_{kl}\\) changes. This is a bit inconvenient, but we can’t change it anymore. Most quantum chemistry packages (pyscf, psi4) use the Mulliken convention, some quantum computing packages adopted the google convention, and the Dirac convention is often found in articles. In the tequila package we tried to automatize most of it away for user convenience. Here is a small example on how to get the integrals using tequila (with either pyscf or psi4 in the back):\n\nimport tequila as tq\n\ngeometry = \"Be 0.0 0.0 0.0\"\nmol = tq.Molecule(geometry=geometry, basis_set=\"6-31G\")\n\nc,h,g = mol.get_integrals(two_body_oderings=\"mulliken\")\n\nfor most applications, the integrals are however processed automatically in the back.\n\n\n\nLet’s look at first and second quantized Hamiltonians and wavefunctions in an explicit example: The Helium atom (charge \\(N_\\text{He}=2\\) and nuclear coordinate \\(R_\\text{He} = (0,0,0)\\)) in a basis of two spatial orbitals \\(\\left\\{\\psi_0, \\psi_1 \\right\\}\\).\n\n\nFor the neutral electron with 2 electrons, the Hamiltonian is:\n\\[\nH(r_1,r_2) = -\\frac{\\nabla^2}{2} - \\frac{\\nabla^2}{2} - \\frac{2}{\\|r_1\\|} - \\frac{2}{\\|r_2\\|} + \\frac{1}{\\|r_1 - r_2 \\|}  \n\\] and a general two-electron Slater-determinant is written as\n\\[\n\\det\\left(\\phi_k,\\phi_l\\right) = \\frac{1}{\\sqrt{2}} \\left( \\phi_k(r_1) \\phi_l(r_2) - \\phi_l(r_1) \\phi_k(r_2) \\right).\n\\]\nAll possible Slater-determinants in the given basis:\n\nclosed-shell singlets (both electrons in the same spatial orbital):\n\\[\n\\det\\left(\\phi_0 \\phi_1 \\right) = \\frac{1}{\\sqrt{2}}\\psi_0(r_1) \\psi_0(r_1) \\otimes \\left( \\lvert \\downarrow \\uparrow \\rangle - \\lvert \\uparrow \\downarrow \\rangle \\right)\n\\] \\[\n\\det\\left(\\phi_3 \\phi_4\\right) = \\frac{1}{\\sqrt{2}}\\psi_1(r_1) \\psi_1(r_1) \\otimes \\left( \\lvert \\downarrow \\uparrow \\rangle - \\lvert \\uparrow \\downarrow \\rangle \\right)\n\\]\nopen-shell polarized triplets:\n\\[\n\\det\\left(\\phi_1 \\phi_3\\right) = \\left(\\psi_0(r_1) \\psi_1(r_2) + \\psi_1(r_1) \\psi_0(r_2)\\right) \\otimes \\left( \\lvert \\uparrow \\uparrow \\rangle  \\right)\n\\]\n\n\\[\n\\det\\left(\\phi_2 \\phi_4\\right) = \\left(\\psi_0(r_1) \\psi_1(r_2) + \\psi_1(r_1) \\psi_0(r_2)\\right) \\otimes \\left( \\lvert \\downarrow \\downarrow \\rangle  \\right)\n\\]\n\nopen-shell (with broken spin symmetry - recombinable into non-polarized triplet state and one additional singlet state):\n\\[\n\\det\\left(\\phi_0\\phi_2\\right) = \\frac{1}{\\sqrt{2}}\\left(\\phi_0(x_1) \\phi_2(x_2) - \\phi_2(x_1) \\phi_0(x2) \\right)\n\\] \\[\n\\det\\left(\\phi_1\\phi_3\\right) = \\frac{1}{\\sqrt{2}}\\left(\\phi_1(x_1) \\phi_3(x_2) - \\phi_3(x_1) \\phi_1(x2) \\right)\n\\]\n\nA general two-electron wavefunction can then be written as a linear combination of those 6 Determinants (note however, that the different spin-symmetries, i.e. the triplet and the two singlets, usually don’t mix) \\[\n\\Psi(x_1,x_2) = \\sum_{i&lt;j\\in\\left\\{0,1\\right\\}} d_{ij} \\det\\left(\\phi_i\\phi_j\\right)\n\\] Note how this always denotes a two-electron wavefunction. The electron number directly enters the definition of the first quantized Hamiltonian and therefore defines the space onto which the Hamiltonian acts.\nFor numerical procedures it is often necessary to directly express the Hamiltonian in the given basis. Here this would mean to compute all matrix elements \\[\nH_{ij} = \\langle \\det\\left(\\phi_m\\phi_n\\right)\\rvert H \\lvert \\det\\left(\\phi_k\\phi_l\\right) \\rangle.\n\\] In this two electron example this is no problem, the task of computing all matrix elements will however become unfeasible with growing electron number due to the growth of possible determinants. Explicit computation of the Hamiltonian in the given basis is usually only performed within further approximations - e.g. truncated configuration interaction methods that only include slater determinants that differ in a specific number of orbitals from a given reference determinant.\n\n\n\nIn second quantization it is sufficient to compute the one- and two-body integrals given above to define the Hamiltonian. They grow with the fourth power of the basis size rendering the task always feasible.\nA general wavefunction can be constructed from all possible linear combinations of electronic configurations in the given spin-orbital basis - denoted by so called occupation vectors representing which spin orbitals are occupied and not. In this case we have 4 spin orbitals then therefore \\(2^4=16\\) different configurations:\n\nvacuum\n\\[\\lvert 0000 \\rangle\\]\nsingle electron\n\\[\n\\lvert 1000 \\rangle, \\vert 0100 \\rangle, \\lvert 0010 \\rangle, \\lvert 0001\\rangle,\n\\]\ntwo electrons\n\\[\n\\lvert 1100 \\rangle, \\lvert 0011 \\rangle, \\lvert 1001 \\rangle, \\lvert 0110 \\rangle, \\lvert 1010\\rangle, \\lvert 0101 \\rangle,\n\\]\nthree electrons\n\\[\n\\lvert 1110 \\rangle, \\lvert 1101 \\rangle, \\lvert 1011 \\rangle, \\lvert 0111 \\rangle,\n\\]\nfour-electrons\n\\[\n\\lvert 1111 \\rangle.\n\\]\n\nA general wavefunction is then given by\n\\[\\lvert \\Psi \\rangle = \\sum_{k=0}^{16} c_k \\lvert \\text{binary}(k) \\rangle.\\]"
  },
  {
    "objectID": "research/electronic-hamiltonians/index.html#tldr",
    "href": "research/electronic-hamiltonians/index.html#tldr",
    "title": "Electronic Hamiltonians",
    "section": "",
    "text": "First Quantized Formulation:\n\nHamiltonian is directly defined from the nuclear coordinates and charges\n\nSpin and Fermionic anti-symmetry need to be imposed on the wavefunctions\n\nParticle number is fixed\n\nExplicit computation of matrix representation unfeasible without approximations\n\nSecond Quantized Formulation:\n\nNeeds a set of orbitals to be constructed\n\nSpin and Fermionic anti-symmetry included in Hamiltonian\n\nParticle number is not fixed\n\nExplicit construction in finite basis feasible"
  },
  {
    "objectID": "research/electronic-hamiltonians/index.html#first-quantized-formulation",
    "href": "research/electronic-hamiltonians/index.html#first-quantized-formulation",
    "title": "Electronic Hamiltonians",
    "section": "",
    "text": "The word molecule often stands for \\(N_\\text{e}\\) electrons with coordinates \\(r_k\\) moving in a potential created by atomic nuclei - assumed to be fixed point-charges with coordinates \\(R_A\\) and charges \\(N_A\\). The electronic Hamiltonian is then the operator expressing the interactions of the electrons in that potential \\[H =  \\sum_{k}^{N_\\text{e}} h\\left(r_k\\right) + \\sum_{k}^{N_\\text{e}} \\sum_{l&lt;k} g\\left(r_k,r_l\\right) + V_\\text{nn}.\\] We write it three parts and a constant, which are in atomic units:\n\nOne-body interactions: \\[ h(r) = T(r) + V_\\text{ne}(r) \\] including the kinetic energy of the electrons and the Coulombic attraction between electrons and nuclear charges\n\\[T(r) = -\\frac{1}{2} {\\nabla^2_{r}}, \\quad V_{\\text{ne}}(r) = \\sum_{A \\in \\text{nuclei}} \\frac{N_A}{\\|r-R_A\\|}.\\]\n\nTwo-body interactions: the Coulombic repulsion between individual electrons\n\\[g(r_k,r_l) = \\frac{1}{\\| r_k - r_l \\|}\\]\n\nA constant term: Coulombic repulsion between the nuclear charges\n\\[V_\\text{nn} = \\sum_{A&lt;B} \\frac{N_A N_B}{\\|R_A - R_b\\|} \\]\nwhich is just a constant for a given molecular structure.\n\nWith this, we have fully defined it, and the lowest eigenvalue of this differential operator gives the corresponding ground state energy. To ensure that the ground state describes a multi-electron system, we must impose restrictions on the wavefunction - Fermions have a spin and anti-symmetric permutation symmetry.\n\n\nAs we are describing electrons, they need to obey fermionic antisymmetry. In first quantization (or real-space formulation), the Hamiltonian does not have that property included, so without restrictions on the wavefunctions, it only describes \\(N_\\text{e}\\) negatively charged point-particles without any permutation symmetries or spin.\nWe can add spin conveniently by defining a single-electron wavefunction as a so called spin-orbital: A three-dimensional function \\(\\psi(r) \\in \\mathcal{L}^2(\\mathbb{R}^3)\\), describing the electron in spatial space, augmented with a spin-state \\[\\lvert\\sigma\\rangle \\in \\text{Span}\\left\\{\\lvert \\uparrow \\rangle, \\lvert \\downarrow \\rangle\\right\\} \\equiv \\mathbb{C}^2.\\] If the set of spatial orbitals \\(\\psi_k\\) forms a complete basis in \\(\\mathcal{L}^2(\\mathbb{R}^3)\\), we have an exact description of the electron. A convenient notation is to express the spin component as a function of a spin-coordinate \\(s\\left\\{-1,1\\right\\}\\) and combine spin coordinate \\(s\\) and spatial coordinate \\(r\\) to \\(x=(r,s)\\). In a given set of \\(M\\) spatial orbital, an arbitrary one electron wavefunction can then be expressed as \\[\n\\Psi(x) = \\sum_k^{2M} c_k \\phi(x) = \\sum_{l}^{M} \\psi_{l}(r)\\otimes \\left( c_{2l}\\lvert \\uparrow \\rangle + c_{2l+1} \\lvert \\downarrow \\rangle \\right)\n\\] with the spin-orbitals defined as \\[\n\\phi_k = \\psi_{\\lfloor{i/2}\\rfloor} \\otimes \\lvert \\sigma(k) \\rangle,\\; \\sigma_k=\\begin{cases} \\lvert \\uparrow \\rangle,\\; k \\text{ is even}  \\\\  \\lvert \\uparrow \\rangle,\\; k \\text{ is odd}  \\end{cases}.  \n\\] Many electron functions can then be constructed as linear combinations of anti-symmetric products of single electron functions (so called Slater-Determinants). \\[\n\\Psi\\left(x_1, \\dots, x_{N_\\text{e}}\\right) = \\sum_{m} d_m \\det\\left(\\phi_{m_1},\\dots, \\phi_{m_{N_\\text{e}}}\\right) \\\n\\]"
  },
  {
    "objectID": "research/electronic-hamiltonians/index.html#second-quantization",
    "href": "research/electronic-hamiltonians/index.html#second-quantization",
    "title": "Electronic Hamiltonians",
    "section": "",
    "text": "Using second quantized language, we can significantly simplify the treatment of electron spin and anti-symmetry with the help of abstract field operators \\(\\hat{\\phi}^\\dagger(x)\\) (\\(\\hat{\\phi}(x)\\)) that create (or annihilate) electrons at spin-position \\(x\\). With them, we can formaly write the electronic Hamiltonian as \\[H = \\int \\hat{\\phi}^\\dagger(x) h(x) \\hat{\\phi}(x) \\operatorname{x}x + \\int \\int \\hat{\\phi}^\\dagger(x)\\hat{\\phi}^\\dagger(y) g(x,y) \\hat{\\phi}(x)\\hat{\\phi}(y) \\operatorname{d}x\\operatorname{d}y+ V_\\text{nn}.\\] The wavefunction is now only required to carry information about electron occupancies at all points in space. When acting on the wavefunction, the one-body part of the operator is first annihilating an electron at point \\(x\\). If no electron is present, this will lead to an energy contribution of zero and otherwise invoke \\(h(x)\\), followed by the restoration of the electron by the creation operator. The two-body part acts in the same way and the integrals ensure that we probe all points in space. In practice, this is unfeasible, and it is convenient to introduce a finite basis in the form of spin orbitals to expand the field operators as \\[\\hat{\\phi}(x) = \\sum_k \\phi(x)_k a_k, \\] leading to the more prominent form of the second quantized Hamiltonian \\[\nH = \\sum_{ij} \\tilde{h}^i{j}a^\\dagger_i a_j \\sum_{ijkl} \\tilde{g}^{ij}_{kl} a^\\dagger_i a^\\dagger_j a_l a_k + V_\\text{nn}.\n\\] The new discretized operators \\(a^\\dagger_k\\) (\\(a_k\\)) are now creating (annihilating) an electron in the spin orbital \\(\\phi_k\\) and the tensors \\(\\tilde{h}^{i}_{j}\\) and \\(\\tilde{g}^{ij}_{kl}\\) are integrals over the one- and two-body operators and the spin orbitals. The one-body integrals are then given by \\[\n\\tilde{h}^{i}_{j} = h^{\\lfloor{i/2}\\rfloor}_{\\lfloor{j/2}\\rfloor} \\langle \\sigma_i \\vert \\sigma_j  \\rangle\n\\] with the spatial part \\[ h^{k}_{l} =  \\langle k \\rvert h \\lvert l \\rangle \\equiv \\int \\psi_k^*(r) h(r) \\psi_l(r) \\operatorname{d}r. \\] In the same way, the spatial part of the two-body integrals is given by \\[ g^{ij}_{kl} = \\langle i j \\rvert g_{12}  \\lvert k l \\rangle \\equiv \\int \\int \\psi_i^*(r_1) \\psi_j^*(r_2) \\frac{1}{|r_1-r_2|} \\psi_k(r_1) \\psi_l(r_2) \\operatorname{d}r_1 \\operatorname{d}r_2.  \\] Note that there exist three different short notations \\[ \\langle ij\\vert kl \\rangle \\equiv \\left(ik \\vert jl \\right) \\equiv \\left[ ij  \\vert lk \\right]  \\] usually referred to as Dirac (physicist, 1212), Mulliken (chemist, 1122) and openfermion (google, 1221) notations. Depending on the convention used, the meaning of the indices \\(g^{ij}_{kl}\\) changes. This is a bit inconvenient, but we can’t change it anymore. Most quantum chemistry packages (pyscf, psi4) use the Mulliken convention, some quantum computing packages adopted the google convention, and the Dirac convention is often found in articles. In the tequila package we tried to automatize most of it away for user convenience. Here is a small example on how to get the integrals using tequila (with either pyscf or psi4 in the back):\n\nimport tequila as tq\n\ngeometry = \"Be 0.0 0.0 0.0\"\nmol = tq.Molecule(geometry=geometry, basis_set=\"6-31G\")\n\nc,h,g = mol.get_integrals(two_body_oderings=\"mulliken\")\n\nfor most applications, the integrals are however processed automatically in the back."
  },
  {
    "objectID": "research/electronic-hamiltonians/index.html#example-and-comparison",
    "href": "research/electronic-hamiltonians/index.html#example-and-comparison",
    "title": "Electronic Hamiltonians",
    "section": "",
    "text": "Let’s look at first and second quantized Hamiltonians and wavefunctions in an explicit example: The Helium atom (charge \\(N_\\text{He}=2\\) and nuclear coordinate \\(R_\\text{He} = (0,0,0)\\)) in a basis of two spatial orbitals \\(\\left\\{\\psi_0, \\psi_1 \\right\\}\\).\n\n\nFor the neutral electron with 2 electrons, the Hamiltonian is:\n\\[\nH(r_1,r_2) = -\\frac{\\nabla^2}{2} - \\frac{\\nabla^2}{2} - \\frac{2}{\\|r_1\\|} - \\frac{2}{\\|r_2\\|} + \\frac{1}{\\|r_1 - r_2 \\|}  \n\\] and a general two-electron Slater-determinant is written as\n\\[\n\\det\\left(\\phi_k,\\phi_l\\right) = \\frac{1}{\\sqrt{2}} \\left( \\phi_k(r_1) \\phi_l(r_2) - \\phi_l(r_1) \\phi_k(r_2) \\right).\n\\]\nAll possible Slater-determinants in the given basis:\n\nclosed-shell singlets (both electrons in the same spatial orbital):\n\\[\n\\det\\left(\\phi_0 \\phi_1 \\right) = \\frac{1}{\\sqrt{2}}\\psi_0(r_1) \\psi_0(r_1) \\otimes \\left( \\lvert \\downarrow \\uparrow \\rangle - \\lvert \\uparrow \\downarrow \\rangle \\right)\n\\] \\[\n\\det\\left(\\phi_3 \\phi_4\\right) = \\frac{1}{\\sqrt{2}}\\psi_1(r_1) \\psi_1(r_1) \\otimes \\left( \\lvert \\downarrow \\uparrow \\rangle - \\lvert \\uparrow \\downarrow \\rangle \\right)\n\\]\nopen-shell polarized triplets:\n\\[\n\\det\\left(\\phi_1 \\phi_3\\right) = \\left(\\psi_0(r_1) \\psi_1(r_2) + \\psi_1(r_1) \\psi_0(r_2)\\right) \\otimes \\left( \\lvert \\uparrow \\uparrow \\rangle  \\right)\n\\]\n\n\\[\n\\det\\left(\\phi_2 \\phi_4\\right) = \\left(\\psi_0(r_1) \\psi_1(r_2) + \\psi_1(r_1) \\psi_0(r_2)\\right) \\otimes \\left( \\lvert \\downarrow \\downarrow \\rangle  \\right)\n\\]\n\nopen-shell (with broken spin symmetry - recombinable into non-polarized triplet state and one additional singlet state):\n\\[\n\\det\\left(\\phi_0\\phi_2\\right) = \\frac{1}{\\sqrt{2}}\\left(\\phi_0(x_1) \\phi_2(x_2) - \\phi_2(x_1) \\phi_0(x2) \\right)\n\\] \\[\n\\det\\left(\\phi_1\\phi_3\\right) = \\frac{1}{\\sqrt{2}}\\left(\\phi_1(x_1) \\phi_3(x_2) - \\phi_3(x_1) \\phi_1(x2) \\right)\n\\]\n\nA general two-electron wavefunction can then be written as a linear combination of those 6 Determinants (note however, that the different spin-symmetries, i.e. the triplet and the two singlets, usually don’t mix) \\[\n\\Psi(x_1,x_2) = \\sum_{i&lt;j\\in\\left\\{0,1\\right\\}} d_{ij} \\det\\left(\\phi_i\\phi_j\\right)\n\\] Note how this always denotes a two-electron wavefunction. The electron number directly enters the definition of the first quantized Hamiltonian and therefore defines the space onto which the Hamiltonian acts.\nFor numerical procedures it is often necessary to directly express the Hamiltonian in the given basis. Here this would mean to compute all matrix elements \\[\nH_{ij} = \\langle \\det\\left(\\phi_m\\phi_n\\right)\\rvert H \\lvert \\det\\left(\\phi_k\\phi_l\\right) \\rangle.\n\\] In this two electron example this is no problem, the task of computing all matrix elements will however become unfeasible with growing electron number due to the growth of possible determinants. Explicit computation of the Hamiltonian in the given basis is usually only performed within further approximations - e.g. truncated configuration interaction methods that only include slater determinants that differ in a specific number of orbitals from a given reference determinant.\n\n\n\nIn second quantization it is sufficient to compute the one- and two-body integrals given above to define the Hamiltonian. They grow with the fourth power of the basis size rendering the task always feasible.\nA general wavefunction can be constructed from all possible linear combinations of electronic configurations in the given spin-orbital basis - denoted by so called occupation vectors representing which spin orbitals are occupied and not. In this case we have 4 spin orbitals then therefore \\(2^4=16\\) different configurations:\n\nvacuum\n\\[\\lvert 0000 \\rangle\\]\nsingle electron\n\\[\n\\lvert 1000 \\rangle, \\vert 0100 \\rangle, \\lvert 0010 \\rangle, \\lvert 0001\\rangle,\n\\]\ntwo electrons\n\\[\n\\lvert 1100 \\rangle, \\lvert 0011 \\rangle, \\lvert 1001 \\rangle, \\lvert 0110 \\rangle, \\lvert 1010\\rangle, \\lvert 0101 \\rangle,\n\\]\nthree electrons\n\\[\n\\lvert 1110 \\rangle, \\lvert 1101 \\rangle, \\lvert 1011 \\rangle, \\lvert 0111 \\rangle,\n\\]\nfour-electrons\n\\[\n\\lvert 1111 \\rangle.\n\\]\n\nA general wavefunction is then given by\n\\[\\lvert \\Psi \\rangle = \\sum_{k=0}^{16} c_k \\lvert \\text{binary}(k) \\rangle.\\]"
  },
  {
    "objectID": "research/exvqe/Eigensolver.html",
    "href": "research/exvqe/Eigensolver.html",
    "title": "Excited State Methods",
    "section": "",
    "text": "Introduction and Ansatz\nIn this work we discuss an Eigensolver, which aims to find the ground state of a given Electronic Hamiltonian. To briefly recap: A Hamiltonian itself describes the possible energies of a physical system, including both the kinetic and potential energy of that system and is represented by a matrix. If we know the Hamiltonian, we can gain information about the physical states of the system. In the covered example, the Hamiltonian takes the following form\n\\[ 1.5  - 0.5 \\cdot (Z_1 - Z_0 + Z_0 \\cdot Z_1 + X_1 - Z_0 \\cdot X_1)\\]\n\n\nCode\n\n#| code-fold: True\nimport tequila as tq\nimport numpy as np\nH = 1.5-0.5*(tq.paulis.Z(1)-tq.paulis.Z(0)+tq.paulis.Z(0)*tq.paulis.Z(1)+ tq.paulis.X(1)-tq.paulis.Z(0)*tq.paulis.X(1))\nv, vv = np.linalg.eigh(H.to_matrix())\nprint(\"Eigenvalues: \", v)\n\n\nEigenvalues:  [0. 1. 2. 3.]\n\n\nAn Ansatz is the parameterized quantum circuit, which, in our case, we are going to define as follows:\n\na = tq.Variable(\"a\")\nU = tq.gates.Ry(angle=(a)*np.pi,target=0)\nU+= tq.gates.CNOT(0,1)\nU+= tq.gates.Ry(angle=(a/2)*np.pi, target=1)\n\n\n\n\n\nCircuit\n\n\n\nAt this point we need to take into consideration, that Ansatz errors may occur, since we perceive the Ansatz as an educated guess.\nBy computing the Eigenvalues beforehand, we were able to match the circuit on smooth values ​​at the angles 0,1,2 and 3. It should also be noted that in the following only values ​​in the interval [0,3] are considered. Therefore, values ​​outside the interval are mapped back to the interval by applying modulo 4.\nOur circuit consists of two qubits, hence we are able to have four Eigenvalues \\(\\psi_{k}\\). Furthermore, we know that every state has its expectation value. Since we can regard the Hamiltonian as a Hermition Operator we can write it as follows:\n\\[H\\ket{\\psi_{guess}} =  E_{guess}\\ket{\\psi_{guess}}\\] We assume \\(E_{guess}\\) to represent the expectation value of the given Hamiltonian. Furthermore we know, that \\(E_{guess}\\) is a minimum under the precondition that it approximates to a specific Eigenstate.\nOur goal is to minimize the expectation value of the energy, such that no other energy is greater than \\(E_{guess}\\). Therefore we will have a solid approximation of the ground state energy. In our case the sought Eigenvalue is the angle of the minimum Eigenstate, which corresponds to the desired ground state energy. It can be found by applying a minimization method to the expectation value \\(E_{guess}\\).\nIn the following graphic we can observe the plotted, expected energy depending on the angle a. The Eigenstates are those energies corresponding to the already calculated Eigenvalues for our circuit.\n\n\n\n\nHamiltonian\n\n\n\nThe circles in this graph represent the sought Eigenstates of \\(H\\). Therefore, the corresponding angles are the targeted Eigenvalues. It is essential to point out that the minima and maxima of this graph are potential Eigenvalues, but they don´t neccessarily need to be. Only, when applying different excited state methods the real Eigenvalues will emerge. In this example we know the values. However, without prior knowledge, we are forced to assume certain starting values. Therefore, on one hand, it is possible to get some potential Eigenvalues at first, which will later turn out to be irrelevant. On the other hand, saddle points might turn into minima or maxima when applying the minimization on multiple, consecutively executed excited state methods.\n\n\nExcited state methods\nAfter having introduced the main goal and concept, we should clarify the implementation and usage of different excited state methods. We assume, that the Hamiltonian and our computed circuit \\(U\\), depending on the angles \\(\\phi\\), is already given in the beginning. These methods particularly differ in the way of defining the expectation value, with the given Hamiltonian and circuit. Also, their superposition and the parametrization of our given circuit play a crucial role.\n\nFolded Spectrum Method\nFirst we discuss the popular Folded Spectrum method. In general, it is formulated like this: \\(\\langle (H-\\mu)^2\\rangle_{U(\\phi)}\\) with \\(\\mu\\) being the estimated value. Here it is initially assigned to 1, since this is the first excited state in our case.\n\n\ndef expectation_value_folded_spectrum(H,U, constant):\n    return tq.ExpectationValue(H=(H-constant)**2, U=U)\n\n\n\n\n\nFolded Spectrum Method\n\n\n\nThis method modifies the Hamiltonian, by shifting its energy values. If done properly, this concludes in the targeted excited state becoming the lowest energy state in the plotted graph. Here, the local maximum at angle 2.0 and local minimum at angle 3.0 are being shifted to their initial energy value + 1.0. Simultaneously, every other value is being shifted to the initial energy value - 1.0.\n\n\nApproximation Method\nThe next method is the approximation method, which differs in the way of applying the expectation value. This looks as follows: \\((\\langle H\\rangle_{U(\\phi)}-\\mu)^2\\).\n\nAt first we compute the expectation value of our Hamiltonian. As next step we approximate the difference to the constant \\(\\mu\\). This constant is an assumption of what we think might be the target Eigenstate. Therefore we are minimizing the difference between the output energy of our Hamiltonian and the target energy \\(\\mu\\).\n\ndef expectation_value_approximation(H,U, constant):\n    return (tq.ExpectationValue(H=H, U=U)-constant)**2\n\n\n\n\n\nApproximation Method\n\n\n\nSince we initialized \\(\\mu\\) to 1, we mapped every energy value from 1.0 to 0.0. Thus, all affected points become the new local minima. This is caused by minimizing the difference between our initial energy values and the target energy \\(\\mu\\) and \\((1.0 - 1.0)^2 = 0.0\\). The same procedure is also applied to any other value of our energy graph. In the end, the approximation affects the energy graph similarly to the Folded Spectrum method, since it alters the initial Hamiltonian by distorting or smoothing the spectrum. Here, the energies of the local maxima are being shifted to their initial energy value + \\(\\mu\\) as well. In contrast to the Folded Spectrum method, this graph now mainly differs in the amount of local minimas, since the Hamiltonian had two energies of value 1.0 before.\n\n\nProjection Method\nOur last presented strategy is the Projection method, which is also known as the Variational Quantum Deflation (VQD) algorithm.\nThis method uses a variational technique to find the k Eigenvalues of the given Hamiltonian. With this approach we are also able to find excited states by minimizing an objective function, which represents the disparity between the measured expectation values and the true ground state energy. This strategy penalizes overlapping states over several applications of the excited state methods.\n\nTo find the k-th lowest excited state, VQD requires us to find the lowest k - 1 states first. We then minimize the energy, while constraining the state \\(|\\psi(\\phi)\\rangle\\) to be orthogonal to the lower known states \\(|\\psi(\\phi_{i})\\rangle\\) :\n\\[\\begin{align}\n\\underset{\\phi}{\\text{minimize}} & & \\langle H\\rangle_{\\psi(\\phi)} & \\\\\n\\text{subject to } & & \\langle\\psi(\\phi_{i})~|~\\psi(\\phi)\\rangle = 0, & \\forall i \\in \\{ 0,\\ldots k - 1\\}\n\\end{align}\\]\n\nThe constraint is given by the orthonormality of the eigenbasis of \\(H\\). We can write the optimization problem as the cost function:\n\n\n\\(C(\\phi) = \\langle\\psi(\\phi)|H|\\psi(\\phi)\\rangle + \\sum_{i = 0}^{k - 1}\\lambda_{i}|\\langle\\psi(\\phi_{i})|\\psi(\\phi)\\rangle|^{2}\\)\n\n\nwhere \\(\\lambda_{i}\\) are the penalty weights. By optimizing over this cost function we are able to compute the excited state energies.\n\nWe define \\(\\left( U_{i} \\right)_{i \\in \\{ 0,\\ldots k - 1\\}}\\) to be the circuits preparing the i-th state and U as the circuit preparing \\(|\\psi(\\phi)\\rangle\\).\nThe second term describes the squares of overlaps of the current circuit U, generally known as the fidelity.\nReferring to this paper, we get the following conversion:\n\n\\(|\\braket{\\psi(\\phi _{i}) | \\psi(\\phi)}|^2\\)\n\\(= \\braket{\\psi(\\phi _{i}) | \\psi(\\phi)} \\braket{\\psi(\\phi) | \\psi(\\phi _{i})}\\)\n\\(= \\bra{\\psi(\\phi _{i})}U_{i}\\ket{0} \\bra{0}U_{i}^{\\textdagger}\\ket{\\psi(\\phi _{i})}\\)\n\\(=\\langle P_0\\rangle_{U_{i}^{\\textdagger} U(\\phi)}\\)\nThe expectation values of the projected Hamiltonian can then be described as sum of expectation values of the original Hamiltonian and projectors of the current circuit U:\n\n\\(\\langle H\\rangle_{U(\\phi)} + \\sum_{i=0}^{k-1} \\lambda_{i} \\langle P_0\\rangle_{U_{i}^{\\textdagger} U(\\phi)}\\).\nThereby we create a sequential strategy in which the ground state is first being calculated and then projected outwards. Therefore, a new possible ground state is able to emerge from the projection.\n\ndef expectation_value_orthogonality_constraint(H,U, circuit_list, constant_list):\n    E = tq.ExpectationValue(H=H, U=U)\n    if (len(circuit_list) != len(constant_list)):\n        raise ValueError(f\"Circuit_list and constant_list have different lengths. len(circuit_list): '{len(circuit_list)}', len(constant_list): '{len(constant_list)}'\")\n    list_length = len(circuit_list)\n    for l in range(list_length):\n        if (circuit_list[l].extract_variables() == None):\n            raise ValueError(f\"Circuit_list contains unparametrized elements\")\n    U_list = []\n    for i in range(0, list_length):\n1        U_k = U + circuit_list[i].dagger()\n        P_k = 1\n        for k in U_k.qubits:\n2            P_k*= tq.paulis.Qp(k)\n        E_k = tq.ExpectationValue(H=P_k, U=U_k)\n        U_list.append(constant_list[i]*E_k)\n    return E + sum(U_list)\n\n\n1\n\nThe circuit list consists of the circuits preparing the i-th state. The addition is not an actual addition, but the concatenation operator for quantum circuits.\n\n2\n\nThis is the 0-projector.\n\n\n\n\n\n\n\n\nVariational Quantum Deflation Algorithm\n\n\n\nIn our case, we already know that the energy is 0 at angle 3.0 (so we reached a possible ground state). Hence, we set \\(\\lambda_{i}\\) to 10, so that the energy at angle 3.0 will become greater than any other energy in this graph.\nWhile the Folded Spectrum and Approximation methods are generally easier to implement, they may have limitations in terms of accuracy and efficiency. The Projection method offers a higher accuracy and ensures orthogonality between the excited states, but it can be more complex and computationally demanding, particularly for larger systems. Therefore it is a good idea to experiment with different methods to determine the most suitable one for a given application.\n\n\n\nOptimization process\nNow, having discussed all possible methods, we´re going to test different ways of concatenating those to find the ground state energy with regard to the optimal Eigenstates and the corresponding Eigenvalues. The whole process of finding the ground state energy functions similarly to the popular gradient descent, since we work stepwise through our generated graph and create a new minimum at each iteration. For this purpose Tequila provides its own method for the entire optimization process, the minimize-function. This method takes the expectation value as well as a dictionary of additional parameters, such as the initial values, as input.\n\n\nCode\n\n#| code-fold: true\ndef minimization(E, dict_of_parameters=None):\n    if dict_of_parameters is None:\n        dict_of_parameters = {}\n    if not isinstance(dict_of_parameters, dict):\n        raise TypeError(f\"dict expected, got '{type(dict_of_parameters).__name__}'\")\n    dict_of_parameters.setdefault(\"method\", \"BFGS\")\n    dict_of_parameters.setdefault(\"initial_values\", \"random\")\n    return tq.minimize(E, **dict_of_parameters)\n\n\nBelow you can first see all neccessary functions, including the excited state methods, for the minimization as well as for plotting. Here, when calling the main function, we pass the following input parameters: Hamiltonian H, curcuit U, variables/angles as dictionary, a variance threshold (optional) and list of ordered excited state methods (optional) eg. [“A”,“P”,“F”] for Approximation, Projection, Folded Spectrum. In this implementation, the final minimum, found after applying the optimization on a certain excited state method, will become the starting point of the minimization of the next method. Also, we use the previous result energy as expectation value for the input of the current minimization.\nAfter the optimization process was completed successfully, you are able to trace the derivation process of the ground state energies in the corresponding 1D or 2D diagrams.\n\n\nCode\nimport tequila as tq\nfrom tequila import numpy as np\nfrom numpy import pi\nimport matplotlib.pyplot as plt\nimport matplotlib.pyplot as plt\n\ndef main(H,U, variables, variance_threshold=1.e-8, list=None):\n    '''This is the main part of this programm, where the optimization strategies \"folded spectrum\", \"approximation\" and \"projection\"\n    are being tested and plotted.\n    Input:  Hamiltonian H\n            curcuit U\n            variables/angles as dictionary\n            variance threshold (optional)\n            list of ordered functions (optional) eg. [\"A\",\"P\",\"F\"] for Approximation, Projection, Folded Spectrum\n    Output: 1D or 2D graphics showing the optimization process as well as the Eigenvalues/Eigenstates of H'''\n    \n    eigenvalues, vv = np.linalg.eigh(H.to_matrix())\n    oneDimensional = True\n    if (len(variables) == 2):\n        oneDimensional=False\n        variables = {\"a\": -1, \"b\": -0.5}\n    else:\n        variables = {\"a\": -1}\n\n    circuit_list = []\n    constant_list = []\n    list_length = 4\n    constant = 1\n    \n    for l in range(list_length):\n        circuit_list.append(U.map_variables(variables))\n        constant_list.append(constant)\n        constant += 1\n    if list==None:\n        # First Projection, then Approximation, then Folded Spectrum\n        E = eigensolver.expectation_value_orthogonality_constraint(H,U, circuit_list, constant_list)\n        E_optimized = eigensolver.minimization(E, {\"method\":\"BFGS\"})\n        eigensolver.plotting_preparation(E, E_optimized, \"Energy with orthogonality constraint\", eigenvalues, oneDimensional)\n        if eigensolver.proof_eigenstate(H,U, variables, variance_threshold):\n                print(\"The optimal eigenstate with a variance &lt;= \", variance_threshold, \"was found.\")\n        variables = E_optimized.variables\n        mu = tq.simulate(tq.ExpectationValue(H=H, U=U), variables=variables)\n        E_AFS = eigensolver.expectation_value_approximation(H,U, mu)\n        E_AFS_optimized = eigensolver.minimization(E_AFS, {\"method\":\"BFGS\", \"initial_values\":variables})\n        eigensolver.plotting_preparation(E_AFS, E_AFS_optimized, \"Energy with approximation\", eigenvalues, oneDimensional)\n        if eigensolver.proof_eigenstate(H,U, variables, variance_threshold):\n                print(\"The optimal eigenstate with a variance &lt;= \", variance_threshold, \"was found.\")\n        variables = E_AFS_optimized.variables\n        mu = tq.simulate(tq.ExpectationValue(H=H, U=U), variables=variables)\n        E_FS = eigensolver.expectation_value_folded_spectrum(H,U, mu)\n        E_FS_optimized = eigensolver.minimization(E_FS, {\"method\":\"BFGS\", \"initial_values\":variables})\n        eigensolver.plotting_preparation(E_FS, E_FS_optimized, \"Energy with folded spectrum\", eigenvalues, oneDimensional)\n        if eigensolver.proof_eigenstate(H,U, variables, variance_threshold):\n                print(\"The optimal eigenstate with a variance &lt;= \", variance_threshold, \"was found.\")\n    else:\n        \n        for l in list:\n            if (l.isalpha()==False or len(l)!= 1):\n                raise ValueError('An elemet of the list is not one letter')\n            if (l == list[0]):\n                mu = 1\n            else:\n                variables = E_optimized.variables\n                mu = tq.simulate(tq.ExpectationValue(H=H, U=U), variables=variables)\n\n            if (l == \"A\"):\n                E = eigensolver.expectation_value_approximation(H,U, mu)\n                if (l == list[0]):\n                    E_optimized = eigensolver.minimization(E, {\"method\":\"BFGS\"})\n                else: \n                    E_optimized = eigensolver.minimization(E, {\"method\":\"BFGS\", \"initial_values\":variables})\n                eigensolver.plotting_preparation(E, E_optimized, \"Energy with approximation\", eigenvalues, oneDimensional)\n                if eigensolver.proof_eigenstate(H,U, variables, variance_threshold):\n                        print(\"The optimal eigenstate with a variance &lt;= \", variance_threshold, \"was found.\")\n            elif (l == \"P\"):\n                E = eigensolver.expectation_value_orthogonality_constraint(H,U, circuit_list, constant_list)\n                if (l == list[0]):\n                    E_optimized = eigensolver.minimization(E, {\"method\":\"BFGS\"})\n                else: \n                    E_optimized = eigensolver.minimization(E, {\"method\":\"BFGS\", \"initial_values\":variables})\n                eigensolver.plotting_preparation(E, E_optimized, \"Energy with orthogonality constraint\", eigenvalues, oneDimensional)\n                if eigensolver.proof_eigenstate(H,U, variables, variance_threshold):\n                        print(\"The optimal eigenstate with a variance &lt;= \", variance_threshold, \"was found.\")\n            elif (l == \"F\"):\n                E = eigensolver.expectation_value_folded_spectrum(H,U, mu)\n                if (l == list[0]):\n                    E_optimized = eigensolver.minimization(E, {\"method\":\"BFGS\"})\n                else: \n                    E_optimized = eigensolver.minimization(E, {\"method\":\"BFGS\", \"initial_values\":variables})\n                eigensolver.plotting_preparation(E, E_optimized, \"Energy with folded spectrum\", eigenvalues, oneDimensional)\n                if eigensolver.proof_eigenstate(H,U, variables, variance_threshold):\n                        print(\"The optimal eigenstate with a variance &lt;= \", variance_threshold, \"was found.\")\n                \n            else:\n                raise ValueError('An elemet of the list is not letter \"A\", \"P\" or \"F\"')\n\n#----------------General functions------------\nclass eigensolver:\n    \n    def expectation_value_folded_spectrum(H,U, constant):\n        return tq.ExpectationValue(H=(H-constant)**2, U=U)\n    \n    def expectation_value_approximation(H,U, constant):\n        return (tq.ExpectationValue(H=H, U=U)-constant)**2\n    \n    def expectation_value_orthogonality_constraint(H,U, circuit_list, constant_list):\n        E = tq.ExpectationValue(H=H, U=U)\n        if (len(circuit_list) != len(constant_list)):\n            raise ValueError(f\"Circuit_list and constant_list have different lengths. len(circuit_list): '{len(circuit_list)}', len(constant_list): '{len(constant_list)}'\")\n        list_length = len(circuit_list)\n        for l in range(list_length):\n            if (circuit_list[l].extract_variables() == None):\n                raise ValueError(f\"Circuit_list contains unparametrized elements\")\n        U_list = []\n        for i in range(0, list_length):\n            U_k = U + circuit_list[i].dagger()\n            P_k = 1\n            for k in U_k.qubits:\n                P_k*= tq.paulis.Qp(k)\n            E_k = tq.ExpectationValue(H=P_k, U=U_k)\n            U_list.append(constant_list[i]*E_k)\n        return E + sum(U_list)\n\n    def minimization(E, dict_of_parameters=None):\n        if dict_of_parameters is None:\n            dict_of_parameters = {}\n        if not isinstance(dict_of_parameters, dict):\n            raise TypeError(f\"dict expected, got '{type(dict_of_parameters).__name__}'\")\n        dict_of_parameters.setdefault(\"method\", \"BFGS\")\n        dict_of_parameters.setdefault(\"initial_values\", \"random\")\n        return tq.minimize(E, **dict_of_parameters)\n    \n    \n    def proof_eigenstate(H, U, variables, variance_threshold=1.e-4):\n        V = ((tq.ExpectationValue(H=H, U=U))  **2 - tq.ExpectationValue(H=H**2, U=U)).apply(abs)\n        V = tq.simulate(V, variables)\n        return V &lt;= variance_threshold\n    \n    def get_optimization_energies(result):\n        return result.history.energies_calls\n\n    def get_optimization_angles(result, eigenvalues):\n        mod = len(eigenvalues)\n        angle_dots = [{k:v % mod for k,v in x.items()} for x in result.history.angles_calls]\n        angles_np = np.array([list(i.values()) for i in angle_dots])\n        return angles_np\n    \n    def compile_E_values1D(fE, angle_range):\n        return [fE({\"a\":v}) for v in angle_range]\n    \n    def compile_E_values2D(fE, angle_range):\n        fE_result = []\n        for v in angle_range:\n            for w in angle_range:\n                fE_result.append(fE({\"a\":v, \"b\":w}))\n                return fE_result\n\n    def compile_dE_values1D(fdE, angle_range):\n        return [fdE({\"a\":v}) for v in angle_range]\n    \n    def compile_dE_values2D(fdE, angle_range):\n        fE_result = []\n        for v in angle_range:\n            for w in angle_range:\n                fE_result.append(fdE({\"a\":v, \"b\":w}))\n                return fE_result\n    \n    # calculating min and max values of range of all energies (E or dE) for plotting. Returning array [y_min, y_max]\n    def min_max_y_value(E, values_E, values_dE, energy_dots):\n        min_max = []\n        all_energy_values = []\n        for v in values_E:\n            all_energy_values.append(v)\n        for v in values_dE:\n            all_energy_values.append(v)\n        y_min = energy_dots[0]\n        y_max = energy_dots[0]\n        for energy in all_energy_values:\n            if energy &lt; y_min:\n                y_min = energy\n            if energy &gt; y_max:\n                y_max = energy\n        min_max.append(y_min)\n        min_max.append(y_max)\n        return min_max\n    \n    def plotting1D(aprox_name, angle_range, angles_np, values_E, values_dE, fE, energy_np, start_dot_E, end_dot_E, start_dot_angle, end_dot_angle, angles_of_eigenvalues, y_min, y_max):\n        \n        plt.plot(angle_range, values_E, label= str(aprox_name))\n        \n        plt.plot(angle_range, values_dE, label= 'Derivation of the ' + str(aprox_name))\n        plt.legend([str(aprox_name), 'Derivation of the ' + str(aprox_name)])\n        plt.scatter(angles_np, energy_np)\n        \n        for a in angles_of_eigenvalues:\n            plt.plot(a, fE({\"a\":a}), \"o\",mfc = '#4CAF50',ms = 10,mec = 'r')\n            plt.vlines(x=a, colors='purple', ymin=y_min-5, ymax=y_max+5, ls='--', lw=2, label='Eigenvalues')\n        plt.annotate('Starting point',\n        ha = 'center', va = 'bottom',\n        xytext = (start_dot_angle , start_dot_E - 2),\n        xy = (start_dot_angle, start_dot_E),\n        arrowprops = { 'facecolor' : 'black', 'shrink' : 0.5, 'width' : 0.5, 'headwidth' : 10})\n        plt.annotate('End point',\n        ha = 'center', va = 'bottom',\n        xytext = (end_dot_angle, end_dot_E + 2),\n        xy = (end_dot_angle, end_dot_E),\n        arrowprops = { 'facecolor' : 'black', 'shrink' : 0.5, 'width' : 0.5, 'headwidth' : 10})\n        \n        plt.xlabel(\"Eigenvalues\")\n        plt.ylabel(\"Eigenstates\")\n        plt.show()\n\n    def plotting2D(aprox_name, start_dot_E, end_dot_E, start_dot_angle, end_dot_angle, fE, angles_of_eigenvalues):\n        X=np.linspace(0.0, 2.0*np.pi,25)\n        Y=X\n        Z = np.zeros([25,25])\n        for i,x in enumerate(X):\n            for j,y in enumerate(Y):\n                Z[i,j]= fE({\"a\":x, \"b\":y})\n        X, Y = np.meshgrid(X, Y)\n        ax = plt.figure().add_subplot(projection='3d')\n        ax.plot_surface(X, Y, Z, edgecolor='royalblue', lw=0.5, rstride=8, cstride=8,\n                        alpha=0.3, shade=True)\n        \n        for a in angles_of_eigenvalues:\n            for b in angles_of_eigenvalues:\n                if (a == angles_of_eigenvalues[0] and b == angles_of_eigenvalues[0]):\n                    ax.plot(a,b, fE({\"a\":a, \"b\":b}), \"o\",mfc = '#4CAF50',ms = 10,mec = 'r',label=\"Possible Eigenvalues\")\n                else:\n                    ax.plot(a,b, fE({\"a\":a, \"b\":b}), \"o\",mfc = '#4CAF50',ms = 10,mec = 'r')\n\n        if (fE({\"a\":end_dot_angle[0], \"b\":end_dot_angle[1]}) == fE({\"a\":start_dot_angle[0], \"b\":start_dot_angle[1]})):\n            ax.scatter3D(start_dot_angle[0], start_dot_angle[1],fE({\"a\":start_dot_angle[0], \"b\":start_dot_angle[1]}),color='red', s=25, label=\"Starting point equals End point\")\n        else:\n            ax.scatter3D(end_dot_angle[0], end_dot_angle[1],fE({\"a\":end_dot_angle[0], \"b\":end_dot_angle[1]}),color='black', s=25, label=\"Starting point\")\n            ax.scatter3D(start_dot_angle[0], start_dot_angle[1],fE({\"a\":start_dot_angle[0], \"b\":start_dot_angle[1]}),color='red', s=25, label=\"End point\")\n\n\n        ax.set_xlabel('Angle \"a\"')\n        ax.set_ylabel('Angle \"b\"')\n        ax.set_zlabel('Energy')\n        ax.legend()\n        ax.set_title(str(aprox_name))\n        plt.show()\n        \n    def plotting2D_chemistry(aprox_name, fE):\n        X=np.linspace(0.0, 2.0*np.pi,25)\n        Y=X\n        Z = np.zeros([25,25])\n        for i,x in enumerate(X):\n            for j,y in enumerate(Y):\n                Z[i,j]= fE({\"a\":x, \"b\":y})\n        X, Y = np.meshgrid(X, Y)\n        ax = plt.figure().add_subplot(projection='3d')\n        ax.plot_surface(X, Y, Z, edgecolor='royalblue', lw=0.5, rstride=8, cstride=8,\n                        alpha=0.3, shade=True)\n\n        ax.set_xlabel('Angle \"a\"')\n        ax.set_ylabel('Angle \"b\"')\n        ax.set_zlabel('Energy')\n        ax.legend()\n        ax.set_title(str(aprox_name))\n        plt.show()\n\n    def plotting_preparation(E, result, aprox_name, eigenvalues, oneDimensional=True):\n        angle_range = (np.linspace(0,4,100))\n        angles_of_eigenvalues = eigenvalues\n\n        fE = tq.compile(E)\n        \n        if oneDimensional:\n            values_E = eigensolver.compile_E_values1D(fE, angle_range)\n            dE = tq.grad(E, \"a\")\n        else:\n            values_E = eigensolver.compile_E_values2D(fE, angle_range)\n            dE = tq.grad(E, \"a\", \"b\")\n        fdE = tq.compile(dE)\n        if oneDimensional:\n            values_dE = eigensolver.compile_dE_values1D(fdE, angle_range)\n        else:\n            values_dE = eigensolver.compile_dE_values2D(fdE, angle_range)\n        \n        angles = eigensolver.get_optimization_angles(result, eigenvalues)\n        energy_dots = eigensolver.get_optimization_energies(result)\n        \n        if oneDimensional:\n            angles_np = []\n            for xs in angles:\n                for x in xs:\n                    angles_np.append(x)\n        else:\n            angles_np = angles\n\n        y_min = eigensolver.min_max_y_value(E, values_E, values_dE, energy_dots)[0]\n        y_max = eigensolver.min_max_y_value(E, values_E, values_dE, energy_dots)[1]\n        \n        start_dot_E = energy_dots[0]\n        end_dot_E = energy_dots[len(energy_dots)-1]\n        start_dot_angle = angles_np[0]\n        end_dot_angle = angles_np[len(energy_dots)-1]\n        \n        if oneDimensional:\n            eigensolver.plotting1D(aprox_name, angle_range, angles_np, values_E, values_dE, fE, energy_dots, start_dot_E, end_dot_E, start_dot_angle, end_dot_angle, angles_of_eigenvalues, y_min, y_max)\n        else:\n            eigensolver.plotting2D(aprox_name, start_dot_E, end_dot_E, start_dot_angle, end_dot_angle, fE, angles_of_eigenvalues)\n    \n\n    def min_max_energy_and_angle(fE,values_E, angle_range):\n        min_E = min(np.array(values_E))\n\n        for a in angle_range:\n            if (fE({\"a\":a}) == min_E):\n                min_angle = a\n                break\n        max_E = max(np.array(values_E))\n        for a in angle_range:\n            if (fE({\"a\":a}) == max_E):\n                max_angle = a\n                break\n        return min_E, max_E, min_angle, max_angle\n    \n# Given Hamiltonian H\nH = 1.5-0.5*(tq.paulis.Z(1)-tq.paulis.Z(0)+tq.paulis.Z(0)*tq.paulis.Z(1)+tq.paulis.X(1)-tq.paulis.Z(0)*tq.paulis.X(1))\n\n# ------------1D model--------------\na = tq.Variable(\"a\")\nvariables = {\"a\": -1}\nU = tq.gates.Ry(angle=(a)*np.pi,target=0)\nU+= tq.gates.CNOT(0,1)\nU+= tq.gates.Ry(angle=(a/2)*np.pi, target=1)\nmain(H, U, variables, variance_threshold=1.e-8, list=[\"A\", \"F\", \"P\", \"F\"])\n\n# ------------2D model--------------\na = tq.Variable(\"a\")\nb = tq.Variable(\"b\")\n\nvariables = {\"a\":1.0, \"b\":0.7}\nU = tq.gates.Ry(angle=(a)*np.pi,target=0)\nU+= tq.gates.CNOT(0,1)\nU+= tq.gates.Ry(angle=(b)*np.pi, target=1)\nmain(H, U, variables, variance_threshold=1.e-8, list=[\"A\", \"F\", \"P\", \"F\"])\n\n\nLet´s take a look at an exemplary 1D optimization using the approximation and subsequent folded spectrum method.\n\n\n\n\n\n\nFigure 1: Energy graph\n\n\n\n\n\n\n\nFigure 2: Optimization process\n\n\n\n\n\n\nOptimization with the Approximation method\n\n\n\nFirst, we start our optimization at Angle 2.15. The blue graph shows us the energy curve after applying the approximation method, the orange one the corresponding gradient. Analyzing this, there is a decline in energy at the starting point, as the orange graph is below the 0 energy level. According to the optimization procedure, we now the curve until we reach a local minimum (obervable along the blue dots). In our case, we reach the local minimum after 7 steps at angle 3.7.\n\n\n\n\n\n\nFigure 3: Energy graph\n\n\n\n\n\n\n\nFigure 4: Optimization process\n\n\n\n\n\n\nOptimization with the Folded Spectrum method\n\n\n\nThis is now the starting point of the Folded Spectrum method. The graph has changed here: We can see that the gradient at the start is much lower than the one of the approximation curve at this angle. This means that there is a point that is even lower than the one previously assumed. Therefore, we carry out the same procedure as before: we continue until we arrive at a local minimum again. Since our optimization steps run in the right direction and in this case we always consider the angles modulo 4, we end up on the left side again. The apparent minimum at 0.0 is initially skipped in step 2 and since then we have been oscillating around the local minimum. In the last step, however, we return there and remain there. Now we have found an actual Eigenstate at angle 0.0.\n\n\n\n\n\n\nFigure 5: Approximation\n\n\n\n\n\n\n\nFigure 6: Projection\n\n\n\n\n\n\n\nFigure 7: Folded Spectrum\n\n\n\n\n\n\nOptimization with 2D models\n\n\n\nThe same procedure was carried out in these 2D models. First with the approximation method, then the projection method and at the end the folded spectrum method. It is not initially clear that the end point of the first method is the starting point of the second method. In fact, this is the case, only the curves have changed accordingly when the projection method has been applied. In the second diagram it is already clear that we have reached a possible Eigenvalue. This is evident in the last excited state method, since the optimization point does not move, but stagnates at the minimum.\n\n\nChemistry example\nSince we have now familiarized ourselves with the excited state methods, we can apply them to a Hamiltonian and circuit from a real chemistry model. In the following code, this model is defined based on two angles and its circuit is similar to the one from this paper (appendix). We then are able to apply our known methods and plot them using 2D models.\n\n\nCode\n\n\n#| code-fold: true\n#| output: false\n\ngeometry1 = \"H 1.5 0.0 0.0\\nH 0.0 0.0 0.0\\nH 1.5 0.0 1.5\\nH 0.0 0.0 1.5\"\nmol = tq.Molecule(geometry=geometry1, basis_set=\"sto-3g\").use_native_orbitals()\nU = tq.gates.X([0,1,2,3])\na = tq.Variable(\"a\")#*pi\nb = tq.Variable(\"b\")#*pi\nUC1 = mol.UC(0,2, a) + mol.UC(1,3, a)\nUR1 = mol.UR(0,2,pi/2) + mol.UR(1,3,pi/2)\nUR2 = mol.UR(0,1,pi/2) + mol.UR(2,3,pi/2)\nUC2 = mol.UC(0,1, b) + mol.UC(2,3, b)\n\n1circuit_chemistry = U + UC1 + UR1.dagger() + UR2 + UC2 + UR2.dagger()\nH = mol.make_hamiltonian()\n\nf_E= tq.compile(tq.ExpectationValue(H=H, U=circuit_chemistry))\n\neigensolver.plotting2D_chemistry(\"Original Hamiltonian\", f_E)\n\n\n\n1\n\nThis is the given circuit, which consists of two rotations and two correlations. Thus, we are particularly able to analize the correlators and study their behaviour.\n\n\n\n\n/var/folders/pw/yjpw_zz56nv7wh1drxkrky_40000gn/T/ipykernel_84822/888881687.py:263: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n  ax.legend()\n\n\n\n\n\n\n\n\n\nCircuit of chemistry model\n\n\n\n\n\n\n\nHamiltonian of chemistry model\n\n\n\n\n\nConclusion\nIn summary, this tutorial has provided an overview of quantum Eigensolvers, a powerful tool for finding the Eigenvalues of quantum systems. We have discussed the key concepts, such as Hamiltonians, expectation values, and excited state methods. The Tequila library was used to implement these concepts and demonstrate their application. Building on this, we have gained some direct optimization protocols by testing different concatenations of our excited state methods, including the optimization after each of them.\nDespite this, we need to take some potential errors, such as hardware errors, which can cause noise, computational errors or Ansatz errors into consideration. Moreover the accuracy and efficiency of our Eigensolver depends highly on the choice of our given excited state methods. Of course, there are also other possibilities of concatenations, since we have a lot of freedom in selecting the suitable parameters and order of our introduced techniques.\nOverall, by addressing these challenges and leveraging future advancements, quantum Eigensolvers have the potential to become a valuable tool for solving complex problems in quantum computing and beyond.\n\nFurther Reading\n\nhttps://pubs.acs.org/doi/epdf/10.1021/acs.jctc.3c01378?ref=article_openPDF\nhttps://www.sciencedirect.com/science/article/pii/S0370157322003118?ref=pdf_download&fr=RR-2&rr=8d2f7feaefd39247\nhttps://arxiv.org/pdf/1805.08138"
  },
  {
    "objectID": "Contribution/Contribution.html",
    "href": "Contribution/Contribution.html",
    "title": "Contribution",
    "section": "",
    "text": "If you find any bugs or inconveniences in tequila please don’t be shy and let us know. You can do so either by raising an issue on github or contact us directly.\n\nHow can you upload your own tutorial or research page?\n\nHow to install Quarto\nFor installing and using Quarto correctly, please take a look at some helpful links:\n\nInstallation: https://quarto.org/docs/get-started/\nQuarto basics: https://quarto.org/docs/get-started/hello/rstudio.html\n\n\n\nHow to set up the environment and compile the blog\n\nClone from source\nCreate a conda environment with the name ‘BlogQa’ (concrete: opt/anaconda3/envs/BlogQA/bin/python3):\n\n\nconda create -n BlogQA python=3.9\nconda env list\npython -m ipykernel install –user –name=BlogQA\nconda install ipykernel\nconda activate BlogQA\n\n\nInstall the dependencies as well as everything needed regarding Jupyter and the BlogQA Kernel: In particular these are the following ones:\n\n\nconda create -n BlogQA python=3.9\npip install pyyaml\npip install nbformat\npip install nbclient\npip install numpy\npip install scipy\npip install matplotlib\npip install tequila-basic\npip install qulacs\npip install pyscf\n\nAlso, these packages are necessary for the Documentation: * pip install sphinx * pip install sphinxcontrib * pip install sphinxcontrib-programoutput * pip install sphinx-rtd-theme\n\nPreview with “quarto preview”\n\n\n\nHow to add your contribution\nFirst, please make sure that only ipynb-files or quarto-files are allowed as tutorials or research pages for the website. Within these, the following HTML parameters can be placed in a separate markdown at the top, before the actual content begins:\n\ntitle: \"Any titel\"\nauthor: \"Your full name\"\ndate: \"yyyy-mm-dd\"\ncategories: [code]\nimage: \"Preview_Image.png\"\nimage-width: \"1cm\"\nimage-height: \"1cm\"\nformat:\n    html:\n        code-fold: false\n        eval: true\njupyter: blogqa\n\nBegin and end this section with three hyphens (—)\n\n\nHow to submit\n\nMake a fork of tequila to your own github account.\nCheckout the devel branch and make sure it is up to date with the main github repository.\nCreate and checkout a new branch from devel via git branch pr-my-branch-name followed by git checkout pr-my-branch-name. By typing git branch afterwards you can check which branch is currently checked out on your computer.\nNavigate to the tutorial/ researches folder and create your own subfolder, which you name with the tutorial/research name. This subfolder should include your ipynb/quarto-file (as well as other necessary files, such as png-files for importing images).\nIntroduce changes to the code and commit them with git.\nPush the changes to your github account.\nLog into github and create a pull request to the main github repository. The pull request should be directed to the devel branch (but we can also change that afterwards).\n\nIf you would like to include a preview image with your contribution, feel free to use our preview image template. It is available as a .png file (for non-macOS users) and a Keynote file (for macOS users). You can find the template in the main folder alongside the other files.\nIf you plan to introduce major changes to the base library it can be beneficial to contact us first. This way we might be able to avoid conflicts before they arise.\nIf you used tequila for your research, feel free to include your algorithms here, either by integrating it into the core libraries or by demonstrating it with a notebook in the tutorials section. If you let us know about it, we will also add your research article in the list of research projects that use tequila (see the github repos README)."
  },
  {
    "objectID": "Tutorials/quanti-gin/quanti-gin_summary.html",
    "href": "Tutorials/quanti-gin/quanti-gin_summary.html",
    "title": "quanti-gin: Benchmarking VQE optimization methods against the SPA",
    "section": "",
    "text": "Working in the quantum domain, we often lack good tools to compare and benchmark against state-of-the-art optimization methods. Benchmarking, requires large amounts of reference data for statistically significant comparisons, so we introduce a configurable data generator which can be used to create large sets of hydrogenic test systems and their corresponding energies, with a focus on allowing quick and easy plug-in testing of custom optimization methods. In the following, we introduce the data generator quanti-gin (available at: https://github.com/nylser/quanti-gin) and illustrate how to use and customize it."
  },
  {
    "objectID": "Tutorials/quanti-gin/quanti-gin_summary.html#introduction",
    "href": "Tutorials/quanti-gin/quanti-gin_summary.html#introduction",
    "title": "quanti-gin: Benchmarking VQE optimization methods against the SPA",
    "section": "",
    "text": "Working in the quantum domain, we often lack good tools to compare and benchmark against state-of-the-art optimization methods. Benchmarking, requires large amounts of reference data for statistically significant comparisons, so we introduce a configurable data generator which can be used to create large sets of hydrogenic test systems and their corresponding energies, with a focus on allowing quick and easy plug-in testing of custom optimization methods. In the following, we introduce the data generator quanti-gin (available at: https://github.com/nylser/quanti-gin) and illustrate how to use and customize it."
  },
  {
    "objectID": "Tutorials/quanti-gin/quanti-gin_summary.html#installation",
    "href": "Tutorials/quanti-gin/quanti-gin_summary.html#installation",
    "title": "quanti-gin: Benchmarking VQE optimization methods against the SPA",
    "section": "Installation",
    "text": "Installation\n\nPrerequisites for the quanti-gin\nquanti-gin can easily be installed via pip install quanti-gin in your preferred python environment or with your preferred python package manager. This will install the data generator and its dependencies."
  },
  {
    "objectID": "Tutorials/quanti-gin/quanti-gin_summary.html#data-generator-visualization",
    "href": "Tutorials/quanti-gin/quanti-gin_summary.html#data-generator-visualization",
    "title": "quanti-gin: Benchmarking VQE optimization methods against the SPA",
    "section": "Data generator & visualization",
    "text": "Data generator & visualization\nFor the generation and analysis of data, we introduce: 1) a parameterizable data generator for the synthesis of data, and 2) a jupyter notebook that can be used to inspect the features & quality of the data, as well as 3) an experimental machine learning application notebook.\n\nData generator\nWe define DataGenerator class and associated functions to generate and optimize examples of hydrogen molecules using the Tequila package. Here is a summary of the main functionalities:\n\nData Classes and Initialization:\n\nJob Dataclass: A data structure that stores information about a DataGenerator job, including geometry, edges, guesses, coordinates, and distances.\n\nGeometry and Coordinate Generation:\n\ngenerate_geometry_string: Creates a string representation of molecular geometry from coordinates.\ngenerate_coordinates: Generates a set of coordinates for atoms in a molecule, ensuring a minimum distance between atoms to avoid generating infeasible data.\n\nOptimization and Reference Computation:\n\nrun_optimization: Optimizes the molecular geometry molecule and calculates energies.\n\nJob Generation and Execution:\n\ngenerate_jobs: Creates a list of molecular jobs with varying geometries, edges, and guesses.\nexecute_job: Runs the optimization for a single job.\nexecute_jobs: Runs the optimization for a list of jobs, displaying progress.\n\nResult Processing:\n\ncreate_result_df: Generates a DataFrame from job results, including optimized energies, exact energies, and coordinates.\n\nMain Execution:\n\nThe main function parses command-line arguments, sets up job generation and execution, evaluates results, and saves the final data to a CSV file.\n\n\nThe code is structured to generate molecular geometries, perform quantum chemistry calculations, and analyze results efficiently, leveraging parallel processing and progress tracking with tqdm.\n\n\nUsage Instructions\n\nBasic Command to Generate Jobs and Results: Run the data generator for one of the built in methods with the following command-line arguments:\npython -m quanti_gin [--method {fci,spa}] [--output &lt;output_file&gt;] &lt;number_of_atoms&gt; &lt;number_of_jobs&gt;\n\n--method {fci,spa} (optional): Specify the method to choose one of the built-in methods.\n--output &lt;output_file&gt; (optional): Specify the name of the output file to save results.\n&lt;number_of_atoms&gt;: Number of atoms in the molecules (must be an even number).\n&lt;number_of_jobs&gt;: Number of molecular jobs to generate and process.\n\nExample:\npython -m quanti_gin 4 100 --output results.csv\nThis will run the data generator with 100 jobs for a molecule with 4 atoms, using the default method (SPA) and save the results to results.csv.\nCompare with custom methods and FCI To compare multiple built-in methods with a custom method, use the following command:\npython -m quanti_gin --compare-to fci,spa --custom_method &lt;path_to_method.py&gt; &lt;number_of_atoms&gt; &lt;number_of_jobs&gt;\n\n--compare-to fci,spa: Specify the methods to compare with the custom method.\n--custom_method &lt;path_to_method.py&gt;: Specify the path to the custom method file.\n&lt;number_of_atoms&gt;: Number of atoms in the molecules (must be an even number).\n&lt;number_of_jobs&gt;: Number of molecular jobs to generate and process.\n\nThis will run the data generator with 100 jobs for a molecule with 4 atoms, every job will be calculated with the custom method, the FCI method, and the SPA method.\n\n\n\nCreating a custom optimization method for comparison\nAs an example, we can create a custom optimization method that uses a different optimization algorithm or circuit structure. To do this, we can create a new python file with the custom optimization method and can then pass it to the --custom_method argument.\nFirst, we initialize our Hamiltonian and Ansatz circuit. Make note that we are only getting the molecule as an input, which is a QuantumChemistryBase object from tequila. Using the molecule, one can easily get the geometry, basis set, and other information needed for the optimization, so there is no need to use tequila for the optimization itself.\nimport tequila as tq\nfrom tequila.quantumchemistry import QuantumChemistryBase\n\n    def run_optimization(mol: QuantumChemistryBase, *args, **kwargs):\n        H = mol.make_hamiltonian()\n\n        U = tq.gates.QCircuit()\nNow, for building the circuit, we populate the circuit U, using a structural approach:\n\n        # structure of the ansatz:\n        # 1. Ry rotations on all qubits\n1        for i in range(len(coordinates) * 2):\n            U += tq.gates.Ry(target=i, angle=\"a\" + str(i))\n        depth = 2\n        # 2. Entangling layer =&gt; Alternating: CNOTs on even and odd qubits\n        # 3. Ry rotations on all qubits\n2        for d in range(depth):\n            offset = d % 2\n            iterations = len(coordinates) * 2\n3            for i in range(0, iterations - 1 - offset, 2):\n                U += tq.gates.CNOT(control=offset + i, target=offset + i + 1)\n4            for i in range(iterations):\n                U += tq.gates.Ry(target=i, angle=f\"b{d}_{i}\")\n\n1\n\nAdd an Ry rotation gate for all qubits we need to represent the atoms of the molecule.\n\n2\n\nRepeat while configured depth is not reached:\n\n3\n\nAdd entangling layer: CNOTs alternating on even/odd qubits per iteration\n\n4\n\nAdd Ry rotation on all qubits\n\n\nThe resulting circuit with the configured depth = 2 for 4 H-atoms is illustrated in Figure 1.\n\n\n\nFigure 1: Structural Circuit with depth 2\n\n\n1    E = tq.ExpectationValue(H=H, U=U)\n2    result = tq.minimize(E, silent=True)\n    return {\n        \"energy\": result.energy,\n}\n\n1\n\nCreate an expectation value E with our previously obtained Hamiltonian H for the molecule, and constructed circuit U.\n\n2\n\nrun the minimization algorithm for that expectation value via tequila.\n\n\nThe only requirement for the custom method is that it returns a dictionary in the form:\n{\n    \"energy\": result.energy,\n}\nThis concludes the introduction of custom methods for the quanti-gin DataGenerator. If you desire to customize more or different aspects, you can use a subclass of the DataGenerator class and override the methods you want to change. Looking at the source code of quanti-gin https://github.com/nylser/quanti-gin always is a good reference and starting point."
  },
  {
    "objectID": "Tutorials/quanti-gin/quanti-gin_summary.html#data-visualization",
    "href": "Tutorials/quanti-gin/quanti-gin_summary.html#data-visualization",
    "title": "quanti-gin: Benchmarking VQE optimization methods against the SPA",
    "section": "Data Visualization",
    "text": "Data Visualization\nThe quanti-gin repository includes a Jupter Notebook for visualizations and analysis of the generated data.\n\nData Visualization Example\n\n\nCollecting quanti-gin\n  Downloading quanti_gin-2.5.0-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: numpy in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from quanti-gin) (1.26.4)\nRequirement already satisfied: pandas&lt;3.0.0,&gt;=2.2.2 in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from quanti-gin) (2.2.3)\nRequirement already satisfied: tequila-basic&lt;2.0.0,&gt;=1.9.8 in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from quanti-gin) (1.9.9)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from pandas&lt;3.0.0,&gt;=2.2.2-&gt;quanti-gin) (2.9.0.post0)\nRequirement already satisfied: pytz&gt;=2020.1 in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from pandas&lt;3.0.0,&gt;=2.2.2-&gt;quanti-gin) (2025.2)\nRequirement already satisfied: tzdata&gt;=2022.7 in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from pandas&lt;3.0.0,&gt;=2.2.2-&gt;quanti-gin) (2025.2)\nRequirement already satisfied: scipy in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from tequila-basic&lt;2.0.0,&gt;=1.9.8-&gt;quanti-gin) (1.15.2)\nRequirement already satisfied: sympy in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from tequila-basic&lt;2.0.0,&gt;=1.9.8-&gt;quanti-gin) (1.13.3)\nRequirement already satisfied: autograd in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from tequila-basic&lt;2.0.0,&gt;=1.9.8-&gt;quanti-gin) (1.7.0)\nRequirement already satisfied: setuptools in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from tequila-basic&lt;2.0.0,&gt;=1.9.8-&gt;quanti-gin) (78.1.0)\nRequirement already satisfied: pytest in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from tequila-basic&lt;2.0.0,&gt;=1.9.8-&gt;quanti-gin) (8.3.5)\nRequirement already satisfied: openfermion~=1.0 in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from tequila-basic&lt;2.0.0,&gt;=1.9.8-&gt;quanti-gin) (1.7.0)\nRequirement already satisfied: cirq-core in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from openfermion~=1.0-&gt;tequila-basic&lt;2.0.0,&gt;=1.9.8-&gt;quanti-gin) (1.4.1)\nRequirement already satisfied: deprecation in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from openfermion~=1.0-&gt;tequila-basic&lt;2.0.0,&gt;=1.9.8-&gt;quanti-gin) (2.1.0)\nRequirement already satisfied: h5py&gt;=3.10.0 in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from openfermion~=1.0-&gt;tequila-basic&lt;2.0.0,&gt;=1.9.8-&gt;quanti-gin) (3.13.0)\nRequirement already satisfied: networkx in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from openfermion~=1.0-&gt;tequila-basic&lt;2.0.0,&gt;=1.9.8-&gt;quanti-gin) (3.4.2)\nRequirement already satisfied: pubchempy in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from openfermion~=1.0-&gt;tequila-basic&lt;2.0.0,&gt;=1.9.8-&gt;quanti-gin) (1.0.4)\nRequirement already satisfied: requests~=2.32.2 in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from openfermion~=1.0-&gt;tequila-basic&lt;2.0.0,&gt;=1.9.8-&gt;quanti-gin) (2.32.3)\nRequirement already satisfied: six&gt;=1.5 in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas&lt;3.0.0,&gt;=2.2.2-&gt;quanti-gin) (1.17.0)\nRequirement already satisfied: iniconfig in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from pytest-&gt;tequila-basic&lt;2.0.0,&gt;=1.9.8-&gt;quanti-gin) (2.1.0)\nRequirement already satisfied: packaging in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from pytest-&gt;tequila-basic&lt;2.0.0,&gt;=1.9.8-&gt;quanti-gin) (24.2)\nRequirement already satisfied: pluggy&lt;2,&gt;=1.5 in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from pytest-&gt;tequila-basic&lt;2.0.0,&gt;=1.9.8-&gt;quanti-gin) (1.5.0)\nRequirement already satisfied: mpmath&lt;1.4,&gt;=1.1.0 in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from sympy-&gt;tequila-basic&lt;2.0.0,&gt;=1.9.8-&gt;quanti-gin) (1.3.0)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from requests~=2.32.2-&gt;openfermion~=1.0-&gt;tequila-basic&lt;2.0.0,&gt;=1.9.8-&gt;quanti-gin) (3.4.1)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from requests~=2.32.2-&gt;openfermion~=1.0-&gt;tequila-basic&lt;2.0.0,&gt;=1.9.8-&gt;quanti-gin) (3.10)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from requests~=2.32.2-&gt;openfermion~=1.0-&gt;tequila-basic&lt;2.0.0,&gt;=1.9.8-&gt;quanti-gin) (2.3.0)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from requests~=2.32.2-&gt;openfermion~=1.0-&gt;tequila-basic&lt;2.0.0,&gt;=1.9.8-&gt;quanti-gin) (2025.1.31)\nRequirement already satisfied: attrs&gt;=21.3.0 in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from cirq-core-&gt;openfermion~=1.0-&gt;tequila-basic&lt;2.0.0,&gt;=1.9.8-&gt;quanti-gin) (25.3.0)\nRequirement already satisfied: duet&gt;=0.2.8 in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from cirq-core-&gt;openfermion~=1.0-&gt;tequila-basic&lt;2.0.0,&gt;=1.9.8-&gt;quanti-gin) (0.2.9)\nRequirement already satisfied: matplotlib~=3.0 in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from cirq-core-&gt;openfermion~=1.0-&gt;tequila-basic&lt;2.0.0,&gt;=1.9.8-&gt;quanti-gin) (3.10.1)\nRequirement already satisfied: sortedcontainers~=2.0 in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from cirq-core-&gt;openfermion~=1.0-&gt;tequila-basic&lt;2.0.0,&gt;=1.9.8-&gt;quanti-gin) (2.4.0)\nRequirement already satisfied: typing-extensions&gt;=4.2 in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from cirq-core-&gt;openfermion~=1.0-&gt;tequila-basic&lt;2.0.0,&gt;=1.9.8-&gt;quanti-gin) (4.13.1)\nRequirement already satisfied: tqdm in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from cirq-core-&gt;openfermion~=1.0-&gt;tequila-basic&lt;2.0.0,&gt;=1.9.8-&gt;quanti-gin) (4.67.1)\nRequirement already satisfied: contourpy&gt;=1.0.1 in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from matplotlib~=3.0-&gt;cirq-core-&gt;openfermion~=1.0-&gt;tequila-basic&lt;2.0.0,&gt;=1.9.8-&gt;quanti-gin) (1.3.1)\nRequirement already satisfied: cycler&gt;=0.10 in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from matplotlib~=3.0-&gt;cirq-core-&gt;openfermion~=1.0-&gt;tequila-basic&lt;2.0.0,&gt;=1.9.8-&gt;quanti-gin) (0.12.1)\nRequirement already satisfied: fonttools&gt;=4.22.0 in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from matplotlib~=3.0-&gt;cirq-core-&gt;openfermion~=1.0-&gt;tequila-basic&lt;2.0.0,&gt;=1.9.8-&gt;quanti-gin) (4.57.0)\nRequirement already satisfied: kiwisolver&gt;=1.3.1 in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from matplotlib~=3.0-&gt;cirq-core-&gt;openfermion~=1.0-&gt;tequila-basic&lt;2.0.0,&gt;=1.9.8-&gt;quanti-gin) (1.4.8)\nRequirement already satisfied: pillow&gt;=8 in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from matplotlib~=3.0-&gt;cirq-core-&gt;openfermion~=1.0-&gt;tequila-basic&lt;2.0.0,&gt;=1.9.8-&gt;quanti-gin) (11.1.0)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in /usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages (from matplotlib~=3.0-&gt;cirq-core-&gt;openfermion~=1.0-&gt;tequila-basic&lt;2.0.0,&gt;=1.9.8-&gt;quanti-gin) (3.2.3)\nDownloading quanti_gin-2.5.0-py3-none-any.whl (14 kB)\nInstalling collected packages: quanti-gin\nSuccessfully installed quanti-gin-2.5.0\n\n\nIf you just want to visualize the different methods and their results, you can use the following code.\nSetup and load the data:\n\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport random\n\nfrom quanti_gin.shared import (\n    read_data_file,\n)\n\ndata = read_data_file(Path(\"./example_data.csv\"))\n\nNow, data.df contains the data in a pandas DataFrame, which can be used for visualization and analysis. As our example data compares multiple methods against each other, we can group the data by the method and visualize the results.\n\ngrouped_methods = data.df.groupby(\"method\")\nmethod_names = grouped_methods.groups.keys()\n\n# boxplot of custom_energy and fci, and SPA energy\nfig, axes = plt.subplots(\n    1, len(grouped_methods), sharey=True, figsize=(9, 5), layout=\"constrained\"\n)\n\nfig.suptitle(\"Method energies\")\n\nfig.set_figheight(fig.get_figheight())\nfor i, (axis, (method_name, method)) in enumerate(zip(axes, grouped_methods)):\n    axis.boxplot(method.optimized_energy)\n    axis.set_title(method_name)\n\nplt.show()\n\n\n\n\nTo compare all the different methods to each other, we can use this example plot:\n\ncombinations = []\nfor method_a in method_names:\n    combinations.append(\n        [(method_a, method_b) for method_b in method_names if method_a != method_b]\n    )\n\nfor comb_list in combinations:\n    fig, axes = plt.subplots(\n        1, len(method_names) - 1, sharey=True, figsize=(10, 5), layout=\"constrained\"\n    )\n    fig.suptitle(f\"{comb_list[0][0]}\")\n    for plot, (a, b) in zip(axes, comb_list):\n        energy_a = np.array(grouped_methods.get_group(a).optimized_energy)\n        energy_b = np.array(grouped_methods.get_group(b).optimized_energy)\n        error = np.abs(energy_a - energy_b)\n\n        plot.boxplot(abs(energy_a - energy_b), labels=[f\"{a} vs. {b}\"])\n\nplt.show()\n\n/tmp/ipykernel_2536/1747858103.py:17: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n  plot.boxplot(abs(energy_a - energy_b), labels=[f\"{a} vs. {b}\"])\n/tmp/ipykernel_2536/1747858103.py:17: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n  plot.boxplot(abs(energy_a - energy_b), labels=[f\"{a} vs. {b}\"])\n/tmp/ipykernel_2536/1747858103.py:17: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n  plot.boxplot(abs(energy_a - energy_b), labels=[f\"{a} vs. {b}\"])\n/tmp/ipykernel_2536/1747858103.py:17: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n  plot.boxplot(abs(energy_a - energy_b), labels=[f\"{a} vs. {b}\"])\n/tmp/ipykernel_2536/1747858103.py:17: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n  plot.boxplot(abs(energy_a - energy_b), labels=[f\"{a} vs. {b}\"])\n/tmp/ipykernel_2536/1747858103.py:17: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n  plot.boxplot(abs(energy_a - energy_b), labels=[f\"{a} vs. {b}\"])\n\n\n\n\n\n\n\n\n\n\n\nFor more detailed analysis and visualization, you can use the provided Jupyter Notebook in the quanti-gin repository."
  },
  {
    "objectID": "FAQ/FAQ.html",
    "href": "FAQ/FAQ.html",
    "title": "FAQ",
    "section": "",
    "text": "Frequently Asked Questions\n\nIt is recommended to take a look at the BasicUsage notebook before looking at this\n\nimport tequila as tq\nimport numpy\n\n\n\n\nWhich optimization methods can I use?\ntq.show_available_optimizers shows you all installed modules on your systems and the methods which tq.minimize understands. Method names are not case sensitive when passed to tq.minimize.\nIn the end you see which modules are supported and which of them are actually installed on your system.\nThe table with methods and modules will only show you the methods for modules that are currently installed within your environment.\nOf course you can also use tequila objectives for your own optimizers.\nYou don’t need to use the modules here.\n\ntq.show_available_optimizers()\n\navailable methods for optimizer modules found on your system:\nmethod               | optimizer module\n--------------------------\nNELDER-MEAD          | scipy\nCOBYLA               | scipy\nPOWELL               | scipy\nSLSQP                | scipy\nL-BFGS-B             | scipy\nBFGS                 | scipy\nCG                   | scipy\nTNC                  | scipy\nTRUST-KRYLOV         | scipy\nNEWTON-CG            | scipy\nDOGLEG               | scipy\nTRUST-NCG            | scipy\nTRUST-EXACT          | scipy\nTRUST-CONSTR         | scipy\nadam                 | gd\nadagrad              | gd\nadamax               | gd\nnadam                | gd\nsgd                  | gd\nmomentum             | gd\nnesterov             | gd\nrmsprop              | gd\nrmsprop-nesterov     | gd\nspsa                 | gd\ngpyopt-lbfgs         | gpyopt\ngpyopt-direct        | gpyopt\ngpyopt-cma           | gpyopt\nSupported optimizer modules:  ['scipy', 'gpyopt', 'gd']\nInstalled optimizer modules:  ['scipy', 'gd', 'gpyopt']\n\n\n\n\nWhich simulators/Quantum-Backends can I use?\ntq.show_available_simulators shows all simulators/quantum backends which are supported by tequila as well as which are installed within your current environment.\nThe default choice if you don’t specify a backend when for example simulating a tequila objective with tq.simulate is the first entry of the supported backends which is installed on your system.\n\ntq.show_available_simulators()\n\nbackend         | wfn        | sampling   | noise      | installed \n--------------------------------------------------------------------\nqulacs_gpu      | False      | False      | False      | False     \nqulacs          | True       | True       | True       | True      \nqibo            | False      | False      | False      | False     \nqiskit          | False      | False      | False      | False     \ncirq            | False      | False      | False      | False     \npyquil          | True       | True       | True       | True      \nsymbolic        | True       | False      | False      | True      \nqlm             | False      | False      | False      | False     \n\n\n\n\nCan I avoid re-translation/compilation on my objectives/circuits?\nYes, you can. By calling tq.compile instead of tq.simulate. This will give you back a callable objective.\nCheck also the basic usage tutorial notebook\n\nU = tq.gates.H(target=1) + tq.gates.Rx(angle=\"a\", target=0, control=1)\n\n# simulate the wavefunction with different variables\nwfn0 = tq.simulate(U, variables={\"a\": 1.0})\nwfn1 = tq.simulate(U, variables={\"a\": 2.0})\n\nprint(wfn0)\nprint(wfn1)\n\n# the same, but avoiding re-compilation\n# Note that your compiled object is translated to a quantum backend\n# if the backend was not set, tequila it will pick the default which depends\n# on which backends you have installed. You will seee it in the printout of the\n# compiled circuits\ncompiled_U = tq.compile(U)\nwfn0 = compiled_U(variables={\"a\":1.0})\nwfn1 = compiled_U(variables={\"a\":2.0})\n\nprint(\"compiled circuit:\", compiled_U)\nprint(wfn0)\nprint(wfn1)\n\n\n# With Objectives it works in the same way\nH = tq.paulis.Y(0)\nE = tq.ExpectationValue(H=H, U=U)\nobjective = E**2 + 1.0\n\n# simulate the objective with different variables\nresult0 = tq.simulate(objective, variables={\"a\": 1.0})\nresult1 = tq.simulate(objective, variables={\"a\": 2.0})\n\nprint(\"compiled objective:\", objective)\nprint(result0)\nprint(result1)\n\n# compile and then simulate\ncompiled_objective = tq.compile(objective)\nresult0 = compiled_objective(variables={\"a\":1.0})\nresult1 = compiled_objective(variables={\"a\":2.0})\n\nprint(\"compiled objective:\", compiled_objective)\nprint(result0)\nprint(result1)\n\n+0.7071|00&gt; +0.6205|01&gt; -0.3390i|11&gt; \n+0.7071|00&gt; +0.3821|01&gt; -0.5950i|11&gt; \ncompiled circuit: &lt;tequila.simulators.simulator_qulacs.BackendCircuitQulacs object at 0x3075b72e0&gt;\n+0.7071|00&gt; +0.6205|01&gt; -0.3390i|11&gt; \n+0.7071|00&gt; +0.3821|01&gt; -0.5950i|11&gt; \ncompiled objective: Objective with 1 unique expectation values\ntotal measurements = 1\nvariables          = [a]\ntypes              = not compiled\n1.1770183545683928\n1.2067054526079515\ncompiled objective: Objective with 1 unique expectation values\ntotal measurements = 1\nvariables          = [a]\ntypes              = [&lt;class 'tequila.simulators.simulator_qulacs.BackendExpectationValueQulacs'&gt;]\n1.1770183545683928\n1.2067054526079515\n\n\n\n\nHow can I emulate a real quantum computer?\nEmulation is performed similarly to running on real devices. All you need to do is pass down the right string to the ‘device’ keyword. For qiskit, these are the same as for regular backends, but have ‘fake_’ at the beginning; I.E to emulate ‘armonk;, set device=\"fake_armonk\". For PyQuil, this is done by adding’-qvm’ to the end of the chosen string, i.e, ‘Aspen-8’ becomes device=Aspen-8-qvm'. For Cirq, only emulation is currently possible; the only string options for cirq are ‘foxtail’,‘bristlecone’,‘sycamore’, and ‘sycamore23’.\nWhen emulating, a few things about the real device will be mimicked, principally its native gate set and its connectivities. Emulation will NOT include noisy emulation by default; If you want to emulate noise, pass down the keyword noise='device'. Using this option without specifying a device will result in an error.\nBelow, we will emulate pyquil’s Aspen 8, with emulated noise. You need pyquil installed for this to work.\nadditionally: when real backends cannot be accessed, emulation will be attempted, with a warning.\n\nU = tq.gates.Ry(angle=\"a\", target=0)\nH = tq.paulis.X(0)\nE = tq.ExpectationValue(H=H, U=U)\n\n# simulate the square of the expectation value with a specific set of variables\nresult = tq.simulate(E**2, variables={\"a\":1.0}, samples=1000, backend=\"pyquil\")\nprint('sampling from pyquil yielded: ', result)\nresult = tq.simulate(E**2, variables={\"a\":1.0}, samples=1000, backend=\"pyquil\",device='Aspen-8-qvm')\nprint('sampling from pyquil while emulating Aspen-8 yielded: ', result)\nresult = tq.optimizer_scipy.minimize(E**2, initial_values={\"a\":1.0}, samples=1000,\n                                    backend='pyquil', device=\"Aspen-8-qvm\", \n                                    noise='device')\nprint('optimizing while emulating Aspen-8 with noise yielded a best energy of: ', result.energy)\n\nQVMError: Could not communicate with QVM at http://127.0.0.1:5000\n\n\n\n\nCan I compile Objectives into different backends?\nYes you can. Tequila will print a warning if this happens. Warnings can be ignored by filtering them out (see the python warnings documentation)\nIf a compiled circuit is used as input to compile then tequila will re-compile the circuit to the new backend (it it differs from the previous one)\nIf a compiled objective is used as input to compile then tequila will only compile non-compiled expectationvalues into the different backend. Already compiled expectation values will remain untouched\nNote that you need at least two different backends for the following cell to execute.\nJust change the key to whatever you have installed.\n\nbackend1 = \"qulacs\"\nbackend2 = \"cirq\"\n\nU = tq.gates.X(target=[0,1])\nprint(\"Example Circuit: \", U)\ncompiled_1 = tq.compile(U, backend=backend1)\ncompiled_2 = tq.compile(compiled_1, backend=backend2)\nprint(\"Circuit compiled to {} -&gt; \".format(backend1), compiled_1)\nprint(\"Circuit compiled to {} -&gt; \".format(backend1), compiled_1)\n\nH = tq.paulis.X(0)*tq.paulis.Y(1) + tq.paulis.X([0,1])\nprint(\"\\nmake objective with H = \", H)\nobjective = tq.ExpectationValue(H=H, U=U)\ncompiled_1 = tq.compile(objective, backend=backend1)\n\nprint(\"\\nExpectationValues of objective 1:\")\nprint(compiled_1)\n    \nobjective2 = compiled_1 + objective # Its recommended to avoid those hybrids, but in principle it works\n\nprint(\"\\nExpectationValues of partly compiled objective:\")\nprint(objective2)\n    \ncompiled_2 = tq.compile(objective2, backend=backend2)\nprint(\"\\nExpectationValues of hybdrid compiled objective:\")\nprint(compiled_2)\n\n\n\n\n\nHow do I transform Measurements into Hamiltonians?\nWe can not answer this question in general, but we can try to give a small example here.\nAssume you have a quantum circuit with \\(4\\) Qubits and you are measuring Qubit \\(0\\) and \\(2\\). You define your cost function in the following way:\n\\[\nL(AB) = A + B, \\qquad A,B \\in \\left\\{ 0,1 \\right\\}  \n\\]\nmeaning you accumulate the number of ones measured in your circuit.\nThe corresponding expectationvalue would be\n\\[\nL = \\langle \\Psi \\rvert H \\lvert \\Psi \\rangle \\qquad H = 1 - \\frac{1}{2}\\left(Z(0) + Z(1)\\right)\n\\]\nThe Hamiltonian could also be written as\n\\[\nH = 2\\lvert 11 \\rangle \\langle 11 \\rvert + \\lvert 10 \\rangle \\langle 10 \\rvert + \\lvert 01 \\rangle \\langle 01 \\rvert\n\\]\nTequila provides the convenience function tq.gates.Projector to initialize Hamiltonians like that\n\n2*tq.paulis.Projector(\"|11&gt;\") + tq.paulis.Projector(\"|01&gt;\") + tq.paulis.Projector(\"|10&gt;\")\n\nThe projector can also be initialized with more structured QubitWaveFunctions which can itself be initialized from array or string.\nHere are some examples\n\nwfn = tq.QubitWaveFunction.from_string(\"1.0*|00&gt; + 1.0*|11&gt;\")\nwfnx = tq.QubitWaveFunction.from_array(arr=[1.0, 0.0, 0.0, 1.0])\nprint(wfn == wfnx)\nwfn = wfn.normalize()\nprint(wfn)\n\nP = tq.paulis.Projector(wfn=wfn)\nprint(\"P = \", P)\n\nApart from Projector there is also KetBra which intialized more general operators like \\[\n\\lvert \\Psi \\rangle \\langle \\Phi \\rvert\n\\]\nKeep in mind that those are not hermitian.\nBut they can be split up into their hermitian and anti hermitian part where both can then be used as hamiltonians for expectationvalues.\nIf the hermitian = True key is set, the function returns the hermitian version of the operator (which is the same as the hermitian part of the old operator)\n\\[\n\\frac{1}{2}\\left(\\lvert \\Psi \\rangle \\langle \\Phi \\rvert + \\lvert \\Phi \\rangle \\langle \\Psi \\rvert \\right)\n\\]\n\nwfn1 = tq.QubitWaveFunction.from_string(\"1.0*|00&gt; + 1.0*|11&gt;\").normalize()\n\nop = tq.paulis.KetBra(bra=wfn1, ket=\"|00&gt;\")\n\nH1, H2 = op.split()\n\nprint(\"operator=\", op)\nprint(\"hermitian part      = \", H1)\nprint(\"anti-hermitian part =\", H2)\n\nH = tq.paulis.KetBra(bra=wfn1, ket=\"|00&gt;\", hermitian=True)\nprint(\"hermitianized operator = \", H)\n\n\n\nCan I do basic operations on wavefunctions and operators without quantum backends?\nIn principle yes. But keep in mind that tequila was not made for this.\nHowever, some of those operations might come in handy for debugging or small examples.\nYou can not execute circuits without a simulator since they are just abstract data types (no matrices or anything). Tequila has however its own small debug simulator backend = symbolic but there is no reason to use it if you have any other quantum backend installed.\nHamiltonians can be converted to matrices.\nWe give a few examples here\n\nwfn = tq.QubitWaveFunction.from_string(\"1.0*|0&gt; + 1.0*|1&gt;\").normalize()\nH = 1.0/numpy.sqrt(2.0)*(tq.paulis.Z(0) + tq.paulis.X(0))\nwfn2 = wfn.apply_qubitoperator(H).simplify()\n\nprint(\"|wfn&gt;  = \", wfn)\nprint(\"H      = \", H)\nprint(\"H|wfn&gt; = \", wfn2)\n\n\nwfn1 = tq.QubitWaveFunction.from_string(\"1.0*|0&gt; + 1.0*|1&gt;\").normalize()\nwfn2 = tq.QubitWaveFunction.from_string(\"1.0*|0&gt; - 1.0*|1&gt;\").normalize()\nprint(\"&lt;wfn1|wfn2&gt; = \", wfn1.inner(wfn2))\n\n\nH = 1.0/numpy.sqrt(2.0)*(tq.paulis.Z(0) + tq.paulis.X(0))\nprint(H.to_matrix())\n\n\n\nCan I import an Hamiltonian from OpenFermion?\nYes! OpernFermion is currently tequilas backend for Hamiltonians, which makes importing from it straight forward. You just need to wrap the OpenFermion QubitOperator into tequilas QubitHamiltonian.\nWe show a few examples\n\nfrom openfermion import QubitOperator\n\n# get OpenFermion QubitOperator from tequila QubitHamiltonian\nH = tq.paulis.X(0)\nof_operator = H.to_openfermion()\n\nprint(\"{} = {}\".format(type(H), H))\nprint(\"{} = {}\".format(type(of_operator), of_operator))\n\n# init tequila QubitHamiltonian with OpenFermion QubitOperator\nH = tq.QubitHamiltonian.from_openfermion(of_operator)\nprint(\"{} = {}\".format(type(H), H))\n\n# initialization from file os often read in the string form\nof_string = str(of_operator)\ntq_string = str(H)\n\nprint(of_string)\nprint(tq_string)\n\nH = tq.QubitHamiltonian.from_string(string=of_string, openfermion_format=True)\nprint(H)\nH = tq.QubitHamiltonian.from_string(string=tq_string, openfermion_format=False)\nprint(H)\n\n\n\nCan I compile into a regular function instead of one which takes dictionaries?\nNot recommended but yes. The order of the function arguments is the order you get from extract_variables\n\nU = tq.gates.Ry(angle=\"a\", target=0)\nU += tq.gates.X(power = \"b\", target=1)\nH = tq.QubitHamiltonian.from_string(\"X(0)Z(1)\")\nE = tq.ExpectationValue(H=H, U=U)\n\nf = tq.compile_to_function(E)\n\nprint(\"order is : \", E.extract_variables())\nprint(f(0.5, 1.0))\nprint(tq.simulate(E, variables={\"a\":0.5, \"b\":1.0}))\n\nIf you also want to fix the samples and other entries to your compiled objective you can build wrappers\n\ndef mywrapper(compiled_obj, samples):\n    return lambda *x: compiled_obj(*x, samples=samples)\n\nwrapped = mywrapper(f, samples=100)\n\n# don't expect same results, since samples are taken individually\nprint(wrapped(1.0, 0.5)) # always takes 100 samples\nprint(f(1.0, 0.5, samples=100)) # samples need to be given\nprint(f(1.0, 0.5, samples=1000)) # but sampling rate can be changed\nprint(f(1.0, 0.5)) # you can go back to full simulation which you cannot with the wrapped function\n\n\n\nHow do numerical gradients work?\nYes this is possible by passing for example gradient={'method':'2-point', 'stepsize': 1.e-4} to the tq.minimize function.\nThe default is a central 2-point derivative stencil where h is the stepsize: \\[\\displaystyle\n\\frac{\\partial f}{\\partial a} = \\frac{f(a+\\frac{h}{2}) - f(a-\\frac{h}{2})} {h}\n\\]\nOther methods are: 2-point-forward: Forward derivative stencil:\n\\[\\displaystyle\n\\frac{\\partial f}{\\partial a} = \\frac{f(a+h) - f(a)} {h}\n\\]\n2-point-backward: Backward derivative stencil:\n\\[\\displaystyle\n\\frac{\\partial f}{\\partial a} = \\frac{f(a) - f(a-h)} {h}\n\\]\nYou can also use your own numerical derivative stencil by passing a callable function as method.\nThe function should have the signature which is given in the example below.\nHere is an example:\n\nimport tequila as tq\n# form a simple example objective\nH = tq.paulis.X(0)\nU = tq.gates.Ry(angle=\"a\", target=0)\nE = tq.ExpectationValue(U=U, H=H)\n\n# make it more interesting by using analytical gradients for the objective\n# and numerical gradients to optimize it\n\nobjective = tq.grad(E, 'a')**2 # integer multiples of pi/2 are minima\n\n# start from the same point in all examples\ninitial_values = {'a': 2.3}\n\n\n# optimize with analytical derivatives\nresult = tq.minimize(objective=objective, method=\"bfgs\", initial_values=initial_values)\n#result.history.plot(\"energies\")\n#result.history.plot(\"gradients\")\n\n# optimize with 2-point stencil\nresult = tq.minimize(objective=E, method=\"bfgs\", gradient={'method': '2-point', 'stepsize':1.e-4}, initial_values=initial_values)\n#result.history.plot(\"energies\")\n#result.history.plot(\"gradients\")\n\n# optimize with custom stencil\n# here this is the same as the default\nimport copy\ndef mymethod(obj, angles, key, step, *args, **kwargs):\n    left = copy.deepcopy(angles)\n    left[key] += step / 2\n    right = copy.deepcopy(angles)\n    right[key] -= step / 2\n    return 1.0 / step * (obj(left, *args, **kwargs) - obj(right, *args, **kwargs))\n\nresult = tq.minimize(objective=E, method=\"bfgs\", gradient={'method': mymethod, 'stepsize':1.e-4}, initial_values=initial_values)\n#result.history.plot(\"energies\")\n#result.history.plot(\"gradients\")\n\n# optimize with a scipy method and use scipys 2-point\n# the scipy protocol will have more function evaluations and less gradient evaluations for some methods\n# the stepsize in scipy has to be passed with the `method_options` dictionary\n# with the keyword `eps`\nresult = tq.minimize(objective=E, method=\"bfgs\", gradient='2-point', method_options={'eps':1.e-4}, initial_values=initial_values)\n#result.history.plot(\"energies\")\n\n\n\n\nCan I use the numerical gradient protocols from SciPy?\nYes you can for all scipy methods by passing gradient='2-point' to tq.minimize.\nSee the scipy documentation for the stepsize and more options which can be passed with method_options dictionary where the key for the stepsize is usually eps. Note that not all scipy methods support numerical gradients, but you can always fall back to tequilas numerical gradients. See the previous cell for an example."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tequila Tutorials",
    "section": "",
    "text": "Tequila is an abstraction framework for (variational) quantum algorithms. It operates on abstract data structures allowing the formulation, combination, automatic differentiation and optimization of generalized objectives. Tequila can execute the underlying quantum expectation values on state of the art simulators as well as on real quantum devices.\nThis website contains some hands-on examples using tequila. A good starting point from a very fundamental tutorial is here.\nThe main sections of this website are:\n\na wide collection of tutorials for getting to know tequila’s basic functionalities and general usage\na collection of more specific tutorials regarding research\na page with frequently asked questions regarding various aspects and usage of tequila FAQ\n\n\nContribute\nTequila is free and open source. You’re welcome to contribute if you have ideas to improve the library. The standard way to contribute is via pull-requests or issues on github. For larger projects it might be useful to let us know in advance what you are planning.\n\n\nInfluences\nThe design of tequilas API was inspired by madness. Agnostic backend handling and forcing differentiability was inspired by pennylane."
  },
  {
    "objectID": "research/gaussian_convolution/index.html",
    "href": "research/gaussian_convolution/index.html",
    "title": "Building a Quantum Circuit for Gaussian Convolutions",
    "section": "",
    "text": "This post shows how to use Tequila to implement a quantum circuit which performs a Gaussian convolution.\nThe first chapter will give an overview over the structure that the circuit will have, and divide it into smaller subproblems which can be implemented separately. These implementations will be described in the next chapters, and combined into the final circuit at the end.\n\n\nA Gaussian Convolution has an impulse response that is a Gaussian function \\(g(x) = a \\cdot \\exp\\left(-||x - b||_2^2 / c \\right)\\), so when applied to a function \\(f: \\mathbb{R}^d \\to \\mathbb{R}^d\\), it yields a new function \\[ (f * g)(i) = \\int_{\\mathbb{R}^d} f(j) \\cdot g(i - j) dj \\]\nNote that \\(g\\) is separable, so even if we are interested in high-dimensional functions, it is sufficient to consider the one-dimensional case for now. We can then run the one-dimensional implementation multiple times on separate qubits to get a multi-dimensional implementation.\nTo implement this on a quantum computer, we want a circuit that instead of a function \\(f\\) takes a state \\(\\ket{\\psi} = \\sum_{k = 0}^{N - 1} \\alpha_i \\ket{i}\\) on \\(n\\) qubits with \\(N = 2^n\\), and outputs the state \\[ U \\ket{\\psi}\n= \\ket{\\psi} * g\n= z \\cdot \\sum_{i = 0}^{N - 1} \\left(\\sum_{j = 0}^{N - 1} \\alpha_j \\cdot g(i - j)\\right) \\ket{i} \\] for some normalization factor \\(z\\).\nFor a basis state \\(\\ket{\\psi} = \\ket{j}\\), this gives us \\[ U \\ket{j}\n= z \\cdot \\sum_{i = 0}^{N - 1} g(i - j) \\ket{i}\n= z \\cdot \\sum_{i = 0}^{N - 1} \\exp(-(i - j - b)^2 / c) \\ket{i} \\] where \\(z\\) might be a different normalization factor than before and might depend on \\(j\\).\nBecause the result will be normalized, \\(a\\) does not have any effect and can be ignored. We will also have to make an approximation to implement this efficiently, as we will see in the next section.\n\n\n\nNow we need to find a way to embed this operation into a quantum circuit. To do this, notice that the matrix representation is a Toeplitz matrix, i.e. a matrix where elements on the same diagonal have the same value.\nFor example, with \\(n = 2\\), \\(b = -1\\) and \\(c = 1\\), it would be \\[ A = \\begin{pmatrix}\ne^{-1} & 1 & e^{-1} & e^{-4} \\\\\ne^{-4} & e^{-1} & 1 & e^{-1} \\\\\ne^{-9} & e^{-4} & e^{-1} & 1 \\\\\ne^{-16} & e^{-9} & e^{-4} & e^{-1} \\\\\n\\end{pmatrix} \\]\nWe can follow [1] to implement this, however because we will have to load the value of each diagonal separately, we need to limit the number of diagonals to make this efficient. Luckily this is not an issue if we can tolerate some small error, since the values decrease exponentially in the distance, the number of diagonals only need to be logarithmic in the cutoff value.\nIn our example, we could limit it to three diagonals, ignoring values \\(\\leq e^{-4}\\), resulting in the following matrix representation: \\[ A' = \\begin{pmatrix}\ne^{-1} & 1 & e^{-1} & 0 \\\\\n0 & e^{-1} & 1 & e^{-1} \\\\\n0 & 0 & e^{-1} & 1 \\\\\n0 & 0 & 0 & e^{-1} \\\\\n\\end{pmatrix} \\]\nThen we can build the following circuit, where \\(\\ket{0} \\bra{0}\\) indicates postselecting the register as \\(\\ket{0 \\dots 0}\\), i.e. rerunning the algorithm until a measurement of this register yields only zeros:\n\n\n\n\n\nFirst, we use a PREP operation which can initialize any arbitrary state to load a single column of values onto the s register, in this example this would be \\[ \\begin{align}\n\\text{PREP} \\ket{0}^{\\otimes 2}\n= z \\cdot \\begin{pmatrix} e^{-1} \\\\ 1 \\\\ e^{-1} \\\\ 0 \\end{pmatrix}\n= z \\cdot (e^{-1} \\ket{0} + \\ket{1} + e^{-1} \\ket{2}) \\\\\n= z \\cdot \\sum_{k = 0}^2 e^{-(k - 1)^2} \\ket{k}\n= z \\cdot \\sum_{k = 0}^2 g(k - 2) \\ket{k}\n\\end{align}\\] with some normalization factor \\(z\\).\nThen we use an addition operation to add the state from the s register to the j register, which contains the input of the algorithm. This essentially copies the state initialized by PREP onto the register, but shifted by the incoming value (it copies in the sense that a CNOT gate copies a bit, not in the sense that violates the no-cloning theorem).\nNext, we subtract some constant \\(k\\) to add an offset from the main diagonal. If we are considering \\(2 \\cdot m + 1\\) diagonals, and the main diagonal with value \\(1\\) is in the center, that means there are \\(m\\) diagonals above that. Then \\(k = m - b\\), so in this example \\(k = 2\\).\nThe overflow qubit is treated as an additional high bit of the j register, and indicates that the two additions overflowed and caused values to wrap around the matrix. By postselecting it as \\(\\ket{0}\\), those values can be filtered out. This part can be removed to optimize the circuit, if overflows are impossible or tolerable.\nAt the end we perform an UNPREP operation on the s register, which is in this case equivalent to a Hadamard gate on each qubit. The register is then postselected as \\(\\ket{0}^{\\otimes n}\\). This applies the first row of the matrix representation of \\(H^{\\otimes n}\\), which contains only ones, i.e. builds a sum of the input values, combining the different values in the s register into a single state.\nAn alternative way of looking at this is as a linear combination of unitaries, where each of the unitaries is one of the diagonals.\nDenoting the addition gates in square brackets, and \\(\\ket{0}_s \\bra{0}_s\\) as the postselection / projection on the \\(\\ket{0}^{\\otimes d}\\) state on the s register, the result of the circuit is: \\[ \\begin{align}\n\\ket{0}_s \\bra{0}_s U \\left(\\ket{0} \\otimes \\ket{j} \\otimes \\ket{0}\\right)\n=& \\ket{0}_s \\bra{0}_s \\text{UNPREP} \\cdot [-2] \\cdot [+d] \\cdot \\text{PREP} \\\\\n&\\quad \\cdot \\left(\\ket{0} \\otimes \\ket{j} \\otimes \\ket{0}\\right) \\\\[0.5em]\n=& \\ket{0}_s \\bra{0}_s \\text{UNPREP} \\cdot [-2] \\cdot [+d] \\\\\n&\\quad \\cdot \\left(z \\cdot \\sum_{k = 0}^2 g(k - 2) \\cdot \\ket{k} \\otimes \\ket{j} \\otimes \\ket{0}\\right) \\\\[0.5em]\n=& \\ket{0}_s \\bra{0}_s \\text{UNPREP} \\cdot [-2] \\\\\n&\\quad \\cdot \\left(z \\cdot \\sum_{k = 0}^2 g(k - 2) \\cdot \\ket{k} \\otimes \\ket{(k + j) \\text{ mod } 4} \\otimes \\ket{\\text{overflow}}\\right) \\\\[0.5em]\n=& \\ket{0}_s \\bra{0}_s \\text{UNPREP} \\\\\n&\\quad \\cdot \\left( z \\cdot \\sum_{k = 0}^2 g(k - 2) \\cdot \\ket{k} \\otimes \\ket{(k + j - 2) \\text{ mod } 4} \\otimes \\ket{\\text{overflow}} \\right) \\\\[0.5em]\n=& \\widetilde{z} \\cdot \\sum_{k = 0}^2 g(k - 2) \\cdot \\ket{0} \\otimes \\ket{(k + j - 2) \\text{ mod } 4} \\otimes \\ket{\\text{overflow}} \\\\[0.5em]\n\\overset{i = k + j - 2}{=}& \\widetilde{z} \\cdot \\ket{0} \\otimes \\sum_{i = j - 2}^{j} g(i - j) \\cdot \\ket{i \\text{ mod } 4} \\otimes \\ket{\\text{overflow}}\n\\end{align} \\] for some normalization factor \\(\\widetilde{z}\\).\nAfter postselecting the overflow bit as \\(\\ket{0}\\), the values where the modulo operation has an effect are removed, so the sum will run from \\(i = \\max(j - 2, 0)\\) to \\(i = \\min(j, 3) = j\\), and the middle register contains the desired results.\nThe PREP and UNPREP operation here correspond to chosing \\(p = 1\\) in chapter 2.3 of [1]. This makes the calculation easier to follow, however the paper shows that chosing \\(p = 1 / 2\\) is better because it decreases the subnormalization, increasing the success rate of the postselection without changing the result of the circuit, so this is what we will do in the implementation.\n\n\n\nWe have seen that we can build a quantum circuit which implements a Gaussian convolution from three building blocks:\n\nA PREP block, which can initialize arbitrary states (which can also be used for the UNPREP block)\nAn addition block which can add a value from one register to another\nAn addition block which can add a compile time constant to a register\n\nIn the next chapters, we will see how to build these subcircuits, and at the end we will combine them to the full circuit."
  },
  {
    "objectID": "research/gaussian_convolution/index.html#goal",
    "href": "research/gaussian_convolution/index.html#goal",
    "title": "Building a Quantum Circuit for Gaussian Convolutions",
    "section": "",
    "text": "A Gaussian Convolution has an impulse response that is a Gaussian function \\(g(x) = a \\cdot \\exp\\left(-||x - b||_2^2 / c \\right)\\), so when applied to a function \\(f: \\mathbb{R}^d \\to \\mathbb{R}^d\\), it yields a new function \\[ (f * g)(i) = \\int_{\\mathbb{R}^d} f(j) \\cdot g(i - j) dj \\]\nNote that \\(g\\) is separable, so even if we are interested in high-dimensional functions, it is sufficient to consider the one-dimensional case for now. We can then run the one-dimensional implementation multiple times on separate qubits to get a multi-dimensional implementation.\nTo implement this on a quantum computer, we want a circuit that instead of a function \\(f\\) takes a state \\(\\ket{\\psi} = \\sum_{k = 0}^{N - 1} \\alpha_i \\ket{i}\\) on \\(n\\) qubits with \\(N = 2^n\\), and outputs the state \\[ U \\ket{\\psi}\n= \\ket{\\psi} * g\n= z \\cdot \\sum_{i = 0}^{N - 1} \\left(\\sum_{j = 0}^{N - 1} \\alpha_j \\cdot g(i - j)\\right) \\ket{i} \\] for some normalization factor \\(z\\).\nFor a basis state \\(\\ket{\\psi} = \\ket{j}\\), this gives us \\[ U \\ket{j}\n= z \\cdot \\sum_{i = 0}^{N - 1} g(i - j) \\ket{i}\n= z \\cdot \\sum_{i = 0}^{N - 1} \\exp(-(i - j - b)^2 / c) \\ket{i} \\] where \\(z\\) might be a different normalization factor than before and might depend on \\(j\\).\nBecause the result will be normalized, \\(a\\) does not have any effect and can be ignored. We will also have to make an approximation to implement this efficiently, as we will see in the next section."
  },
  {
    "objectID": "research/gaussian_convolution/index.html#high-level-circuit",
    "href": "research/gaussian_convolution/index.html#high-level-circuit",
    "title": "Building a Quantum Circuit for Gaussian Convolutions",
    "section": "",
    "text": "Now we need to find a way to embed this operation into a quantum circuit. To do this, notice that the matrix representation is a Toeplitz matrix, i.e. a matrix where elements on the same diagonal have the same value.\nFor example, with \\(n = 2\\), \\(b = -1\\) and \\(c = 1\\), it would be \\[ A = \\begin{pmatrix}\ne^{-1} & 1 & e^{-1} & e^{-4} \\\\\ne^{-4} & e^{-1} & 1 & e^{-1} \\\\\ne^{-9} & e^{-4} & e^{-1} & 1 \\\\\ne^{-16} & e^{-9} & e^{-4} & e^{-1} \\\\\n\\end{pmatrix} \\]\nWe can follow [1] to implement this, however because we will have to load the value of each diagonal separately, we need to limit the number of diagonals to make this efficient. Luckily this is not an issue if we can tolerate some small error, since the values decrease exponentially in the distance, the number of diagonals only need to be logarithmic in the cutoff value.\nIn our example, we could limit it to three diagonals, ignoring values \\(\\leq e^{-4}\\), resulting in the following matrix representation: \\[ A' = \\begin{pmatrix}\ne^{-1} & 1 & e^{-1} & 0 \\\\\n0 & e^{-1} & 1 & e^{-1} \\\\\n0 & 0 & e^{-1} & 1 \\\\\n0 & 0 & 0 & e^{-1} \\\\\n\\end{pmatrix} \\]\nThen we can build the following circuit, where \\(\\ket{0} \\bra{0}\\) indicates postselecting the register as \\(\\ket{0 \\dots 0}\\), i.e. rerunning the algorithm until a measurement of this register yields only zeros:\n\n\n\n\n\nFirst, we use a PREP operation which can initialize any arbitrary state to load a single column of values onto the s register, in this example this would be \\[ \\begin{align}\n\\text{PREP} \\ket{0}^{\\otimes 2}\n= z \\cdot \\begin{pmatrix} e^{-1} \\\\ 1 \\\\ e^{-1} \\\\ 0 \\end{pmatrix}\n= z \\cdot (e^{-1} \\ket{0} + \\ket{1} + e^{-1} \\ket{2}) \\\\\n= z \\cdot \\sum_{k = 0}^2 e^{-(k - 1)^2} \\ket{k}\n= z \\cdot \\sum_{k = 0}^2 g(k - 2) \\ket{k}\n\\end{align}\\] with some normalization factor \\(z\\).\nThen we use an addition operation to add the state from the s register to the j register, which contains the input of the algorithm. This essentially copies the state initialized by PREP onto the register, but shifted by the incoming value (it copies in the sense that a CNOT gate copies a bit, not in the sense that violates the no-cloning theorem).\nNext, we subtract some constant \\(k\\) to add an offset from the main diagonal. If we are considering \\(2 \\cdot m + 1\\) diagonals, and the main diagonal with value \\(1\\) is in the center, that means there are \\(m\\) diagonals above that. Then \\(k = m - b\\), so in this example \\(k = 2\\).\nThe overflow qubit is treated as an additional high bit of the j register, and indicates that the two additions overflowed and caused values to wrap around the matrix. By postselecting it as \\(\\ket{0}\\), those values can be filtered out. This part can be removed to optimize the circuit, if overflows are impossible or tolerable.\nAt the end we perform an UNPREP operation on the s register, which is in this case equivalent to a Hadamard gate on each qubit. The register is then postselected as \\(\\ket{0}^{\\otimes n}\\). This applies the first row of the matrix representation of \\(H^{\\otimes n}\\), which contains only ones, i.e. builds a sum of the input values, combining the different values in the s register into a single state.\nAn alternative way of looking at this is as a linear combination of unitaries, where each of the unitaries is one of the diagonals.\nDenoting the addition gates in square brackets, and \\(\\ket{0}_s \\bra{0}_s\\) as the postselection / projection on the \\(\\ket{0}^{\\otimes d}\\) state on the s register, the result of the circuit is: \\[ \\begin{align}\n\\ket{0}_s \\bra{0}_s U \\left(\\ket{0} \\otimes \\ket{j} \\otimes \\ket{0}\\right)\n=& \\ket{0}_s \\bra{0}_s \\text{UNPREP} \\cdot [-2] \\cdot [+d] \\cdot \\text{PREP} \\\\\n&\\quad \\cdot \\left(\\ket{0} \\otimes \\ket{j} \\otimes \\ket{0}\\right) \\\\[0.5em]\n=& \\ket{0}_s \\bra{0}_s \\text{UNPREP} \\cdot [-2] \\cdot [+d] \\\\\n&\\quad \\cdot \\left(z \\cdot \\sum_{k = 0}^2 g(k - 2) \\cdot \\ket{k} \\otimes \\ket{j} \\otimes \\ket{0}\\right) \\\\[0.5em]\n=& \\ket{0}_s \\bra{0}_s \\text{UNPREP} \\cdot [-2] \\\\\n&\\quad \\cdot \\left(z \\cdot \\sum_{k = 0}^2 g(k - 2) \\cdot \\ket{k} \\otimes \\ket{(k + j) \\text{ mod } 4} \\otimes \\ket{\\text{overflow}}\\right) \\\\[0.5em]\n=& \\ket{0}_s \\bra{0}_s \\text{UNPREP} \\\\\n&\\quad \\cdot \\left( z \\cdot \\sum_{k = 0}^2 g(k - 2) \\cdot \\ket{k} \\otimes \\ket{(k + j - 2) \\text{ mod } 4} \\otimes \\ket{\\text{overflow}} \\right) \\\\[0.5em]\n=& \\widetilde{z} \\cdot \\sum_{k = 0}^2 g(k - 2) \\cdot \\ket{0} \\otimes \\ket{(k + j - 2) \\text{ mod } 4} \\otimes \\ket{\\text{overflow}} \\\\[0.5em]\n\\overset{i = k + j - 2}{=}& \\widetilde{z} \\cdot \\ket{0} \\otimes \\sum_{i = j - 2}^{j} g(i - j) \\cdot \\ket{i \\text{ mod } 4} \\otimes \\ket{\\text{overflow}}\n\\end{align} \\] for some normalization factor \\(\\widetilde{z}\\).\nAfter postselecting the overflow bit as \\(\\ket{0}\\), the values where the modulo operation has an effect are removed, so the sum will run from \\(i = \\max(j - 2, 0)\\) to \\(i = \\min(j, 3) = j\\), and the middle register contains the desired results.\nThe PREP and UNPREP operation here correspond to chosing \\(p = 1\\) in chapter 2.3 of [1]. This makes the calculation easier to follow, however the paper shows that chosing \\(p = 1 / 2\\) is better because it decreases the subnormalization, increasing the success rate of the postselection without changing the result of the circuit, so this is what we will do in the implementation."
  },
  {
    "objectID": "research/gaussian_convolution/index.html#summary",
    "href": "research/gaussian_convolution/index.html#summary",
    "title": "Building a Quantum Circuit for Gaussian Convolutions",
    "section": "",
    "text": "We have seen that we can build a quantum circuit which implements a Gaussian convolution from three building blocks:\n\nA PREP block, which can initialize arbitrary states (which can also be used for the UNPREP block)\nAn addition block which can add a value from one register to another\nAn addition block which can add a compile time constant to a register\n\nIn the next chapters, we will see how to build these subcircuits, and at the end we will combine them to the full circuit."
  },
  {
    "objectID": "research/gaussian_convolution/index.html#core-idea",
    "href": "research/gaussian_convolution/index.html#core-idea",
    "title": "Building a Quantum Circuit for Gaussian Convolutions",
    "section": "2.1 Core Idea",
    "text": "2.1 Core Idea\nTo illustrate the idea, we will consider the reverse of what we actually want to do: Assume that we get some arbitrary (but determined at compile time) state \\(\\ket{\\psi}\\), and need to transform it to \\(\\ket{0}^{\\otimes n}\\). If we can do this, we can simply run the inverse of the circuit to go from \\(\\ket{0}^{\\otimes n}\\) to \\(\\ket{\\psi}\\).\nFor a single-qubit state this is easily done via a Z-rotation followed by a Y-rotation.\nIf we instead have a multi-qubit state on \\(n\\) qubits, we can write it in the following way:\n\\[ \\ket{\\psi}\n= \\sum_{k = 0}^{2^{n - 1} - 1} c_k \\ket{k} \\otimes \\ket{\\psi_k} \\]\nHere, \\(\\ket{k}\\) are the basis states of the first \\(n - 1\\) qubits, \\(c_k\\) some coefficients, and \\(\\ket{\\psi_k}\\) are single qubit states on the last qubit. With this formulation, we can apply our earlier single qubit approach to each \\(\\ket{\\psi_k}\\) individually by using multi-controlled rotations, and turning this state into\n\\[ \\sum_{k = 0}^{2^{n - 1} - 1} c_k \\ket{k} \\otimes \\ket{0}\n= \\left(\\sum_{k = 0}^{2^{n - 1} - 1} c_k \\ket{k}\\right) \\otimes \\ket{0} \\]\nSo we have successfully unentangled the last qubit from the rest of the state. This can now be recursively repeated for the remaining \\(n - 1\\) qubits, until all of them are in the state \\(\\ket{0}\\)."
  },
  {
    "objectID": "research/gaussian_convolution/index.html#implementation",
    "href": "research/gaussian_convolution/index.html#implementation",
    "title": "Building a Quantum Circuit for Gaussian Convolutions",
    "section": "2.2 Implementation",
    "text": "2.2 Implementation\nTo make the calculation of the angles efficient, we have to go from least to most signficant bit, allowing us to reuse results from lower bits for the calculation of higher bits.\nThen we go through all the possible basis states \\(i\\) of the higher bits, and consider the coefficients \\(a_0 \\ket{0} + a_1 \\ket{1}\\) where the higher bits are in state \\(i\\). This allows us to calculate the relative magnitude and phase of these two coefficients, giving us the angles \\(\\theta\\) and \\(\\varphi\\) for the rotations. But we also need to calculate the “combined” coefficient, which will then be used for the next higher bit.\n\n\nCode\n\ndef prepare_state(\n    state: npt.NDArray[float],\n    target: Sequence[int]\n) -&gt; tq.QCircuit:\n    theta = dict()\n    phi = dict()\n    combined = dict()\n    for bit in reversed(range(n)):\n        for i in range(2 ** bit):\n            a0 = state[2 * i] if bit == n - 1 else combined[bit + 1, 2 * i]\n            a1 = state[2 * i + 1] if bit == n - 1 else combined[bit + 1, 2 * i + 1]\n            r = hypot(abs(a0), abs(a1))\n            theta[bit, i] = 2 * np.arccos(np.abs(a0) / r) if r != 0 else 0\n            phi[bit, i] = phase(a1) - phase(a0)\n            combined[bit, i] = rect(r, (phase(a0) + phase(a1)) / 2)\n    ...\n\nNow that we know the rotation angles, we can build the actual circuit. For this, we go from the most to least signifcant bit (we are doing the reverse of what was described earlier), and for each bit, iterate through states of the higher bits and apply the rotations. We implement the controls by inserting NOT gates, so that at the time of each rotation, the state we are looking at is \\(\\ket{1 \\dots 1}\\).\n\n\nCode\n\n    ...\n    U = tq.QCircuit()\n\n    for bit in range(n):\n        for i in range(2 ** bit):\n            diff = i ^ (i - 1)\n            for j in range(bit):\n                if diff & (1 &lt;&lt; (bit - j - 1)):\n                    U += tq.gates.X(target=target[j])\n            U += tq.gates.Ry(angle=theta[bit, i], target=target[bit], control=target[:bit])\n            U += tq.gates.Rz(angle=phi[bit, i], target=target[bit], control=target[:bit])\n\n    return U\n\nCalling this code with a 3-qubit state yields the following circuit:\n\n\n\n\n\nIt performs the correct operation, however there are multi-controlled rotations which will likely be a problem when attempting to run this on real hardware. We could let a compiler take care of this, but we don’t know how efficient that will be. Instead we’ll manually decompose it into single-controlled rotations and Toffoli gates, using our knowledge that there are other qubits in this circuit that we can borrow."
  },
  {
    "objectID": "research/gaussian_convolution/index.html#decomposing-multi-controlled-rotations",
    "href": "research/gaussian_convolution/index.html#decomposing-multi-controlled-rotations",
    "title": "Building a Quantum Circuit for Gaussian Convolutions",
    "section": "2.3 Decomposing multi-controlled rotations",
    "text": "2.3 Decomposing multi-controlled rotations\nIf you refer to the overview of the full circuit in the previous chapter, you can see that we only have one additional qubit with a known initialization, the overflow qubit. Unfortunately this is not enough for our purposes, and we’d also like to keep the option of removing the overflow bit when we don’t need it. We could of course simply require additional ancilla qubits, but this would make the circuit more difficult to run. Luckily, we can use a trick described in [3], which allows us to borrow qubits that are already used for something else and in an unknown state. The only requirement is that this unknown state does not change while they’re borrowed.\nFor this, we use the fact that \\[ X \\cdot R_{Y/Z}(\\theta) \\cdot X = R_{Y/Z}(-\\theta) \\] to decompose the circuit in the following way:\n\n\n\n\n\nIf we have a clean qubit in state \\(\\ket{0}\\), the decomposition is easy: We simply run a multi-controlled NOT on the ancilla qubit, and then use that ancilla as the control for the rotation. Then we repeat the controlled NOT to uncompute the effect on the ancilla.\nIf we don’t know the state of our ancilla, we run two rotations, one inside the two controlled NOTs, and one outside. This means that if the controlled NOTs are run, exactly one of those rotations gets executed, achieving the desired result. If the controlled NOTs are not run, it depends on the state of the ancilla. If this state is \\(\\ket{0}\\), nothing happens. But if the state is \\(\\ket{1}\\), then both rotations are run. Because of this there are two additional CNOTs, which will in this case flip the second rotation, making them cancel each other out. Note that this also works if the ancilla is in a superposition, since each component of the superposition will reach the same result.\n\n\nCode\n\ndef multi_controlled_Ry(\n    angle: float,\n    target: int,\n    controls: Sequence[int],\n    ancillae: Sequence[int]\n) -&gt; tq.QCircuit:\n    U = tq.QCircuit()\n\n    if len(controls) &lt;= 1:\n        U += tq.gates.Ry(angle=angle, target=target, control=controls)\n        return U\n\n    U += tq.gates.Ry(angle=angle, target=target, control=ancillae[-1])\n    U += tq.gates.CNOT(target=target, control=ancillae[-1])\n\n    U += multi_controlled_not(target=ancillae[-1], controls=controls, ancillae=ancillae[:-1], uncompute=False)\n\n    U += tq.gates.Ry(angle=angle, target=target, control=ancillae[-1])\n\n    U += multi_controlled_not(target=ancillae[-1], controls=controls, ancillae=ancillae[:-1], uncompute=False)\n\n    U += tq.gates.CNOT(target=target, control=ancillae[-1])\n\n    return U\n\nThe code for the Z-rotation is the same, simply replace Ry with Rz.\nBut now, even though we got rid of the multi-controlled rotation, we instead have multi-controlled NOTs, which we can also not directly execute. Luckily we can also resolve this using borrowed ancillae:\n\n\n\n\n\nThe idea here is similar to the previous circuit. By running controlled operations twice, interleaved with controlled NOTs, we are independent of the initial state of the qubit.\nNote that the last three Toffoli gates in the circuit on the right are only necessary to uncompute the ancillae. In cases where we run this circuit twice, like in the decomposition of the rotation above, this is not necessary, since the two circuits will perform the same bitflips and cancel out.\n\n\nCode\n\ndef multi_controlled_not(\n    target: int,\n    controls: Sequence[int],\n    ancillae: Sequence[int],\n    uncompute: bool = True\n) -&gt; tq.QCircuit:\n    if len(controls) &lt;= 2:\n        return tq.gates.X(target=target, control=controls)\n\n    staircase = tq.QCircuit()\n    for i in range(2, len(controls) - 1):\n        staircase += tq.gates.Toffoli(first=controls[i], second=ancillae[i - 2], target=ancillae[i - 1])\n\n    U = tq.QCircuit()\n\n    U += tq.gates.Toffoli(first=controls[-1], second=ancillae[len(controls) - 3], target=target)\n    U += staircase.dagger()\n    U += tq.gates.Toffoli(first=controls[0], second=controls[1], target=ancillae[0])\n    U += staircase\n    U += tq.gates.Toffoli(first=controls[-1], second=ancillae[len(controls) - 3], target=target)\n\n    if uncompute:\n        U += staircase.dagger()\n        U += tq.gates.Toffoli(first=controls[0], second=controls[1], target=ancillae[0])\n        U += staircase\n\n    return U\n\nThe Toffoli gates can be directly decomposed into CNOTs and T gates, which we will not do here."
  },
  {
    "objectID": "research/gaussian_convolution/index.html#gate-count",
    "href": "research/gaussian_convolution/index.html#gate-count",
    "title": "Building a Quantum Circuit for Gaussian Convolutions",
    "section": "2.4 Gate count",
    "text": "2.4 Gate count\nWe will now analyze the gate usage of these circuits, counting the rotations and Toffoli gates, as they determine the main cost of running the circuit, and ignoring NOT and CNOT gates.\nThe multi-controlled NOT decomposition with \\(c \\geq 2\\) controls and without uncomputing the result uses \\(2 + 2 \\cdot (c - 3) + 1 = 2 c - 3\\) Toffoli gates.\nMulti controlled rotations with \\(c \\geq 2\\) controls have two such decompositions, so \\(4 c - 6\\) Toffoli gates and two rotations.\nFor comparison, decomposing multi-controlled NOTs and rotations with \\(c\\) controls using the Tequila compile_circuit function doesn’t require any ancillae but seems to take approximately \\(2^c\\) single qubit rotations and CNOTs each, from some very quick tests.\nThe part of the PREP circuit operating on the \\(k\\)-th qubit (counting from 1) requires \\(2^k\\) \\(Y\\) and \\(Z\\) rotations, each with \\(k - 1\\) controls. However, if we assume that the coefficients of our state are real and positive, there are no phases so the Z-rotations can be removed. Some of the angles of the Y-rotations might be \\(0\\) too, but we assume here that they are all necessary.\nThis results in \\(2^k\\) rotations and \\(2^{k - 1} \\cdot (4 \\cdot (k - 1) - 6) = 2^k \\cdot (2 k - 5)\\) Toffoli gates, except for \\(k \\leq 2\\) where the decomposition is not necessary, so we get half as many rotations and no Toffoli gates.\nLet \\(D\\) be the number of diagonals that we are loading in the PREP operation. Assuming that \\(D\\) is a power of 2 and we are operating on \\(d = \\log_2(D)\\) qubits in total, for \\(d = 1\\) we have one rotation, and for \\(d &gt;= 2\\) \\[ 3 + \\sum_{k = 3}^{d} 2^k\n= 2^{d + 1} - 5\n= 2 D - 5 \\] rotations. The number of Toffoli gates is \\(0\\) for \\(d \\leq 2\\), and otherwise \\[ \\sum_{k = 3}^d 2^k \\cdot (2k - 5)\n= 2^d \\cdot (4 d - 14) + 24\n= D \\cdot (4 \\log_2(D) - 14) + 24 \\]\nThe costs are exponential in \\(d\\), but this is not surprising as the number of values we are loading is exponential in \\(d\\). More interesting to us is how the cost scales with \\(D\\). Especially considering that, if we allow cutting off values below some error threshold \\(\\varepsilon\\), we only need \\(D \\in O(\\log \\varepsilon)\\), we get costs in \\(O(\\log \\varepsilon \\cdot \\log \\log \\varepsilon)\\)."
  },
  {
    "objectID": "research/gaussian_convolution/index.html#allowing-different-register-sizes",
    "href": "research/gaussian_convolution/index.html#allowing-different-register-sizes",
    "title": "Building a Quantum Circuit for Gaussian Convolutions",
    "section": "3.1 Allowing different register sizes",
    "text": "3.1 Allowing different register sizes\nInstead of applying a NOT operation on a single overflow bit, we want to increment the high bits of the target register.\nWe cannot simply replace the two controlled NOTs with increment operations, because if both NOTs are executed, they cancel out, but if both increment operations are executed, they increment the value twice. To fix this, we will use a trick from [5]: Similar to the rotations in the previous chapter, an increment operation inverts, i.e. becomes a decrement, when its target bits are flipped before and after the operation.\nThis works because the bitwise complement of a two’s complement number is almost the negative of the number, more precisely \\(\\overline{a} = -a - 1\\), so \\[ \\overline{\\overline{a} + 1}\n= \\overline{-a - 1 + 1}\n= \\overline{-a}\n= a - 1 \\]\nSo if we add controlled NOTs to all target registers at the beginning and end of the circuit that run if the first increment will run, then the increments cancel out. If only one of them is running, they will operate correctly.\n\n\n\n\n\nNext, we need a way to implement an increment operation."
  },
  {
    "objectID": "research/gaussian_convolution/index.html#increment-gate",
    "href": "research/gaussian_convolution/index.html#increment-gate",
    "title": "Building a Quantum Circuit for Gaussian Convolutions",
    "section": "3.2 Increment gate",
    "text": "3.2 Increment gate\nWe will first implement an increment circuit that requires n borrowed ancilla qubits, and then improve this to only a single ancilla. Both are taken from [5].\nWe start with this subtraction widget, which is a modified version of a VanRentergem adder and subtracts the garbage in a register and a carry bit from the value in another register:\n\n\n\n\n\n\n\nCode\n\ndef _subtraction_widget(\n    v: Sequence[int],\n    g: Sequence[int],\n    c: int\n) -&gt; tq.QCircuit:\n    g = [c] + list(g)\n\n    U = tq.QCircuit()\n\n    for i in range(len(v) - 1):\n        U += tq.gates.CNOT(control=g[i], target=v[i])\n        U += tq.gates.CNOT(control=g[i + 1], target=g[i])\n        U += tq.gates.Toffoli(first=g[i], second=v[i], target=g[i + 1])\n\n    U += tq.gates.CNOT(control=g[-1], target=v[-1])\n\n    for i in reversed(range(len(v) - 1)):\n        U += tq.gates.Toffoli(first=g[i], second=v[i], target=g[i + 1])\n        U += tq.gates.CNOT(control=g[i + 1], target=g[i])\n        U += tq.gates.CNOT(control=g[i + 1], target=v[i])\n\n    return U\n\nThen we apply this widget twice, but toggle the qubits of \\(g\\) around the second time, so the result in the \\(v\\) register will be \\[ v - g - c - (-g - 1) - c\n= v - 2 c + 1 \\]\nThe result is that if \\(c = 0\\), we perform an increment, and if \\(c = 1\\), we perform a decrement. We want to always perform an increment, and we know that we can turn a decrement into an increment by surrounding it with NOTs, so we do that, controlled by c.\nAs a last detail, because \\(v\\) has one more bit than \\(g\\), when adding both \\(g\\) and \\(\\overline{g}\\), one of those will be negative, but the sign will act as a normal binary digit, toggling the high bit of \\(v\\). We can fix this by adding an additional NOT gate on this bit, ending up with the following circuit:\n\n\n\n\n\n\n\nCode\n\ndef increment_circuit_n_ancillae(\n    target: Sequence[int],\n    ancillae: Sequence[int]\n) -&gt; tq.QCircuit:\n    v = target[::-1]  # LSB ordering\n\n    # If there are more than n ancillas, ignore them\n    g = ancillae[:len(target)]\n\n    U = tq.QCircuit()\n\n    for i in range(len(v)):\n        U += tq.gates.CNOT(control=g[0], target=v[i])\n\n    for i in range(1, len(g)):\n        U += tq.gates.X(target=g[i])\n\n    U += tq.gates.X(target=v[-1])\n\n    U += _subtraction_widget(v, g[1:], g[0])\n\n    for i in range(1, len(g)):\n        U += tq.gates.X(target=g[i])\n\n    U += _subtraction_widget(v, g[1:], g[0])\n\n    for i in range(len(v)):\n        U += tq.gates.CNOT(control=g[0], target=v[i])\n\n    return U\n\nNext, we want to improve this from requiring \\(n\\) ancillae, to only one. To do this, we split one large increment gates into two smaller ones, each acting on half of the register, the second one indirectly controlled by the bits of the lower register using the borrowed ancilla. Reducing the size of the increments like this gives us enough unused qubits to use our \\(n\\) ancilla version.\n\n\n\n\n\nWe already know from the previous chapter how to decompose the multi-controlled NOTs, and have enough unused qubits here. Making a controlled increment is not a problem either, since this is equivalent to a larger increment and a NOT gate.\nTo see this, note that an increment gate is equivalent to a triangle of multi-controlled NOTs:\n\n\n\n\n\nThere is one issue left: Since this method increases the size of the increment on the higher bits, if the size of \\(v\\) is even, we are short one ancilla (if it is odd, we split the register so that the more significant half is one qubit smaller). This can be solved by pulling out the largest multi-controlled NOT, decreasing the size of the increment by one.\n\n\nCode\n\ndef increment_circuit_single_ancilla(\n    target: Sequence[int],\n    ancilla: int\n ) -&gt; tq.QCircuit:\n    split = (len(target) - 1) // 2\n\n    U = tq.QCircuit()\n\n    U += increment_circuit_n_ancillae(target=list(target[:split]) + [ancilla], ancillae=target[split:])\n    U += tq.gates.X(target=ancilla)\n\n    for i in range(split):\n        U += tq.gates.CNOT(control=ancilla, target=target[i])\n\n    U += multi_controlled_not(target=ancilla, controls=target[split:], ancillae=target[:split])\n\n    U += increment_circuit_n_ancillae(target=list(target[:split]) + [ancilla], ancillae=target[split:])\n    U += tq.gates.X(target=ancilla)\n\n    U += multi_controlled_not(target=ancilla, controls=target[split:], ancillae=target[:split])\n\n    for i in range(split):\n        U += tq.gates.CNOT(control=ancilla, target=target[i])\n\n    if len(target) % 2 == 0:\n        # The increment is too large, so pull one qubit out of the operation\n        U += multi_controlled_not(target=target[split], controls=target[split + 1:], ancillae=target[:split])\n        U += increment_circuit_n_ancillae(target=target[split + 1:], ancillae=list(target[:split]) + [ancilla])\n    else:\n        U += increment_circuit_n_ancillae(target[split:], list(target[:split]) + [ancilla])\n\n    return U"
  },
  {
    "objectID": "research/gaussian_convolution/index.html#implementation-1",
    "href": "research/gaussian_convolution/index.html#implementation-1",
    "title": "Building a Quantum Circuit for Gaussian Convolutions",
    "section": "3.3 Implementation",
    "text": "3.3 Implementation\nNow we have all of the tools we need to implement the addition circuit from the paper, with the changes mentioned above. Finding even a single ancilla is not easy though, since this operation covers every single qubit in our entire circuit, leaving not even borrowable ancillas.\nWe solve this problem by noting that we don’t need the ancilla for the entire addition circuit, but only during the increment. This increment only touches the last qubit of the s register, so we simply require that it has at least two qubits and use the first as the ancilla. It seems unlikely that we will want to implement a convolution with only two diagonals, so this limitation shouldn’t be an issue.\nWith this we get the following implementation:\n\n\nCode\n\ndef addition_circuit(\n    source: Sequence[int],\n    target: Sequence[int]\n) -&gt; tq.QCircuit:\n    n = len(source)\n\n    # Change register to LSB ordering and name them like in the paper.\n    # Note that unlike in the paper, A_n does not exist, because of the special handling for larger target registers.\n    a = source[::-1]\n    b = target[::-1]\n\n    U = tq.QCircuit()\n\n    for i in range(1, n):\n        U += tq.gates.CNOT(control=a[i], target=b[i])\n\n    if len(target) &gt; n:\n        U += increment_circuit_single_ancilla(target=list(b[n:][::-1]) + [a[n - 1]], ancilla=b[0])\n        U += tq.gates.X(target=a[n - 1])\n        for i in range(n, len(b)):\n            U += tq.gates.CNOT(control=a[n - 1], target=b[i])\n\n    for i in reversed(range(1, n - 1)):\n        U += tq.gates.CNOT(control=a[i], target=a[i + 1])\n    for i in range(n - 1):\n        U += tq.gates.Toffoli(first=a[i], second=b[i], target=a[i + 1])\n\n    if len(target) &gt; n:\n        U += increment_circuit_single_ancilla(target=list(b[n:][::-1]) + [a[n - 1], b[n - 1]], ancilla=b[0])\n        U += tq.gates.X(target=b[n - 1])\n        U += tq.gates.CNOT(control=b[n - 1], target=a[n - 1])\n\n    for i in reversed(range(1, n)):\n        U += tq.gates.CNOT(control=a[i], target=b[i])\n        U += tq.gates.Toffoli(first=a[i - 1], second=b[i - 1], target=a[i])\n    for i in range(1, n - 1):\n        U += tq.gates.CNOT(control=a[i], target=a[i + 1])\n    for i in range(n):\n        U += tq.gates.CNOT(control=a[i], target=b[i])\n\n    if len(target) &gt; n:\n        for i in range(n, len(b)):\n            U += tq.gates.CNOT(control=a[n - 1], target=b[i])\n\n    return U"
  },
  {
    "objectID": "research/gaussian_convolution/index.html#gate-count-1",
    "href": "research/gaussian_convolution/index.html#gate-count-1",
    "title": "Building a Quantum Circuit for Gaussian Convolutions",
    "section": "3.4 Gate count",
    "text": "3.4 Gate count\nLike before, we will only count Toffoli gates (there are no rotations here).\nOur subtraction widget with \\(n\\) qubit registers has \\(2 (n - 1)\\) Toffoli gates.\nThe n ancilla increment gate uses two such widgets and contains no other Toffoli gates, so \\(4 n - 4\\) Toffoli gates.\nThe calculation for the one ancilla increment gate depends on the parity of \\(n\\).\nFor even \\(n\\), we need to keep the extra multi-controlled NOT in mind that was pulled out from the increment gate on the less significant bits. The more significant part has \\(n / 2 - 1\\) qubits, and the less significant part has \\(n / 2 + 1\\) qubits, so there are two increment gates on \\((n / 2 - 1) + 1\\) qubits, one on \\((n / 2 + 1) - 1\\) qubits, two NOTs with \\(n / 2 + 1\\) controls and one with \\((n / 2 + 1) - 1\\) controls. Unlike before, we need to uncompute the result of the multi-controlled not, requiring \\(4c - 8\\) Toffoli gates for \\(c\\) controls. This brings the total for the incrementer to \\(12n - 28\\) for \\(n \\geq 6\\) (for smaller \\(n\\) the parts into which the register is split become too small for this calculation).\nFor odd \\(n\\), the more significant part has \\((n - 1) / 2\\) qubits, and the less significant part \\((n + 1) / 2\\). So we get two multi-controlled NOTs with \\((n - 1) / 2\\) controls, two increment gates on \\((n + 1) / 2 + 1\\) qubits, and one on \\((n - 1) / 2\\) qubits, for a total of \\(10 n - 18\\) Toffoli gates for \\(n \\geq 5\\).\nThe adder from [4] with registers of size \\(n\\) uses \\(2 n - 1\\) Toffoli gates.\nLet \\(n\\) be the size of the source register and \\(n + k\\) the size of the target register. If \\(k = 0\\), then we remove the Toffoli gate acting on the overflow qubit and get \\(2 n - 2\\) Toffoli gates. If \\(k &gt; 0\\), we also remove this Toffoli gate, but add a \\(k + 1\\) and a \\(k + 2\\) qubit single-ancilla increment gate, one of which has is an even number of qubits and the other odd. If \\(k \\geq 5\\), we get \\(2 n + 22 k - 14\\) Toffoli gates for even \\(k\\) and \\(2 n + 22 k - 16\\) for odd \\(k\\).\nEven though it is linear, the cost of the modification to allow differently sized registers is high. A more efficient solution would be desirable, especially since our source register will generally be very small due to its exponential cost (as shown in the previous chapter), while the target register might be fairly large."
  },
  {
    "objectID": "research/gaussian_convolution/index.html#carry-circuit",
    "href": "research/gaussian_convolution/index.html#carry-circuit",
    "title": "Building a Quantum Circuit for Gaussian Convolutions",
    "section": "4.1 Carry circuit",
    "text": "4.1 Carry circuit\nThe main idea of this algorithm is that if we split the register we are working on in two parts, the only interaction between those is when there is a carry from the less significant to the more significant part. This means that, if we can detect this carry and increment the more significant part when it occurs, we can then work on the two parts separately, halving the size of the operation.\nFor this, we need the following carry operation:\n\n\n\n\n\nDepending on the constant \\(c\\) that is added, some of the gates are removed, see [6] for details.\n\n\nCode\n\ndef _carry_circuit(\n    target: Sequence[int],\n    const: int,\n    carry: int,\n    ancillae: Sequence[int]\n) -&gt; tq.QCircuit:\n    n = len(target)\n\n    U = tq.QCircuit()\n\n    if n == 1:\n        if const & 1:\n            U += tq.gates.CNOT(control=target[0], target=carry)\n        return U\n\n    U += tq.gates.CNOT(control=ancillae[n - 2], target=carry)\n\n    half = tq.QCircuit()\n\n    for i in reversed(range(1, n)):\n        if const & (1 &lt;&lt; i):\n            half += tq.gates.CNOT(control=target[i], target=ancillae[i - 1])\n            half += tq.gates.X(target=target[i])\n        if i &gt; 1:\n            half += tq.gates.Toffoli(first=ancillae[i - 2], second=target[i], target=ancillae[i - 1])\n\n    if const & 1:\n        half += tq.gates.Toffoli(first=target[0], second=target[1], target=ancillae[0])\n\n    for i in range(2, n):\n        half += tq.gates.Toffoli(first=ancillae[i - 2], second=target[i], target=ancillae[i - 1])\n\n    U += half\n\n    U += tq.gates.CNOT(control=ancillae[n - 2], target=carry)\n\n    U += half.dagger()\n\n    return U"
  },
  {
    "objectID": "research/gaussian_convolution/index.html#implementation-2",
    "href": "research/gaussian_convolution/index.html#implementation-2",
    "title": "Building a Quantum Circuit for Gaussian Convolutions",
    "section": "4.2 Implementation",
    "text": "4.2 Implementation\nThis carry operation allows us to split the operation in half like described earlier:\n\n\n\n\n\nHere \\(x_H\\) is the more significant half, and \\(x_L\\) the less significant half of the register, and similarly \\(c_H\\) and \\(c_L\\) are the more and less significant halves of the constant. Even though it looks like it, the carry operation doesn’t act on \\(x_H\\), only on \\(x_L\\) and the \\(g\\) ancilla.\nWe can reuse the n-ancilla incrementer from the last chapter here, and like before we have to be careful about the number of ancillae. If the register size is odd, we have exactly the right amount, but if it is even, we are missing one. We could solve this by not splitting the register in half, and instead making the less significant part larger, at the cost of a higher recursion depth. However we already required that the s register consists of at least two qubits in the last chapter, so we can use those as ancillae. One of these qubits can then be used as the additional ancilla we are missing.\nOnce the recursion reaches a single qubit, the addition operation is simply a NOT gate if \\(c = 1\\).\n\n\nCode\n\ndef const_addition_circuit(\n    target: Sequence[int],\n    const: int,\n    ancillae: Sequence[int]\n) -&gt; tq.QCircuit:\n    n = len(target)\n    if n == 1:\n        U = tq.QCircuit()\n        if const & 1:\n            U += tq.gates.X(target=target[0])\n        return U\n\n    assert abs(const) &lt; 2 ** n\n    assert len(ancillae) &gt;= 2\n\n    split = n // 2\n\n    U = tq.QCircuit()\n\n    U += increment_circuit_n_ancillae(target=list(target[:split]) + [ancillae[0]],\n                                      ancillae=list(target[split:]) + [ancillae[1]])\n    U += tq.gates.X(target=ancillae[0])\n\n    for i in range(split):\n        U += tq.gates.CNOT(control=ancillae[0], target=target[i])\n\n    U += _carry_circuit(target=target[split:][::-1], const=const % (2 ** (n - split)), carry=ancillae[0],\n                        ancillae=list(target[:split]))\n\n    U += increment_circuit_n_ancillae(target=list(target[:split]) + [ancillae[0]],\n                                      ancillae=list(target[split:]) + [ancillae[1]])\n    U += tq.gates.X(target=ancillae[0])\n\n    U += _carry_circuit(target=target[split:][::-1], const=const % (2 ** (n - split)), carry=ancillae[0],\n                        ancillae=list(target[:split]))\n\n    for i in range(split):\n        U += tq.gates.CNOT(control=ancillae[0], target=target[i])\n\n    U += const_addition_circuit(target=target[:split], const=const &gt;&gt; (n - split), ancillae=ancillae)\n    U += const_addition_circuit(target=target[split:], const=const % (2 ** (n - split)), ancillae=ancillae)\n\n    return U\n\nWith this, we have all the building blocks we need for the full circuit that implements a Toeplitz matrix and the convolution."
  },
  {
    "objectID": "research/gaussian_convolution/index.html#gate-count-2",
    "href": "research/gaussian_convolution/index.html#gate-count-2",
    "title": "Building a Quantum Circuit for Gaussian Convolutions",
    "section": "4.3 Gate count",
    "text": "4.3 Gate count\nAgain, we are only counting the Toffoli gates.\nFrom the figure, we can see that the carry operation on an \\(n\\) qubit target register requires \\(4 n - 6\\) Toffoli gates if the lowest bit of the constant is set (otherwise two less) for \\(n \\geq 2\\) and none for \\(n = 1\\) (there the circuit is a CNOT).\nThe constant addition on \\(n\\) qubits contains two \\(\\lceil n / 2 \\rceil\\) qubit carry gates, two \\(\\lfloor n / 2 \\rfloor + 1\\) qubit increment gates, and two smaller constant addition circuits with \\(\\lceil n / 2 \\rceil\\) and \\(\\lfloor n / 2 \\rfloor\\) qubits. For simplicity, we only calculate the number of gates for powers of two, and assume all bits of the constant are set. Denoting this number as \\(f(n)\\) we get \\[f(n) = \\begin{cases}\n  0 &\\text{ for } n = 1 \\\\\n  8 &\\text{ for } n = 2 \\\\\n  8 n - 12 + 2 f(n / 2) \\\\\n  \\quad = 8 n \\log_2(n) - 10 n + 12 &\\text{ for } n &gt; 2\n\\end{cases} \\]"
  },
  {
    "objectID": "research/gaussian_convolution/index.html#toeplitz-matrix",
    "href": "research/gaussian_convolution/index.html#toeplitz-matrix",
    "title": "Building a Quantum Circuit for Gaussian Convolutions",
    "section": "5.1 Toeplitz matrix",
    "text": "5.1 Toeplitz matrix\nAs a reminder, this is the circuit we want to implement:\n\n\n\n\n\nWe have built all the parts in the previous chapters, but one detail was only mentioned briefly. Let \\(A_d\\) be the diagonals of the Toeplitz matrix. Instead of directly loading the values in PREP and using UNPREP only for combining the different values to a single state, we can follow chapter 2.3 from [1] and choose \\(p = 1 / 2\\) (which is shown there to be optimal), resulting in \\[\n\\text{PREP} \\ket{0}\n= \\frac{\\sum_d \\text{sgn}(A_d) \\sqrt{|A_d|} \\ket{d}}{\\sqrt{\\sum_d |A_d|}}\n\\] and \\[\n\\bra{0} \\text{UNPREP}\n= \\frac{\\sum_d \\sqrt{|A_d|} \\bra{d}}{\\sqrt{\\sum_d |A_d|}}\n\\]\nImplementing the Toeplitz matrix circuit is fairly simple now:\n\n\nCode\n\ndef toeplitz_matrix(\n    diags: npt.NDArray[float],\n    target: Sequence[int],\n    ancillae: Sequence[int],\n    overflow: Optional[int],\n    offset: int\n) -&gt; tq.QCircuit:\n    n = len(target)\n    N = 2 ** n\n    d = len(ancillae)\n    D = 2 ** d\n\n    if overflow is not None:\n        target = np.append(overflow, target)\n\n    U = tq.QCircuit()\n\n    prep_values = np.exp(np.angle(diags) * 1j) * np.sqrt(np.abs(diags))\n    U += prepare_state(state=array_to_state(prep_values), target=ancillae, ancillae=target)\n\n    U += addition_circuit(source=ancillae, target=target)\n\n    U += const_addition_circuit(target=target, const=-offset, ancillae=ancillae)\n\n    unprep_values = np.sqrt(np.abs(diags))\n    U += prepare_state(state=array_to_state(unprep_values), target=ancillae, ancillae=target).dagger()\n\n    return U\n\nWith this, we are at the point where we can implement the example matrix from the first chapter:\n\n\nCode\n\nn = 2\nN = 2 ** n\ndiags = np.array([exp(-i * i) for i in range(-1, 2)])\nd = ceil(log2(len(diags)))\n\ns = range(d)\nj = range(d, d + n)\noverflow = d + n\n\nU = toeplitz_matrix(diags=diags, target=j, ancillae=s, overflow=overflow, offset=3)\n\n...\n\nEven this small example results in a fairly large circuit, however that is expected, given the large constant factors in the gate counts:\n\n\n\n\n\nAt the start there are some redundant gates which could be simplified, this is due to the small circuit size and doesn’t happen for larger circuits. Some of the constructions from the previous chapters would need special handling for small registers to fix this.\nA way to verify that this circuit does what it is supposed to is to evaluate it on all the basis states and visualize the resulting matrix. We can also use this opportunity to show the postselection success probability.\nFor this, it is convenient to write a helper function to encode the input, perform the postselection, and return the result as a Numpy array/matrix instead of a Tequila wavefunction, particularly for when we later want to have multiple dimensions:\n\n\nCode\n\ndef eval_circuit(\n    states: Union[int, list[int]],\n    U: tq.QCircuit,\n    ranges: Union[int, list[int]],\n    offsets: Union[int, list[int]],\n    postselection_mask: int = 0\n) -&gt; tuple[np.ndarray, float]:\n    state_combined = 0\n    if isinstance(states, list):\n        for state, offset in zip(states, offsets):\n            state_combined |= state &lt;&lt; offset\n    else:\n        state_combined = states &lt;&lt; offsets\n\n    wvn = tq.simulate(prepare_basis_state(state_combined, U.n_qubits) + U, backend=\"qulacs\")\n    postselected = {k.integer: v for k, v in wvn.state.items() if k.integer & postselection_mask == 0}\n    angle = np.angle(postselected[min(postselected.keys())])\n\n    result = np.zeros(ranges, dtype=np.complex128)\n    for i, val in postselected.items():\n        if isinstance(ranges, list):\n            index = tuple((i &gt;&gt; offset) % N for offset, N in zip(offsets, ranges))\n        else:\n            index = (i &gt;&gt; offsets) % ranges\n        if result[index] != 0:\n            raise ValueError(\"Multiple values in the same state with different ancilla states.\")\n        result[index] = val * np.exp(-angle * 1j)\n    normalization = np.linalg.norm(result)\n    if normalization != 0:\n        result /= normalization\n    \n    return result, normalization\n\nThis makes visualizing the result with Pyplot simple:\n\n\nCode\n\n...\n\nresults = map(lambda j: eval_circuit(states=j, U=U, ranges=N, offsets=1, postselection_mask=0b11001), range(N))\ncolumns, normalizations = zip(*results)\nmatrix = np.column_stack(columns)\nnormalization = np.array(normalizations)\n\nfig, ax = plt.subplots(2, height_ratios=[N, 1], figsize=(10, 10))\n\nax[0].set_title(\"Operation Matrix\", fontsize=24)\nax[0].xaxis.set_major_locator(MaxNLocator(integer=True))\nax[0].yaxis.set_major_locator(MaxNLocator(integer=True))\nim0 = ax[0].imshow(np.real(matrix))\nfig.colorbar(im0, ax=ax[0])\n\nax[1].set_title(\"Postselection Probability\", fontsize=24)\nax[1].xaxis.set_major_locator(MaxNLocator(integer=True))\nax[1].yaxis.set_visible(False)\nim1 = ax[1].imshow(np.square(normalization).reshape(1, -1), vmin=0, vmax=1)\nfig.colorbar(im1, ax=ax[1])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\nThe top left corner might look wrong at first, but remember that each column has to be normalized, so we can’t get the exact matrix we intended. The third and fourth column are correct because none of the values are cut off, so the postselection has no effect.\nWe can also remove the overflow flag from the postselection mask to see what happens without it:\n\n\n\n\n\nThis might also look wrong at first, but this is because in a 4x4 matrix with 3 diagonals we only have one diagonal with value zero. The three values in the bottom left are what was cut off before, and now that we are skipping this step, you can see that the diagonals actually all have the same value.\nTo make the connection to the continuous convolution clearer, we can increase the number of qubits and plot the resulting wavefunction as a graph:\n\n\nCode\n\nn = 6\nN = 2 ** n\ndiags = np.array([exp(-i * i / 32) for i in range(-15, 16)])\nd = ceil(log2(len(diags)))\n\ns = range(d)\nj = range(d, d + n)\noverflow = d + n\n\nU = toeplitz_matrix(diags=diags, target=j, ancillae=s, overflow=overflow, offset=15)\nresult = eval_circuit(states=32, U=U, ranges=N, offsets=1, postselection_mask=0b111110000001)[0]\n\nplt.figure(figsize=(20, 10))\nplt.plot(np.real(result))\nplt.xlabel(\"State\")\nplt.ylabel(\"Amplitude\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\nFor comparison, this is what the function \\(g(x) = \\exp((x - 32)^2 / 32)\\) looks like:\n\n\n\n\n\nThe only major difference is the scale of the y-Axis, which is due to the normalization of quantum states.\nWe can also try what happens when we input a state that isn’t a basis state, but some superposition. Usually this superposition would be the result of the previous part of a larger circuit, but in our case we can simply add some Hadamard and NOT gates to get a similar effect. The circuit smooths the input state, as expected from a Gaussian convolution:\n\n\nCode\n\nn = 6\nN = 2 ** n\ndiags = np.array([exp(-i * i / 32) for i in range(-15, 16)])\nd = ceil(log2(len(diags)))\n\ns = range(d)\nj = range(d, d + n)\noverflow = d + n\n\nprepare = tq.QCircuit()\n# make sure qubits aren't optimized out\nfor i in range(n + d + 1):\n    prepare += tq.gates.Rz(angle=0, target=i)\nprepare += tq.gates.X(target=j[0])\nprepare += tq.gates.H(target=j[0])\nprepare += tq.gates.X(target=j[1])\nprepare += tq.gates.H(target=j[-1])\nprepare += tq.gates.H(target=j[-2])\n\ninit, _ = eval_circuit(states=0, U=prepare, ranges=N, offsets=1, postselection_mask=0b0)\n\nU = toeplitz_matrix(diags=diags, target=j, ancillae=s, overflow=overflow, offset=15)\n\nresult, _ = eval_circuit(states=0, U=prepare + U, ranges=N, offsets=1, postselection_mask=0b111110000001)\n\nfig, ax = plt.subplots(1, 2, figsize=(20, 10))\n\nax[0].set_title(\"Initialization\", fontsize=24)\nax[0].plot(np.real(init))\nax[0].set_xlabel(\"State\")\nax[0].set_ylabel(\"Amplitude\")\n\nax[1].set_title(\"Result\", fontsize=24)\nax[1].plot(np.real(result))\nax[1].set_xlabel(\"State\")\nax[1].set_ylabel(\"Amplitude\")\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "research/gaussian_convolution/index.html#gate-count-3",
    "href": "research/gaussian_convolution/index.html#gate-count-3",
    "title": "Building a Quantum Circuit for Gaussian Convolutions",
    "section": "5.2 Gate count",
    "text": "5.2 Gate count\nLet \\(D\\) be the number of diagonals and a power of 2, and \\(d = log_2(D)\\) the size of the s register. Let \\(n\\) be the number of input and output qubits and assume \\(n + 1\\) is a power of 2 and that \\(n + 1 - d \\geq 5\\). The \\(+1\\) is because we also need to consider the overflow gate in the addition operations. Assuming the values of the diagonals are real and non-negative (otherwise the PREP and UNPREP operation would use more gates), we get the following gate counts:\n\n\\(2 D - 5\\) rotations and \\(D \\cdot (4 \\log_2(D) - 14) + 24\\) Toffoli gates for the PREP and UNPREP block each\n\\(2 d + 22 (n + 1 - d) - 14\\) Toffoli gates for the addition or two less if \\(n + 1 - d\\) is odd\nup to \\(8 (n + 1) \\log_2(n + 1) - 10 (n + 1) + 12\\) Toffoli gates for the constant addition, depending on the constant\n\nSo the total number of rotations is up to \\(4 D - 10 \\in O(D)\\), and the total number of Toffoli gates is up to \\(2 D \\cdot (4 d - 14) - 20 d + 8 (n + 1) \\log_2(n + 1) + 12 n + 58\\) \\(\\in O(D \\log(D) +n \\log(n))\\)."
  },
  {
    "objectID": "research/gaussian_convolution/index.html#postselection-success-probability",
    "href": "research/gaussian_convolution/index.html#postselection-success-probability",
    "title": "Building a Quantum Circuit for Gaussian Convolutions",
    "section": "5.3 Postselection success probability",
    "text": "5.3 Postselection success probability\nAnother important factor when considering the cost of this algorithm is subnormalization, which influences the chance that the postselection succeeds, as this will determine how often the algorithm needs to be repeated.\nIf we don’t postselect the overflow qubit, the implementation here is optimal. This is because the uniform wavefunction \\(\\ket{\\psi} = \\frac{1}{\\sqrt{N}} \\sum_{k = 0}^{N - 1} \\ket{k}\\) is a fixpoint of our algorithm. A Gaussian convolution has a smoothing effect, so if the wavefunction is already completely uniform, there is nothing left for it to do. But here, we are less interested in the shape of the result, and more in the norm. For this we need to multiply the scale of the PREP and UNPREP operations from earlier, which gives us the factor \\(1 / \\sum_d |A_d|\\). However this is the exact value that the result gets from summing the different terms (except for a phase, which doesn’t matter for our uniform wavefunction), so it cancels out, and we get scale \\(1\\), i.e. a postselection success probability of 100%. This shows that we can’t possibly achieve a lower subnormalization, because then we could map \\(\\ket{\\psi}\\) to a wavefunction with norm greater than \\(1\\).\nThis doesn’t apply with the postselection on the overflow bit, but if we assume that the kernel is much smaller than the wavefunction (which we have to anyways, because of the exponential costs), then only a small number of values is removed, so the norm is still close to \\(1\\), and the circuit thus close to optimal.\nOf course for other wavefunctions the success probability can be much lower or even \\(0\\), e.g. a quickly oscillating function where the positive and negative parts cancel out when smoothed, but this is due to the operation, not the implementation."
  },
  {
    "objectID": "research/gaussian_convolution/index.html#multiple-dimensions",
    "href": "research/gaussian_convolution/index.html#multiple-dimensions",
    "title": "Building a Quantum Circuit for Gaussian Convolutions",
    "section": "5.4 Multiple dimensions",
    "text": "5.4 Multiple dimensions\nNow that we have implemented the one dimensional case, we can easily extend this to multiple dimensions by simply running the same circuit on multiple registers in parallel:\n\n\nCode\n\nn = 4\nN = 2 ** n\ndiags = np.array([exp(-i * i / 4) for i in range(-3, 4)])\nd = ceil(log2(len(diags)))\n\ns1 = range(d)\nj1 = range(d, d + n)\noverflow1 = d + n\ns2 = range(overflow1 + 1, overflow1 + d + 1)\nj2 = range(overflow1 + d + 1, overflow1 + d + n + 1)\noverflow2 = overflow1 + d + n + 1\n\nU = toeplitz_matrix(diags=diags, target=j1, ancillae=s1, overflow=overflow1, offset=3)\nU += toeplitz_matrix(diags=diags, target=j2, ancillae=s2, overflow=overflow2, offset=3)\n\n...\n\nThis is also the point where wrapping the evaluation in eval_circuit starts to really help, because otherwise dealing with multiple input and output registers quickly becomes hard to read. It also allows to easily parallelize the evaluation of multiple states using the Python multiprocessing module (at the time of writing this helped due to inefficiencies in the Tequila simulate function, but since version 1.9.7 this should no longer be necessary). We will not evaluate every basis state, instead, confirming that it behaves correctly in the center, at the edges and in corners should be sufficient:\n\n\nCode\n\n...\n\nfig, ax = plt.subplots(3, 3, figsize=(20, 20))\n\noffsets = [0, 7, 15]\nwith Pool(9) as p:\n    results = p.starmap(eval_circuit, zip(\n        map(lambda x: list(x), product(offsets, offsets)),  # states\n        repeat(U),  # U\n        repeat([N, N]),  # ranges\n        repeat([1, n + d + 2]),  # offsets\n        repeat(0b1110000111100001),  # postselection mask\n    ))\n    matrices, normalizations = zip(*results)\n    for plot_i, plot_j in product(range(3), range(3)):\n        im = ax[plot_i, plot_j].imshow(np.real(matrices[3 * plot_i + plot_j]))\n        fig.colorbar(im, ax=ax[plot_i, plot_j])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\nWe can again add some initialization code to see how the circuit operates on other input:\n\n\nCode\n\nn = 4\nN = 2 ** n\ndiags = np.array([exp(-i * i / 4) for i in range(-3, 4)])\nd = ceil(log2(len(diags)))\n\ns1 = range(d)\nj1 = range(d, d + n)\noverflow1 = d + n\ns2 = range(overflow1 + 1, overflow1 + d + 1)\nj2 = range(overflow1 + d + 1, overflow1 + d + n + 1)\noverflow2 = overflow1 + d + n + 1\n\nprepare = tq.QCircuit()\n# make sure qubits aren't optimized out\nfor i in range(2 * (n + d + 1)):\n    prepare += tq.gates.Rx(angle=0, target=i)\nprepare += tq.gates.X(target=j1[1])\nprepare += tq.gates.H(target=j1[-2])\nprepare += tq.gates.H(target=j1[-1])\nprepare += tq.gates.H(target=j2[0])\nprepare += tq.gates.X(target=j2[1])\n\ninit, _ = eval_circuit(states=[0, 0], U=prepare, ranges=[N, N], offsets=[1, n + d + 2], postselection_mask=0)\n\nU = prepare + toeplitz_matrix(diags=diags, target=j1, ancillae=s1, overflow=overflow1, offset=3)\nU += toeplitz_matrix(diags=diags, target=j2, ancillae=s2, overflow=overflow2, offset=3)\n\nresult, _ = eval_circuit(states=[0, 0], U=U, ranges=[N, N], offsets=[1, n + d + 2],\n                         postselection_mask=0b1110000111100001)\n\nfig, ax = plt.subplots(1, 2, figsize=(20, 10))\n\nax[0].set_title(\"Initialization\", fontsize=24)\nim0 = ax[0].imshow(np.real(init))\nfig.colorbar(im0, ax=ax[0])\n\nax[1].set_title(\"Result\", fontsize=24)\nim1 = ax[1].imshow(np.real(result))\nfig.colorbar(im1, ax=ax[1])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\nIn this example, you could also ignore the postselection because no values wrap around, so it doesn’t have any effect."
  },
  {
    "objectID": "research/gaussian_convolution/index.html#lcu",
    "href": "research/gaussian_convolution/index.html#lcu",
    "title": "Building a Quantum Circuit for Gaussian Convolutions",
    "section": "5.5 LCU",
    "text": "5.5 LCU\nLastly, we will see how to use a linear combination of unitaries to implement a weighted sum of Gaussian convolutions. This is not part of the algorithm, so we will only look at this briefly, but it seems likely that usecases of Gaussian convolutions will require it, and it is fairly simple with the tools developed already.\nWe will use the method described in [7]. The PREP block there is the same block we built in the second chapter, and the selection operator can be implemented in the same way as the multi controlled rotations in the PREP operator, so we get the following code:\n\n\nCode\n\ndef lcu(\n    circuits: Sequence[tq.QCircuit],\n    coefficients: npt.NDArray[float],\n    flags: Sequence[int],\n    ancillae: Sequence[int]\n) -&gt; tq.QCircuit:\n    flags = flags[:ceil(log2(len(circuits)))]\n\n    U = tq.QCircuit()\n\n    prep_values = np.exp(np.angle(coefficients) * 1j) * np.sqrt(np.abs(coefficients))\n    U += prepare_state(state=array_to_state(prep_values), target=flags, ancillae=ancillae)\n\n    for i, (circuit, coefficient) in enumerate(zip(circuits, coefficients)):\n        diff = i ^ (i - 1)\n        for j in range(len(flags)):\n            if diff & (1 &lt;&lt; j):\n                U += tq.gates.X(target=flags[-j - 1])\n        U += circuit.add_controls(flags)\n\n    # Handle the case that the number of circuits is not a power of 2\n    for j in range(len(flags)):\n        if not (len(circuits) - 1) & (1 &lt;&lt; j):\n            U += tq.gates.X(target=flags[-j - 1])\n\n    unprep_values = np.sqrt(np.abs(coefficients))\n    U += prepare_state(state=array_to_state(unprep_values), target=flags, ancillae=ancillae).dagger()\n\n    return U\n\nAs a simple example, we can reuse the previous two dimensional circuit, but add a second convolution with the same values but slightly shifted. We give a negative coefficient to this new convolution, and double the weight of the original convolution:\n\n\nCode\n\nn = 4\nN = 2 ** n\ndiags = np.array([exp(-i * i / 4) for i in range(-3, 4)])\nd = ceil(log2(len(diags)))\n\ns1 = range(d)\nj1 = range(d, d + n)\noverflow1 = d + n\ns2 = range(overflow1 + 1, overflow1 + d + 1)\nj2 = range(overflow1 + d + 1, overflow1 + d + n + 1)\noverflow2 = overflow1 + d + n + 1\nlcu_flag = overflow2 + 1\n\nprepare = tq.QCircuit()\n# make sure qubits aren't optimized out\nfor i in range(2 * (n + d + 1)):\n    prepare += tq.gates.Rx(angle=0, target=i)\nprepare += tq.gates.X(target=j1[1])\nprepare += tq.gates.H(target=j1[-2])\nprepare += tq.gates.H(target=j1[-1])\nprepare += tq.gates.H(target=j2[0])\nprepare += tq.gates.X(target=j2[1])\n\ninit, _ = eval_circuit(states=[0, 0], U=prepare, ranges=[N, N], offsets=[1, n + d + 2], postselection_mask=0)\n\nU1 = toeplitz_matrix(diags=diags, target=j1, ancillae=s1, overflow=overflow1, offset=3)\nU1 += toeplitz_matrix(diags=diags, target=j2, ancillae=s2, overflow=overflow2, offset=3)\n\nU2 = toeplitz_matrix(diags=diags, target=j1, ancillae=s1, overflow=overflow1, offset=-1)\nU2 += toeplitz_matrix(diags=diags, target=j2, ancillae=s2, overflow=overflow2, offset=1)\n\nU = prepare + lcu(circuits=[U1, U2], coefficients=np.array([2, -1]), flags=[lcu_flag], ancillae=range(lcu_flag))\n\nresult, _ = eval_circuit(states=[0, 0], U=U, ranges=[N, N], offsets=[2, n + d + 3],\n                         postselection_mask=0b11100001111000011)\n\nfig, ax = plt.subplots(1, 2, figsize=(20, 10))\nax[0].set_title(\"Initialization\", fontsize=24)\nim0 = ax[0].imshow(np.real(init))\nfig.colorbar(im0, ax=ax[0])\nax[1].set_title(\"Result\", fontsize=24)\nim1 = ax[1].imshow(np.real(result))\nfig.colorbar(im1, ax=ax[1])\nplt.show()"
  },
  {
    "objectID": "research/gaussian_convolution/index.html#conclusion",
    "href": "research/gaussian_convolution/index.html#conclusion",
    "title": "Building a Quantum Circuit for Gaussian Convolutions",
    "section": "5.6 Conclusion",
    "text": "5.6 Conclusion\nIn this post, we have seen how we can implement a Gaussian convolution on a quantum superposition. For this we developed circuits which can prepare arbitrary states, add a value in a register to another register, and add a constant to a register. Combining these three operations allowed us to implement any Toeplitz matrix, including one dimensional Gaussian convolutions. Since Gaussian convolutions are separable, we were able to simply run this algorithm multiple times in parallel to extend it to multiple dimensions. We have also briefly seen that it is possibly to combine multiple convolutions to weighted sums of convolutions.\nTo be efficient, we need to approximate the convolution by cutting it off after a certain number of values, but this should rarely be an issue because of how quickly the coefficients of a Gaussian convolution drop towards \\(0\\). We achieved asymptotic rotation and Toffoli gate count of \\(O(D \\log(D) + n \\log(n))\\) for the one dimensional convolution, where \\(D\\) is the number of values that are considered, and \\(n\\) is the number of input and output qubits. By borrowing qubits which are already in use, the algorithm is able to avoid using dedicated ancilla qubits in most places.\nDespite these favourable characteristics, there is likely to be much room for optimization, particularly for the large constant factors. Also the decompositions here focused on Toffoli gates, it would be interesting to see what costs can be achieved with different operations instead, like single qubit rotations and CNOTs."
  },
  {
    "objectID": "research/gaussian_convolution/index.html#references",
    "href": "research/gaussian_convolution/index.html#references",
    "title": "Building a Quantum Circuit for Gaussian Convolutions",
    "section": "5.7 References",
    "text": "5.7 References\n\n\n[1] C. Sünderhauf, E. Campbell, and J. Camps, “Block-encoding structured matrices for data input in quantum computing,” Quantum, vol. 8, p. 1226, Jan. 2024, doi: 10.22331/q-2024-01-11-1226.\n\n\n[2] V. V. Shende, S. S. Bullock, and I. L. Markov, “Synthesis of quantum-logic circuits,” IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, vol. 25, no. 6, pp. 1000–1010, Jun. 2006, doi: 10.1109/tcad.2005.855930.\n\n\n[3] C. Gidney, “Trouble adding constants into qubit registers.” Accessed: May 31, 2024. [Online]. Available: https://algassert.com/post/1701\n\n\n[4] Y. Takahashi, S. Tani, and N. Kunihiro, “Quantum addition circuits and unbounded fan-out.” 2009. Available: https://arxiv.org/abs/0910.2530\n\n\n[5] C. Gidney, “Constructing large increment gates.” Accessed: May 31, 2024. [Online]. Available: https://algassert.com/circuits/2015/06/12/Constructing-Large-Increment-Gates.html\n\n\n[6] T. Häner, M. Roetteler, and K. M. Svore, “Factoring using 2n+2 qubits with toffoli based modular multiplication.” 2017. Available: https://arxiv.org/abs/1611.07995\n\n\n[7] D. Guala, J. Soni, and J. M. Arrazola, “Linear combination of unitaries and block encodings.” Accessed: Jun. 16, 2024. [Online]. Available: https://pennylane.ai/qml/demos/tutorial_lcu_blockencoding/\n\n\nThe bibliography uses a citation style file from the CSL project: https://citationstyles.org/"
  },
  {
    "objectID": "research/quantum_classifier/quantum_classifier.html",
    "href": "research/quantum_classifier/quantum_classifier.html",
    "title": "Building a Variational Quantum Classifier",
    "section": "",
    "text": "Currently, Convolutional and Deep Neural Networks are at the forefront of research in Machine Learning and Computer Science in general. These networks show the best results in solving complex tasks such as Language Processing and Image Generation. On the other hand, in the area of quantum algorithms, scientists are trying to find algorithms and use cases, where quantum computing creates a unique advantage over classical computers. With the current boom of Machine Learning and Neural Networks, one avenue where quantum advantage might be found would be quantum machine learning. In this area, certain aspects of the classical approach are replaced by quantum systems or data. With the currently available quantum computers, one of the most successful approaches uses Variational Quantum Algorithms, as these work fairly well with only a limited amount of qubits and noise. As a result, there has been a lot of work regarding Quantum Machine Learning using Variational Quantum Algorithms. This tutorial will implement one such algorithm. The implementation will solve a classification task and will do so based on the paper by Pérez-Salinas et al. (2020), where the quantum circuit only uses a single qubit and rotational gates to solve the given task. The simulation will be implemented with the Tequila API (Kottmann et al. 2021) using the qulacs backend for computations. The data and result will be visualized with Matplotlib (Hunter 2007) and Qutip (Johansson, Nation, and Nori 2013).\n\n\nCode\nimport tequila as tq\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport qutip"
  },
  {
    "objectID": "research/quantum_classifier/quantum_classifier.html#machine-learning",
    "href": "research/quantum_classifier/quantum_classifier.html#machine-learning",
    "title": "Building a Variational Quantum Classifier",
    "section": "Machine Learning",
    "text": "Machine Learning\nIn the most general sense, supervised machine learning aims to train a model using known data to infer knowledge about unknown data based on the training result. In mathematical terms, we are trying to learn some function \\(M: \\mathcal{X} \\to \\mathcal{Y}\\) where \\(\\mathcal{X}\\) is the set of all possible data points and \\(\\mathcal{Y}\\) is the set of labels. We do this using only a relatively small set of data points \\(\\{x_i\\}\\subset \\mathcal{X}\\) with their labels \\(\\{y_i\\}\\subset \\mathcal{Y}\\) and use these to train the parameters \\(\\theta\\) of a model \\(M_\\theta(x)\\). Through the training we get some optimal parameters \\(\\theta_{opt}\\) such that \\(M_{\\theta_{opt}}(x_i)\\) is the best approximation of \\(y_i\\). We can then take an unseen data point \\(x\\in\\mathcal{X}\\) and use our trained model to assign a label \\({y}\\). We do this by calculating \\(M_{\\theta_{opt}}(x)\\) and assigning the result as the label for \\(x\\). One of the most famous examples for this would be the classification of images using a neural network. In that case, the function we are trying to learn maps images to labels. We take a neural network \\(N_{w,\\theta}(x)\\) with some tunable weights \\(w\\) and biases \\(\\theta\\) and train it using some labeled images. After the training, the neural network should have learned some pattern in the data, and we now can insert a new image, which will return the optimal label based on the training images.\nThere are many choices which determine the quality of the result. These consist of:\n\nThe model and its associated parameters\nThe choice of the loss function\nTh optimization routine\n\nThe optimal answers to these questions are in most cases problem specific and chosen based on additional knowledge. The aforementioned choices will be further explained when we need to implement them in section 3."
  },
  {
    "objectID": "research/quantum_classifier/quantum_classifier.html#variational-quantum-algorithms-and-quantum-machine-learning",
    "href": "research/quantum_classifier/quantum_classifier.html#variational-quantum-algorithms-and-quantum-machine-learning",
    "title": "Building a Variational Quantum Classifier",
    "section": "Variational Quantum Algorithms and Quantum Machine Learning",
    "text": "Variational Quantum Algorithms and Quantum Machine Learning\nWe can view Quantum Machine Learning from two different perspectives. From a machine learning point of view, we simply use a parameterized quantum circuit as our model, and try to adapt all other parts to fit the concepts of this circuit. The other viewpoint considers general Variational Quantum Algorithms (VQAs), which are hybrid algorithms that involve a parameterized quantum circuit and classical computation to optimize the parameters. These VQAs can also be used to solve tasks that are native to machine learning, which would lead us again to quantum machine learning.\nWe can examine the basic structure of a VQA through a simple example using Tequila:\n\n1a = tq.Variable(name=\"a\")\nb = tq.Variable(name=\"b\")\n2Unitary = tq.gates.Rx(np.pi * a, target=0) + tq.gates.Ry(np.pi * b, target=0)\n\n3Observable = tq.paulis.X(0) + tq.paulis.Y(0)\n4Objective = tq.ExpectationValue(U=Unitary, H=Observable)\n\n5initial_values = {a: 1, b:1}\n6minimized = tq.minimize(Objective,variables=[a,b],initial_values=initial_values, silent=True)\n7print('minimal value of the objective: ', minimized.energy)\nprint('optimal variable values: \\n', minimized.angles)\n\n\n1\n\nInitialize tunable variables, that will be optimized later\n\n2\n\nCreate a unitary/quantum circuit using a given problem structure\n\n3\n\nDefine an Observable whose expectation we want to measure\n\n4\n\nDefine the Objective/Loss function we want to minimize as the expectation value of the Observable after applying the Unitary\n\n5\n\nDefine some initial values for the variables we want to optimize\n\n6\n\nMinimize the Objective through one of many different minimization methods to compute optimal variable assignments\n\n7\n\nReturn the calculated parameters of the circuit and the minimal value of the Objective\n\n\n\n\nminimal value of the objective:  -1.4142135607453392\noptimal variable values: \n a : 0.2499994506269027\nb : -0.499978415813107\n\n\n\nThe bulk of the work is done in the minimization step, where we iteratively calculate the current value of the objective and its gradient and use these values to determine some small changes to the parameters so that we can further improve the result. The objective describes the error of our circuit and the minimum would be the parameter assignment that has the least error. Using this setup, we can now build a VQA to do classification."
  },
  {
    "objectID": "research/quantum_classifier/quantum_classifier.html#the-data-for-classification",
    "href": "research/quantum_classifier/quantum_classifier.html#the-data-for-classification",
    "title": "Building a Variational Quantum Classifier",
    "section": "3.1 The data for Classification",
    "text": "3.1 The data for Classification\nWe first need to determine the data we want to classify. For general data, there are several complicated questions that arise when trying to insert a data point in the circuit. The usual data, like numbers, vectors, matrices or higher dimensional data are best represented using a classical computer, and we need to figure out how to transform the representation as many bits onto a quantum circuit with only a few qubits. We will address this in section 3.3. In order to visualize the data and to assess the quality of our training, we will be using elements of \\(\\mathbb{R}^2\\). We further restrict ourselves to the area \\([0,2]\\times [0,2]\\). In this area we draw three partially overlapping circles, resulting in four total classes including the background (Figure 1). We create three different lists. visual to simply show what the classes look like, test_data to see if the trained circuit is able to classify correctly, and training_data with associated labels, which is used to train the model.\n\n\nCode\ndef get_random_point():\n    return random.uniform(0.0, 2.0), random.uniform(0.0, 2.0)\n\n\n\ndef calculate_label(datapoint):\n    circle1 = ((0.0,0.0), np.pi / 2)\n    circle2 = ((0.5,1.75), np.pi / 8)\n    circle3 = ((2.0,2.0), np.pi / 4)\n    if np.linalg.norm((datapoint[0] - circle1[0][0], datapoint[1]- circle1[0][1])) &lt; circle1[1]:\n        return 1\n    elif np.linalg.norm((datapoint[0] - circle2[0][0], datapoint[1]- circle2[0][1])) &lt; circle2[1]:\n        return 2\n    elif np.linalg.norm((datapoint[0] - circle3[0][0], datapoint[1]- circle3[0][1])) &lt; circle3[1]:\n        return 3\n    else:\n        return 0\n    pass\n\n\ndef visualize_points(data_set):\n    colors = []\n    for data_point in data_set:\n        if data_point[2] == 1:\n            colors.append('r')\n        elif data_point[2] == 2:\n            colors.append('g')\n        elif data_point[2] == 3:\n            colors.append('y')\n        else:\n            colors.append('b')\n    fig, ax = plt.subplots(figsize=(5, 5))\n    ax.scatter([dp[0] for dp in data_set], [dp[1] for dp in data_set], c=colors, marker='.')\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    pass\n\n\n\nvisual = [get_random_point() for _ in range(10000)]\nvisual = [(dp[0],dp[1],calculate_label(dp)) for dp in visual]\n\ntest_data =[get_random_point() for _ in range(1000)]\n\ntraining_data = [get_random_point() for _ in range(250)]\nlabels = [calculate_label(dp) for dp in training_data]\n\nvisualize_points(visual)\n\n\n\n\nFigure 1: Data to be classified"
  },
  {
    "objectID": "research/quantum_classifier/quantum_classifier.html#measurement-and-interpretation",
    "href": "research/quantum_classifier/quantum_classifier.html#measurement-and-interpretation",
    "title": "Building a Variational Quantum Classifier",
    "section": "3.2 Measurement and interpretation",
    "text": "3.2 Measurement and interpretation\nBefore looking at our Ansatz, we will first look at what we do with the final state. When we insert a data point in the circuit, we will find some final state, which we now need to measure, to infer the classification result. The circuit prepares a state \\(|\\phi\\rangle = c_0 |0\\rangle + c_1 |1\\rangle\\). If we simply measure in the computational basis, we have the result \\(|0\\rangle\\) with a probability of \\(p_0=|c_0|^2\\) and the result \\(|1\\rangle\\) with probability \\(p_1=|c_1|^2\\).\nFor more information, we need to prepare the final state several times in order to measure the expectation value of some observable. The simplest case would be to measure the observable \\(\\Lambda = |1\\rangle\\langle 1| = \\begin{pmatrix} 0 & 0\\\\ 0 & 1 \\end{pmatrix}\\), where we would receive \\[\\langle \\Lambda \\rangle = \\langle \\phi |\\Lambda| \\phi \\rangle = \\langle \\phi | 1\\rangle\\langle 1|\\phi \\rangle =  c_1^* c_1 = |c_1|^2 =  p_1\\] which lets us classify based on the probabilities. Binary data with only two classes \\(0\\) and \\(1\\) can be labeled in a straightforward manner: If \\(p_1 &lt; 0.5\\) we choose class \\(0\\), otherwise we assign the label \\(1\\). For our more general case with four classes, we have several different ways we could assign labels:\n\nSeveral thresholds\nWe can directly generalize the way we classify by adding more divisions of \\(p_1\\). \\(p_1\\) takes values in \\([0,1]\\). If we divide this interval into \\(n\\) different sections, we have a way of distinguishing \\(n\\) classes. We can interpret this on the Bloch sphere as making parallel slices of the sphere so that we get \\(n\\) bands. We than classify based on the band the state is on.\n\n\nAssignment using Projectors\nOne interpretation of the binary classification, would be to think of \\(p_1\\) as the fidelity between \\(|1\\rangle\\) and \\(|\\phi\\rangle\\). This would mean, that we choose label \\(1\\) if the fidelity between \\(|1\\rangle\\) and \\(|\\phi\\rangle\\) is bigger than between \\(|0\\rangle\\) and \\(|\\phi\\rangle\\). This allows for a different kind of generalization: We determine \\(n\\) different states \\(|\\psi_i\\rangle\\) as the representatives of \\(n\\) different classes. We then calculate the fidelity between the output of the circuit with all of these \\(n\\) label states and assign the label that is closest to the output, i.e. the one with the highest fidelity. We can compute these fidelities by calculating the expectation value of the projector onto the label states \\(\\Lambda_i = |\\psi_i\\rangle\\langle\\psi_i|\\), which would be \\[\n\\langle\\Lambda_i\\rangle = \\langle \\phi |\\psi_i\\rangle\\langle\\psi_i| \\phi \\rangle = \\langle \\psi_i |\\phi\\rangle^*\\langle\\psi_i| \\phi \\rangle = |\\langle\\psi_i| \\phi \\rangle|^2.\n\\] The \\(i\\) for which this value is maximal will be the label for \\(| \\phi \\rangle\\). We will use this method to assign labels using the trained circuit. We still need to examine how we choose these label states. The criterion for these should be, that they are as far apart as possible. One way to specify that would be to find states such that \\(min_{i,j} |\\langle\\psi_i|\\psi_j \\rangle |^2\\) is as big as possible. In terms of the Bloch Sphere we search \\(n\\) points on the sphere that have the highest pairwise distance. For 4,6,8,12 and 20 classes it is fairly intuitive that we get these label states as the vertices of the respective regular polyhedron. For all other amounts this is a harder question to answer. For 4 classes the label states can be seen in (Figure 2).\n\ndef get_label_state(n):\n    if n == 0:\n        return tq.QubitWaveFunction.from_array([1,0])\n    if n == 1:\n        return tq.QubitWaveFunction.from_array([1 / np.sqrt(3), np.sqrt(2/3)])\n    if n == 2:\n        return tq.QubitWaveFunction.from_array([1 / np.sqrt(3),np.exp(1j * 2 * np.pi / 3) * np.sqrt(2 / 3)])\n    if n == 3:\n        return tq.QubitWaveFunction.from_array([1 / np.sqrt(3), np.exp(-1j * 2 * np.pi / 3) * np.sqrt(2 / 3)])\n    pass\n\n\ndef fidelity(circuit, label_state):\n    \"\"\"\n\n    :param circuit: The quantum circuit\n    :param label_state: The wave function of the label state\n    :return: The expectation value of the projector onto func in the state prepared by circuit\n    \"\"\"\n    projector = tq.paulis.Projector(wfn=label_state)\n    objective = tq.ExpectationValue(circuit, projector)\n    return objective\n\n\n\nCode\ndef show_label_states():\n    x1 = qutip.Qobj(tq.QubitWaveFunction.to_array(get_label_state(0)))\n    x2 = qutip.Qobj(tq.QubitWaveFunction.to_array(get_label_state(1)))\n    x3 = qutip.Qobj(tq.QubitWaveFunction.to_array(get_label_state(2)))\n    x4 = qutip.Qobj(tq.QubitWaveFunction.to_array(get_label_state(3)))\n\n    fig = plt.figure(figsize=(13,12), layout='constrained')\n    ax1 = fig.add_subplot(1,3,1, projection='3d')\n    ax1.set_title(\"label states\")\n    ax2 = fig.add_subplot(1,3,2, projection='3d')\n    ax2.set_title(\"Real part\")\n    ax2.azim = 90\n    ax2.elev = 0\n    ax3 = fig.add_subplot(1,3,3, projection='3d')\n    ax3.set_title(\"Top down view\")\n    ax3.elev = 90\n\n    b = qutip.Bloch(fig=fig, axes=ax1)\n    b.vector_width = 2\n    b.add_states([x1,x2,x3,x4])\n    b.render()\n\n    b2 = qutip.Bloch(fig=fig, axes=ax2)\n    b2.vector_width = 2\n    b2.add_states([x1,x2,x3,x4])\n    b2.render()\n\n    b3 = qutip.Bloch(fig=fig, axes=ax3)\n    b3.vector_width = 2\n    b3.add_states([x1,x2,x3,x4])\n    b3.render()\n\nshow_label_states()\n\n\n\n\n\nFigure 2: Label states for 4 classes from several angles\n\n\n\n\n\n\nAssignment using the full state\nIn the previous solution, we needed one measurement of an expectation value for each class. For a circuit with only one qubit, this seems unreasonably high, as the full state is only characterized by two real numbers and given the full state we could easily calculate the fidelities with all label states. So we might be able to get rid of the scaling number of calculated expectation values if we are able to just calculate the full state with a constant number of expectation values. This is indeed possible using a state tomography protocol, which allows us to obtain the full state with only three expectation values for a single qubit (Schmied 2016). We can visualize the information we gain from a single expectation value using the Bloch sphere. For this we look at the state \\(|-i\\rangle\\) and the three pojectors \\(|0\\rangle\\langle 0|\\), \\(|+\\rangle\\langle +|\\),\\(|i\\rangle\\langle i|\\). Assuming we don’t know that the sytem is in state \\(|-i\\rangle\\), we will figure this out using the three expectation values of the projectors. The expectation value of \\(|0\\rangle\\langle 0|\\) will have the result \\(0.5\\), which gives us the information that the state has to be on the ring seen in Figure 3. \\(\\langle (|+\\rangle\\langle +|)\\rangle\\) will also be \\(0.5\\), so that we are now restricted to two possible states, the ones where both rings intersect in Figure 3. After the final measurement we will now be able to fully determine the final state of the system. This works for all one-qubit states.\nTheoretically this an also be done for more qubits, but requires an exponential amount of expectation values, as the dimensionality of the state also grows exponentially.\n\n\nCode\ndef add_line(bloch, x,y):\n    bloch.add_arc(x, y)\n    bloch.add_arc(-x, y)\n    bloch.add_arc(x, -y)\n    bloch.add_arc(-y, -x)\n\ndef tomography():\n    fig = plt.figure(figsize=(10,10), layout='constrained')\n    ax1 = fig.add_subplot(1,3,1, projection='3d')\n    ax2 = fig.add_subplot(1,3,2, projection='3d')\n    ax3 = fig.add_subplot(1,3,3, projection='3d')\n\n    b1 = qutip.Bloch(fig=fig, axes=ax1)\n    b2 = qutip.Bloch(fig=fig, axes=ax2)\n    b3 = qutip.Bloch(fig=fig, axes=ax3)\n    X = np.arange(-1, 1, 0.1)\n    Y = np.arange(-1, 1, 0.1)\n    Z = np.ones((20,20))\n\n    b1.add_vectors([0,0,1])\n    add_line(b1, np.array([1,0,0]), np.array([0,1,0]))\n    ax1.plot_surface(X, Y, Z)\n    b2.add_vectors([1,0,0])\n    add_line(b2, np.array([1,0,0]), np.array([0,1,0]))\n    add_line(b2, np.array([0,1,0]), np.array([0,0,1]))\n    b2.add_points([[0,0],[1,-1],[0,0]])\n\n    b3.add_vectors([0,1,0])\n    b3.add_points([0,-1,0])\n\n    b1.render()\n    b2.render()\n    b3.render()\n    plt.show()\n\ntomography()\n\n\n\n\n\nFigure 3: Possible states after one, two and three measurements. The arrow describes the projector we are measuring"
  },
  {
    "objectID": "research/quantum_classifier/quantum_classifier.html#ansatz",
    "href": "research/quantum_classifier/quantum_classifier.html#ansatz",
    "title": "Building a Variational Quantum Classifier",
    "section": "3.3 Ansatz",
    "text": "3.3 Ansatz\nAfter figuring out how we turn the final state into a classification result, we can look at the circuit that prepares the final state. We need to build a parameterized circuit, that allows us to insert a datapoint \\(x\\) and parameters \\(\\theta\\). We will be limited to gates that operate on one qubit, so our main choices are rotations \\(R_x,R_y,R_z\\). Using only rotations, it would be impossible to separate the data nonlinearly if we inserted the datapoint only once. We need a layered structure, where each layer inserts the datapoint and some of the parameters. The entire circuit has the form \\[\nU(\\theta,x) = L(N)...L(1)\n\\] where \\(N\\) is the amount of layers in our circuit. One layer is then composed of several rotations \\[\nL(i)= R_z(\\theta_{2i+1}+x_2) R_y(\\theta_{2i} + x_1)\n\\] using a set of \\(2N\\) angles \\(\\theta\\) and the datapoint \\(x=(x_1,x_2)\\). The amount of layers determines the depth of our circuit, as we apply two gates per layer. Also, the amount of computation needed increases as we introduce more layers, as we get two parameters for each layer.\nWhy did we choose the setup with one \\(R_z\\) and \\(R_y\\) gate? This choice was to a certain level arbitrary. We chose two gates as we use data from \\(\\mathbb{R}^2\\), where every gate encodes one of the two values. The choice for the type of gates was made, so that it is possible to rotate every state to every other state. Any combination of two different rotations would be satisfactory, so this choice was arbitrary.\nWe could adapt the layers to encode more parameters, by introducing weights \\(w\\) for every insertion of the datapoint. One layer would then look like \\[\nL(i)= R_z(\\theta_{2i+1}+w_{2i+1} x_2) R_y(\\theta_{2i} + w_{2i}x_1).\n\\] In theory this increases the expressiveness of the circuit. If we replaced the unweighted layers with their weighted alternatives, we only need to set all weights to 1 and would receive the same result as the unweighted case. The computation will be more expensive, but the final result should always be as good as for the unweighted case or even better. We will see if this assumption holds true in section 4.\n\ndef create_circuit(x, angles):\n    circuit = tq.QCircuit()\n    for i in range(len(angles) // 2):\n        circuit += tq.gates.Ry(angles[2*i] + x[0],0) + tq.gates.Rz(angles[2*i+1] + x[1],0)\n    return circuit"
  },
  {
    "objectID": "research/quantum_classifier/quantum_classifier.html#loss-function",
    "href": "research/quantum_classifier/quantum_classifier.html#loss-function",
    "title": "Building a Variational Quantum Classifier",
    "section": "3.4 Loss function",
    "text": "3.4 Loss function\nNow we have everything required to calculate a label for a datapoint and will now examine how we determine the correctness of this assignment. This is done through the loss function. Given a set of values for the parameters in the circuit and the training data, the loss function evaluates how close the result of the circuit is to the actual labels. One possible function is \\[\n\\lambda(X,\\theta) = \\frac{1}{|X|}\\sum_{x\\in X} (1-|\\langle \\psi_c(x)| U(\\theta,x)|0\\rangle|^2)^2\n\\] where \\(| \\psi_c(x)\\rangle\\) is the label state of the class that \\(x\\) belongs to and \\(X\\) is the training data. Each element of the sum is one minus the fidelity between the circuit result and the correct label, therefore each element takes values in \\([0,1]\\). If for one \\(x\\) it is \\(0\\), that means the fidelity between the correct label and the circuit result is \\(1\\), so the circuit has transformed \\(x\\) in the correct state. Alternatively, if the fidelity is low, this datapoint would contribute a fairly big amount to the loss function. In the optimal case, that everything gets classified correctly, the value of the loss function would be zero. In order to get a proper classifier, all that is needed now, is the values of \\(\\theta\\) such that \\(\\lambda\\) is minimal. We try to find these values in the optimization step in the next section.\nFor the optimization it is useful to rewrite \\(\\lambda\\). Instead of looking at fidelities between states, we express the loss in terms of expectation values \\[\n\\lambda(X,\\theta) = \\frac{1}{|X|}\\sum_{x\\in X} (1-\\langle 0|U(\\theta,x)^T \\Psi_c(x) U(\\theta,x)|0\\rangle)^2\n\\] where \\(\\Psi_c(x) = | \\psi_c(x)\\rangle \\langle \\psi_c(x)|\\) is the projector defined by the correct label state of \\(x\\in X\\). This is also the way it is implemented.\n\ndef cost(train_set, labels, parameters, circuit):\n    \"\"\"\n\n    :param train_set: A list of the datapoints in the training set\n    :param labels: A list of the labels of the datapoints\n    :param parameters: The values of the parameters in the parameterized circuit\n    :param circuit: A function that returns a circuit and takes one datapoint and\n                    the parameters as arguments\n    :return: The value of the loss function\n    \"\"\"\n    loss = 0.0\n1    for i in range(len(train_set)):\n        qc = circuit(train_set[i],parameters)\n        target = get_label_state(labels[i])\n2        fid = fidelity(qc, target)\n3        loss = loss + ((1-fid) ** 2)\n    return loss / len(train_set)\n\n\n1\n\nWe iterate through the training data and calculate the impact of that datapoint on the loss function\n\n2\n\nThe fidelity between the circuit result and the correct label state is expressed as a expectation value\n\n3\n\nA value in \\([0,1]\\) gets added based on how good the current datapoint is treated by the circuit"
  },
  {
    "objectID": "research/quantum_classifier/quantum_classifier.html#minimization",
    "href": "research/quantum_classifier/quantum_classifier.html#minimization",
    "title": "Building a Variational Quantum Classifier",
    "section": "3.5 Minimization",
    "text": "3.5 Minimization\nThe training requires us to find values of the tunable parameters \\(\\theta\\) such that the loss function \\(\\lambda(X,\\theta)\\) is minimal. There are many different methods with different advantages and properties to solve optimization problems. Many of these optimization algorithms have a local approach for minimization, meaning we iteratively calculate values \\(\\theta_0,\\theta_1,...,\\theta_n\\) where we calculate \\(\\theta_i\\) based on some calculation using \\(\\theta_{i-1}\\). For most algorithms, we compute or approximate the gradient \\(\\nabla \\lambda(X,\\theta_{i-1})\\) or the hessian \\(H \\lambda(X,\\theta_{i-1})\\) in order to calculate \\(\\theta_{i}\\). The gradient is the vector of the first derivatives and the hessian is the matrix containing all second derivatives. The calculation of these values is fairly expensive and explains why they are in many cases only approximated.\nWe can view our loss function as a function of expectation values, which are in turn functions of the parameters and a single datapoint. This means for the calculation of the gradient we can split the function using the chain rule: \\[\n\\frac{\\partial \\lambda(X,\\theta)}{\\partial\\theta} = \\sum_{x\\in X}\\frac{\\partial \\lambda(X,\\theta)}{\\partial \\langle E_x\\rangle} \\frac{\\partial \\langle E_x\\rangle}{\\partial\\theta}\n\\] where \\(\\langle E_x\\rangle = \\langle 0|U(\\theta,x)^T \\Psi_c(x) U(\\theta,x)|0\\rangle\\). This way we get two parts that we can examine separately. The left part can be done through automatic differentiation like it is usually done for differentiation problems. The right part concerns the differentiation of a quantum circuit with respect to one of the parameters, for which there are several methods, two of these are numerical differentiation and the parameter shift rule (Crooks 2019). Using the result of these calculations, we now have the gradient to determine the next step in an iteration of the optimization.\nWithout further examining whether our choice theoretically leads to a good result, we will be choosing BFGS as our optimization algorithm as used in (Pérez-Salinas et al. 2020).\n\nlayers = 5\nparam_unweighted = [tq.Variable('p' + str(i)) for i in range(layers * 2)]\ninitials_unweighted = {key: random.uniform(0, 2 * np.pi) for key in param_unweighted}\n\n\n\nObjective1 = cost(training_data, labels, param_unweighted, create_circuit)\n\nresult1 = tq.minimize(objective=Objective1, initial_values=initials_unweighted,  silent=True, backend=\"qulacs\")\nprint(result1.history.plot('energies', label='loss'))\nprint(result1.history.plot('angles', label=\"\"))\n\n\n\n\nNone\nNone"
  },
  {
    "objectID": "research/quantum_classifier/quantum_classifier.html#results",
    "href": "research/quantum_classifier/quantum_classifier.html#results",
    "title": "Building a Variational Quantum Classifier",
    "section": "3.6 Results",
    "text": "3.6 Results\nWe have done the optimization and have the optimal parameter assignment stored in result1.angles. With these results we can run through our test set and assign the labels according to the method from section 3.2. For this, we calculate the fidelity to the different label states and assign the label with the highest fidelity. We can use the visualization we used earlier for Figure 1 to compare the correct labels with the trained circuit. By computing the correct label through calculate_label(), we can also calculate the percentage of correct guesses. As a reference, guessing randomly would give us a success rate of \\(0.25\\).\n\ndef assign_label(datapoint, opt_params, circuit, param):\n    qc = circuit(datapoint,param)\n    max_fid = 0\n    choice = 0\n    for i in range(4):\n        H = tq.paulis.Projector(get_label_state(i))\n        Exp = tq.ExpectationValue(U=qc, H=H)\n        fid = tq.simulate(Exp, variables=opt_params)\n        if fid &gt; max_fid:\n            max_fid = fid\n            choice = i\n    return choice\n\ndef test_and_visualize(testing_data, opt_params, circuit, param):\n    labeled_set = []\n    num_correct = 0\n    for x in testing_data:\n        label = assign_label(x, opt_params, circuit, param)\n        if label == calculate_label(x):\n            num_correct += 1\n        labeled_set.append((x[0], x[1], label))\n\n    print(\"Success Rate: \", num_correct / len(testing_data))\n    visualize_points(labeled_set)\n\ntest_and_visualize(test_data, result1.angles, create_circuit, param_unweighted)\n\nSuccess Rate:  0.877\n\n\n\n\n\nAs we can see, the circuit has learned the data fairly well, leading to a success rate of \\(88\\%\\) using 5 layers. In comparison to other machine learning algorithms like neural networks, this result holds up well, as we are only using 10 parameters in our circuit, and are still able to perform fairly well. For many other systems the amount of required parameters would rise significantly faster."
  },
  {
    "objectID": "research/molcirc/index.html",
    "href": "research/molcirc/index.html",
    "title": "Molecular Quantum Circuits",
    "section": "",
    "text": "Physical insights into the construction of quantum circuits.\nChemical graphs (or Lewis structures/resonance structures) are a powerful abstraction concept, that allows the qualitative prediction of molecular properties or reactions from a remarkably simple structure. Applied to the design of quantum circuits for electronic ground states (the ground states of molecules), chemical graphs allow physical insight into construction, optimization, and interpretation of quantum circuits.\nA detailed description of this methodology is given in arxiv:2207.12421. In this blog entry we will try to approach this circuit design principle through an explicit example."
  },
  {
    "objectID": "research/molcirc/index.html#basic-building-blocks",
    "href": "research/molcirc/index.html#basic-building-blocks",
    "title": "Molecular Quantum Circuits",
    "section": "Basic Building Blocks",
    "text": "Basic Building Blocks\nIn conventional methodologies of (unitary) coupled-cluster, the wavefunction is generated by exciting electrons from an initial basis state containing a specific number of electrons. A significant distinction between traditional coupled cluster (both unitary and non-unitary) and recent advancements in quantum circuit design lies in the exclusion of higher-order excitations. Instead, the focus is on utilizing a limited set of unitary operations, which are subsequently iteratively applied in a layer-by-layer manner.\nWithin conventional coupled-cluster approaches, a particular type of excitation, such as a single-electron excitation between two orbitals, is typically accounted for only once. To enhance accuracy, higher-order excitations are introduced.\nHowever, in the context of quantum circuit designs, like the one being discussed, this specific excitation might occur multiple times in various sections of the circuit, while the inclusion of higher-order excitations is often bypassed or minimized.\nA simple choice of two basic building blocks for electronic quantum circuits are:\n\nOrbital Rotations (single electron excitations)\n\nPair Excitations (restricted double excitations)\n\nthese operations are for example used in the prominent k-UpCCGSD approach or the separable pair approximation.\nTake for example two orbitals \\(\\phi_0\\) and \\(\\phi_1\\) encoded into four qubits (\\(\\phi_0^\\uparrow,\\phi_0^\\downarrow,\\phi_1^\\uparrow,\\phi_1^\\downarrow\\)) indicating the occupation of the corresponding spin-orbital. The qubit state holding a spin-paired electron pair in orbital \\(\\phi_0\\) is then \\[\n\\lvert 1100 \\rangle.\n\\] If we excite this spin-paired electron into the second spatial orbital we end up with \\[\n\\lvert 1100 \\rangle \\rightarrow \\lvert 0011 \\rangle.\n\\]\nWe can treat the spin-paired electrons bound to the same orbital as a quasi-particle – so-called Hard-core Bosons. A wavefunction constructed from Hard-core Boson states entirely is not invariant to rotations in the underlying orbital basis, as we are confining the spin-paired electrons to occupy a specific choice of orbitals. Graphically we can depict this as\n\n\n\nwhere we have shown the situation in a hydrogen molecule in a minimal basis – one atomic orbital on each hydrogen atom. In this case, the rotation into a different orbital basis clearly leads to a different wavefunction.\nThe two bases depicted in the figure above are an atomic basis (native orbitals), which we will denote as \\(\\phi_L\\) and \\(\\phi_R\\) for left and right, and a molcular basis \\[\n\\phi_\\pm = \\frac{1}{\\sqrt{2}} \\phi_L \\pm \\phi_R.\n\\] The state in the molecular basis as depicted above, can now be writte as \\[\n\\lvert \\Psi \\rangle = c_0 a^\\dagger_{+_{\\downarrow}} a^\\dagger_{+_{\\uparrow}} \\lvert \\rangle + c_1 a^\\dagger_{-_{\\downarrow}}a^\\dagger_{-_{\\uparrow}} \\lvert \\rangle\n\\] using second quantized language. This is a Hardcore-Boson state with one quasi-particle in two possible orbitals. Expressed in the atomic basis, this state looks like \\[\n\\lvert \\Psi \\rangle = \\frac{1}{2} \\left(c_0+c_1\\right) \\left(a^\\dagger_{L_{\\downarrow}}a^\\dagger_{L_{\\uparrow}} + a^\\dagger_{L_{\\downarrow}}a^\\dagger_{L_{\\uparrow}} \\right)\\lvert \\rangle + \\frac{1}{2}\\left(c_0-c_1\\right) \\left(a^\\dagger_{L_{\\downarrow}}a^\\dagger_{R_{\\uparrow}} + a^\\dagger_{R_{\\downarrow}}a^\\dagger_{L_{\\uparrow}} \\right)\\lvert \\rangle,\n\\] with an ionic (both electrons either in \\(L\\) or \\(R\\)) and a neutral (one electron in \\(L\\) and one in \\(R\\)) part. Depending on the choice of the coefficients we can isolate both extremes. In the article this is used to demonstrate how a Hard-core Boson model, with electron pairs confined to the same orbital, is still able to describe bond breaking – i.e. by chosing \\(c_1=-c_0\\) in the wavefunction above.\nQuasi-particle models like the Hard-core Boson approach are therefore dependent on the chosen orbital basis. We can optimize the basis in order to find the best choice for a given quasi-particle wavefunction. These optimizations are however sensitive to initial guesses. Here, molecular graphs serve as a guiding heuristic to initialize good initial guesses for the orbital optimizer. In the original article, this is illustrated in detail on some examples. In the next section, you will find the code for the linear H\\(_4\\) molecule.\nWithin quantum circuits, we can rotate the orbital basis with the second building block: the orbital rotations. This allows us to connect several quasi-particle models in sequence by rotating into different bases, correlating the quasi-particles in that basis and finally rotating back to the initial basis.\nThe molecular graph will take the role as a guiding heuristic helping with placing and initializing the orbital rotation gates as well as the quasi-particle correlators within the quantum circuit."
  },
  {
    "objectID": "research/molcirc/index.html#example",
    "href": "research/molcirc/index.html#example",
    "title": "Molecular Quantum Circuits",
    "section": "Example",
    "text": "Example\nIn the article the linear H4 system has been used to illustrate the construction of quantum circuits from chemical graphs. We will use the H4 example from the paper and provide the code that reproduces it. First we initialize the molecule and represent the Hamiltonian in a minimal basis. Note that we are using (orthonormalized) atomic orbitals as our second quantized basis and not canonical Hartree-Fock orbitals.\n\nimport tequila as tq\nfrom numpy import pi, eye\n\ngeometry = \"\"\"\nH 0.0 0.0 0.0\nH 0.0 0.0 1.5\nH 0.0 0.0 3.0\nH 0.0 0.0 4.5\n\"\"\"\n\nmol = tq.Molecule(geometry=geometry, basis_set=\"sto-3g\")\n# switch to native orbitals\n# in this case: orthonormalized sto-3g orbitals\nmol = mol.use_native_orbitals()\nH = mol.make_hamiltonian()\nexact = mol.compute_energy(\"fci\")\n\nAs initial state we can construct an SPA circuit using the first graph in the figure above. In this first graph, the H\\(_4\\) molecule is interpreted as two H\\(_2\\) molecules. We initializing the graph, by assigning basis orbitals to the vertices. Here we have 4 basis orbitals (atomic s-type orbitals located on the individual atoms), so the assignment is straightforward.\n\n# graph is\n# H--H  H--H\ngraph = [(0,1),(2,3)]\nUSPA = mol.make_ansatz(name=\"SPA\", edges=graph)\nESPA = tq.ExpectationValue(H=H, U=USPA)\nresult = tq.minimize(ESPA, silent=True)\n\nprint(\"SPA/Atomic error: {:+2.5f}\".format(result.energy-exact))\n\nSPA/Atomic error: +1.09885\n\n\nwe see, that the SPA does not perform well – the reason is that we are currently in an atomic orbital basis. In order to rotate the basis, we add orbital rotations to the initial circuit. Here we will use a static angle that will mix the orbitals in a equally weighted fashion (corresponding to Eq.19 in the article, here explicitly represented with unitary circuits). This represents the SPA in a basis that would correspond to the optimized setting in two isolated H2 molecules (i.e. the first graph)\n\nUR0 = tq.QCircuit()\nfor edge in graph:\n    UR0 += mol.UR(edge[0],edge[1],angle=pi/2)\n\nU0 = USPA + UR0\nE0 = tq.ExpectationValue(H=H, U=U0)\nresult = tq.minimize(E0, silent=True)\n\nprint(\"SPA/Molecular error: {:+2.5f}\".format(result.energy-exact))\n\nSPA/Molecular error: +0.04009\n\n\nThe error is now 40 millihartree. We can bring it further down by allowing the orbitals to relax which can be achieved by adding more orbital rotations with variable angles. We initialize the angles to zero (i.e. we are starting from our previous result as guess). We chose the same pattern as in the \\(U_\\text{RR}\\) circuits in the article\n\n\nCode\nURR0 = mol.UR(0,1,angle=\"b\")\nURR0 = mol.UR(2,3,angle=\"b\")\nURR0 = mol.UR(1,2,angle=\"a\")\n\nU0 = USPA + URR0 + UR0 + URR0 \nE0 = tq.ExpectationValue(H=H, U=U0)\nresult = tq.minimize(E0, silent=True, initial_values=result.variables)\n\nprint(\"SPA/Relaxed-Molecular error: {:+2.5f}\".format(result.energy-exact))\n\n\nSPA/Relaxed-Molecular error: +0.03560\n\n\nAlternatively we can optimize the orbitals with respect to the SPA wavefunction (the strategy from the article) and use this as our orbital basis. As the SPA wavefunction is entirelty within the Hardcode-boson quasiparticle approximation, we can perform the optimization within that approximation reducing our simulation time significantly (see code in the article for the equivalent optimization without HCB approximation)\n\n\nCode\nUHCB = mol.make_ansatz(name=\"HCB-SPA\", edges=graph)\nguess = eye(4)\nguess[0] = [1, 1,0, 0]\nguess[0] = [1,-1,0, 0]\nguess[0] = [0, 0,1, 1]\nguess[0] = [0, 0,1,-1]\nopt = tq.chemistry.optimize_orbitals(circuit=UHCB,molecule=mol, use_hcb=True, initial_guess=guess.T, silent=True)\n\n# update our Hamiltonian\nmol = opt.molecule\nH = mol.make_hamiltonian()\n\nUSPA = UHCB + mol.hcb_to_me()\nE = tq.ExpectationValue(H=H, U=USPA)\nresult = tq.minimize(E, silent=True)\n\nprint(\"SPA/opt-orbitals error: {:+2.5f}\".format(result.energy-exact))\n\n\n/usr/share/miniconda/envs/blogqa/lib/python3.12/site-packages/pyscf/gto/mole.py:1293: UserWarning: Function mol.dumps drops attribute energy_nuc because it is not JSON-serializable\n  warnings.warn(msg)\n\n\nSPA/opt-orbitals error: +0.01626\n\n\nNote, that we can get the same result by providing enough orbital rotations to our circuit.\nTo improve on the SPA model in the optimal basis we take the second graph and apply the following pattern \\[\nU_G = U_R^\\dagger U_C U_R\n\\] that corresponds to 1. rotate into a new orbital basis that resembles the graph structure 2. correlate the quasi particles in this orbital basis 3. rotate back\nIn the following we will do this for the H4 system using the two graphs indicated in the picture above. The first graph is used for the SPA initalization, and the second graph will add further correlation to the initial SPA state. Note that we included an approximation by neglecting one edge in the second graph which we will not correlated. The code-block is identical as the on in the appendix of the article.\n\n\nCode\n# dependencies: tequila &gt;= 1.8.7, pyscf~=1.7, scipy~=1.7\n# suggested quantum backend for optimal performance: qulacs &gt;= 0.3\nimport tequila as tq\nfrom numpy import eye, pi\n\n# Create the molecule object\n# use orthonormalized atomic orbitals as basis\ngeometry = \"h 0.0 0.0 0.0\\nh 0.0 0.0 1.5\\nh 0.0 0.0 3.0\\nh 0.0 0.0 4.5\"\nmol = tq.Molecule(geometry=geometry, basis_set=\"sto-3g\")\nenergies = {\"FCI\":mol.compute_energy(\"fci\")}\n# switch from canonical HF orbitals to orthonormalized STO-3G orbitals\n# to follow notation in the article\nmol = mol.use_native_orbitals()\n\n# Create the SPA circuit for\n# Graph: H -- H    H -- H\n# edges get tuples of orbital-indices assigned\nUSPA = mol.make_ansatz(name=\"SPA\", edges=[(0,1),(2,3)])\n\n# initial guess for the orbitals\n# according to graph in Eq.(17) and orbitals in Eq.(19)\nguess = eye(4)\nguess[0] = [1.0,1.0,0.0,0.0]\nguess[1] = [1.0,-1.,0.0,0.0]\nguess[2] = [0.0,0.0,1.0,1.0]\nguess[3] = [0.0,0.0,1.0,-1.]\n\n# optimize orbitals and circuit parameter\n# PySCF interface\nopt = tq.chemistry.optimize_orbitals(mol, circuit=USPA, initial_guess=guess.T)\nprint(\"Optimized Orbital Coefficients\")\nprint(opt.molecule.integral_manager.orbital_coefficients)\nenergies[\"SPA\"] = opt.energy\n\n# get Hamiltonian with optimized orbitals\nH = opt.molecule.make_hamiltonian()\n\n# initialize rotations to graph in Eq.(21)\n# H    H -- H    H\n# as illustrated in Eq.(24)\n# UR as in Eq.(7) uses spatial orbital indices\nR0 = tq.Variable(\"R0\")\nR1 = tq.Variable(\"R1\")\nUR0 = mol.UR(0,1,angle=(R0+0.5)*pi)\nUR0+= mol.UR(2,3,angle=(R0+0.5)*pi)\nUR1 = mol.UR(1,2,angle=(R1+0.5)*pi)\n\n# initialize correlator according to Eq.(22)\nUC = mol.UC(1,2,angle=\"C\")\n\n# construct the circuit for both graphs\nU = USPA + UR0 + UR1 + UC + UR1.dagger() + UR0.dagger()\n# optimize the energy\nE = tq.ExpectationValue(H=H, U=U)\nresult = tq.minimize(E, silent=True)\nenergies[\"SPA+\"] = result.energy\nprint(energies)\n\n\n\n\nCode\nfor k,v in energies.items():\n    if \"fci\" in k.lower(): continue\n    print(\"{:5} error : {:+2.5f}\".format(k,v-exact))\n\n\nSPA   error : +0.01626\nSPA+  error : +0.00844"
  },
  {
    "objectID": "research/molcirc/index.html#further-reading",
    "href": "research/molcirc/index.html#further-reading",
    "title": "Molecular Quantum Circuits",
    "section": "Further Reading",
    "text": "Further Reading\n\nOriginal Article\nDivide and Conquer Approach\nSeparable Pair Approximation"
  },
  {
    "objectID": "research/molcirc/index.html#dependencies-and-installation",
    "href": "research/molcirc/index.html#dependencies-and-installation",
    "title": "Molecular Quantum Circuits",
    "section": "Dependencies and Installation",
    "text": "Dependencies and Installation\nIn order to execute code from this blog entry you need the following dependencies in your environment\npip install tequila-basic\npip install pyscf\n# optional (significantly faster)\npip install qulacs"
  },
  {
    "objectID": "FAQ.html",
    "href": "FAQ.html",
    "title": "FAQ",
    "section": "",
    "text": "FAQ\n\n\n\n\n\n\n\ncode\n\n\n\n\n\n\n\n\n\n\n\nAug 2, 2024\n\n\nElisabeth Welizky\n\n\n\n\n\n\nNo matching items"
  }
]